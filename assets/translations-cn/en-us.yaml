##############################
# Special stuff
##############################
##############################
# Components & Pages
##############################
about:
  downloadCLI:
    title: CLI Downloads
  downloadImageList:
    title: Image Lists
  os:
    linux: Linux
    mac: macOS
    windows: Windows
  title: About
  versions:
    cli: CLI
    component: Component
    helm: Helm
    machine: Machine
    releaseNotes: View release notes
    title: Versions
    version: Version
accountAndKeys:
  account:
    change: Change Password
    title: Account
  apiKeys:
    add:
      customExpiry:
        options:
          day: Days
          hour: Hours
          minute: Minutes
          month: Months
          year: Years
      description:
        label: Description
        placeholder: Optionally enter a description to help you identify this API Key
      expiry:
        label: Automatically expire
        options:
          custom: Custom
          day: A day from now
          maximum: '{value} - Maximum allowed'
          month: A month from now
          never: Never
          year: A year from now
      label: Create API Key
      noScope: No Scope
      scope: Scope
    apiEndpoint: 'API Endpoint:'
    info:
      accessKey: Access Key
      bearerToken: Bearer Token
      bearerTokenTip: 'Access Key and Secret Key can be sent as the username and password for HTTP Basic auth to authorize requests. You can also combine them to use as a Bearer token:'
      keyCreated: A new API Key has been created
      saveWarning: Save the info above! This is the only time you'll be able to see it. If you lose it, you'll need to create a new API key.
      secretKey: Secret Key
      ttlLimitedWarning: The Expiry time for this API Key was reduced due to system configuration
    notAllowed: You do not have permission to manage API Keys
    title: API Keys
  title: Account and API Keys
action:
  activate: Activate
  addSidecar: Add Sidecar
  clone: Clone
  copy: Copy
  deactivate: Deactivate
  disable: Disable
  download: Download YAML
  downloadFile: Download File
  edit: Edit Config
  editYaml: Edit YAML
  enable: Enable
  hide: Hide
  openLogs: View Logs
  openShell: Execute Shell
  redeploy: Redeploy
  refresh: Refresh
  remove: Delete
  resume: Resume
  rollback: Rollback
  runNow: Run Now
  show: Show
  suspend: Suspend
  unassign: Unassign
  uninstall: Uninstall
  view: View Config
  viewInApi: View in API
  viewYaml: View YAML
addClusterMemberDialog:
  title: Add Cluster Member
addProjectMemberDialog:
  title: Add Project Member
addonConfigConfirmation:
  body: Changing the Kubernetes Version can reset the Add-On Config values. You should check that the values are as expected before continuing.
  title: Add-On Config Reset
##############################
### Advanced Settings
##############################
advancedSettings:
  descriptions:
    auditlog-server-url: Configure the audit log service url
    auth-token-max-ttl-minutes: Custom max TTL (in minutes) on an auth token.
    auth-user-info-max-age-seconds: The maximum age of a users auth tokens before an auth provider group membership sync will be performed.
    auth-user-info-resync-cron: Default cron schedule for resyncing auth provider group memberships.
    auth-user-session-ttl-minutes: Custom TTL (in minutes) on a user auth session.
    brand: Folder name for an alternative theme defined in '/assets/brand'
    cacerts: CA Certificates needed to verify the server's certificate.
    cluster-defaults: Override RKE Defaults when creating new clusters.
    cluster-template-enforcement: Non-admins will be restricted to launching clusters via preapproved RKE Templates only.
    custom-notifications: Edit custom notifications
    engine-install-url: Default Docker engine installation URL (for most node drivers).
    engine-iso-url: Default OS installation URL (for vSphere driver).
    engine-newest-version: The newest supported version of Docker at the time of this release.  A Docker version that does not satisfy supported docker range but is newer than this will be marked as untested.
    engine-supported-range: Semver range for supported Docker engine versions.  Versions which do not satisfy this range will be marked unsupported in the UI.
    harv-additional-ca: Custom CA root certificates for TLS validation.
    harv-auto-disk-provision-paths: Specify the disks(using glob pattern) that Harvester will automatically add as VM storage.
    harv-backup-target: Custom backup target to store VM backups.
    harv-cluster-registration-url: Registration URL for mutil-cluster management.
    harv-http-proxy: HTTP proxy for Harvester to access external services.
    harv-log-level: Configure Harvester server log level. Default to info.
    harv-overcommit-config: Resource overcommit configuration.
    harv-server-version: Harvester server version.
    harv-ssl-parameters: Custom SSL Parameters for TLS validation.
    harv-support-bundle-image: Support bundle image configuration. Find different versions in <a href="https://hub.docker.com/r/rancher/support-bundle-kit/tags" target="_blank">rancher/support-bundle-kit</a>.
    harv-support-bundle-namespaces: Specify resources in other namespaces to be collected by the support package.
    harv-support-bundle-timeout: Support Bundle timeout config in minutes, use 0 to disable the timeout.
    harv-ui-index: HTML index location for the UI.
    harv-ui-source: Config how to load the UI source.
    harv-upgrade-checker-enabled: Specify whether to enable Harvester upgrade check or not. Default is true.
    harv-upgrade-checker-url: Default Harvester upgrade check url. Only used when the <code>upgrade-checker-enabled</code>  is equal to true.
    harv-vip-pools: Config global or namespace IP address pools of the VIP by CIDR.
    harv-vlan: Default Network Interface name of the VLAN network.
    harv-vm-force-reset-policy: Config the force-reset action when a VM is stuck on a node that is down.
    harvester-monitoring: Specifies the monitoring configuration that the Harvester's built-in Prometheus will use.
    hide-local-cluster: Hide the local cluster
    ingress-ip-domain: Wildcard DNS domain to use for automatically generated Ingress hostnames. <ingress-name>.<namespace-name>.<ip address of ingress controller> will be added to the domain.
    kubeconfig-generate-token: Automatically generate kubeconfig tokens for users.
    kubeconfig-token-ttl-minutes: Custom max TTL (in minutes) on a kubeconfig token.
    none-operate-session-time: The user will automatically log out if there is no operation beyond the configured time (in seconds)
    rdns-base-url: Configure the rdns service url.
    rke-metadata-config: Configure RKE metadata refresh parameters.
    server-url: Default {appName} install url. Must be HTTPS. All nodes in your cluster must be able to reach this.
    system-default-registry: Private registry to be used for all system Docker images.
    telemetry-opt: Telemetry reporting opt-in.
    ui-banners: Classification banner is used to display a custom fixed banner in the header, footer, or both.
    ui-brand: Folder name for an alternative theme defined in '/assets/brand'
    ui-consent-banner: Banner is used to display a custom consent banner presented to users during login.
    ui-dashboard-index: HTML index location for the {appName} UI.
    ui-default-landing: The default page users land on after login.
    ui-footer-text: Extra text in footer.
    ui-footer-url: URL for the extra text in footer.
    ui-index: HTML index location for the Cluster Manager UI.
    ui-issues: Use a url address to send new 'File an Issue' reports instead of sending users to the Github issues page.
    ui-offline-preferred: Controls whether UI assets are served locally by the server container or from the remote URL defined in the ui-index and ui-dashboard-index settings. The `Dynamic` option will use local assets in production builds of {appName}.
    ui-pl: Private-Label company name.
    ui-session-logout-minutes: User will automatically logout without any operation after the configured time (in minutes)
  edit:
    changeSetting: 'Change Setting:'
    falseOption: "False"
    invalidJSON: Invalid JSON - please check and correct your input before saving
    label: Edit Setting
    trueOption: "True"
    useDefault: Use the default value
    value: Value
  editHelp:
    ui-banners: This setting takes a JSON object containing 3 root parameters; <code>banner</code>, <code>showHeader</code>, <code>showFooter</code>. <code>banner</code> is an object containing; <code>textColor</code>, <code>background</code>, and <code>text</code>, where <code>textColor</code> and <code>background</code> are any valid CSS color value.
  enum:
    harv-log-level:
      debug: Debug
      info: Info
      trace: Trace
    harv-ui-source:
      auto: Auto
      bundled: Bundled
      external: External
    telemetry-opt:
      in: Opt-in to Telemetry
      out: Opt-out of Telemetry
      prompt: Prompt
    ui-default-landing:
      ember: Cluster Manager
      vue: Cluster Explorer
    ui-offline-preferred:
      dynamic: Dynamic
      false: Remote
      true: Local
  hide: Hide
  label: Settings
  none: None
  show: Show
  subtext: Typical users will not need to change these. Proceed with caution, incorrect values can break your {appName} installation. Settings which have been customized from default settings are tagged 'Modified'.
alertmanagerConfigReceiver:
  addButton: Add Receiver
  name: Receiver Name
  namespaceWarning: Could not render the secret selector because no namespace was found to get secrets from.
  receiverTypes: 'The following receiver types can be edited in forms: Email, Slack, PagerDuty, Opsgenie and Webhook. For other receiver types, edit the AlertmanagerConfig YAML.'
  receivers: Receivers
  secretKeyId: Key Id from Secret
  slack:
    apiUrlTooltip: The secret's key that contains the Slack webhook URL. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
    webhookUrl: Webhook URL
assignTo:
  labelsTitle: |-
    {count, plural,
      =1 { Assign Cluster To&hellip; }
      other { Assign {count} Clusters To&hellip; }
    }
  title: |-
    {count, plural,
      =1 { Assign Cluster To&hellip; }
      other { Assign {count} Clusters To&hellip; }
    }
  workspace: Workspace
asyncButton:
  activate:
    action: Activate
    success: Activated
    waiting: Activating&hellip;
  apply:
    action: Apply
    success: Applied
    waiting: Applying&hellip;
  continue:
    action: Continue
    success: Saved
    waiting: Saving&hellip;
  copy:
    action: Click to Copy
    success: Copied!
  create:
    action: Create
    success: Created
    waiting: Creating&hellip;
  deactivate:
    action: Deactivate
    success: Deactivated
    waiting: Deactivating&hellip;
  default:
    action: Action
    error: Error
    success: Success
    waiting: Waiting
  delete:
    action: Delete
    success: Deleted
    waiting: Deleting&hellip;
  disable:
    action: Disable
    success: Disabled
    waiting: Disabling&hellip;
  done:
    action: Done
    success: Saved
    waiting: Saving&hellip;
  download:
    action: Download
    success: Saving
    waiting: Downloading&hellip;
  drain:
    action: Drain
    success: Drained
    waiting: Draining&hellip;
  edit:
    action: Save
    success: Saved
    waiting: Saving&hellip;
  enable:
    action: Enable
    success: Enabled
    waiting: Enabling&hellip;
  finish:
    action: Finish
    success: Finished
    waiting: Finishing&hellip;
  generate:
    action: Generate
    success: Generated
    waiting: Generating&hellip;
  import:
    action: Import
    success: Imported
    waiting: Importing&hellip;
  install:
    action: Install
    success: Installing
    waiting: Starting&hellip;
  pause:
    action: Pause Orchestration
    description: New revisions will not be deployed because orchestration is temporarily paused. To deploy new revisions, resume orchestration.
    success: Paused Orchestration
    waiting: Pausing Orchestration
  refresh:
    action: ""
    actionIcon: refresh
    error: ""
    errorIcon: error
    success: ""
    successIcon: checkmark
    waiting: ""
    waitingIcon: refresh
  remove:
    action: Remove
    success: Removed
    waiting: Removing&hellip;
  restore:
    action: Restore
    success: Restored
    waiting: Restoring&hellip;
  resume:
    action: Resume Orchestration
    success: Resumed Orchestration
    waiting: Resuming Orchestration
  rollback:
    action: Roll Back
    success: Rolled Back
    waiting: Rolling Back Workload
  rotate:
    action: Rotate
    success: Rotated
    waiting: Rotating&hellip;
  snapshot:
    action: Snapshot Now
    success: Snapshot Creating
    waiting: Snapshot Initiated&hellip;
  uninstall:
    action: Uninstall
    success: Uninstalled
    waiting: Uninstalling&hellip;
  update:
    action: Update
    success: Updated
    waiting: Updating&hellip;
  upgrade:
    action: Upgrade
    success: Upgrading
    waiting: Starting&hellip;
auth:
  config:
    label: Auth Provider
authConfig:
  accessMode:
    label: Configure who should be able to login and use {vendor}
    required: Restrict access to only the authorized users & groups
    restricted: Allow members of clusters and projects, plus authorized users & groups
    unrestricted: Allow any valid user
  allowedPrincipalIds:
    title: Authorized Users & Groups
  associatedWarning: 'Note: The {provider} user you authenticate as will be associated as an alternate way to login to the {vendor} user you are currently logged in as <code>{username}</code>; all the global permissions, project, and cluster role bindings of this {vendor} user will also apply to the {provider} user.'
  azuread:
    applicationId: Application ID
    authEndpoint: Auth Endpoint
    endpoint: Endpoint
    graphEndpoint: Graph Endpoint
    tenantId: Tenant ID
    tokenEndpoint: Token Endpoint
  cas:
    callbackURL:
      label: Service Callback URL
      placeholder: Your CAS Service Callback URL
    cas: Configure Rancher to use CAS to authentication
    connectionTimeout:
      label: Server Connection Timeout
      placeholder: e.g. 5000
    enableTLS: Use a secure connection
    hostUrl:
      label: CAS Host
      placeholder: e.g. cas-server.com
    loginEndpoint:
      label: Login Endpoint
      placeholder: e.g. /cas/login
    logoutEndpoint:
      label: Logout Endpoint
      placeholder: e.g. /cas/logout
    passwordField:
      label: Password Field
      placeholder: e.g. password
    port:
      label: Port
      placeholder: e.g. 6379
    usernameField:
      label: User Name Field
      placeholder: e.g. username
  github:
    clientId:
      label: Client ID
    clientSecret:
      label: Client Secret
    form:
      app:
        label: Application name
        value: Anything you like, e.g. My {vendor}
      callback:
        label: Authorization callback URL
      description:
        label: Application description
        value: Optional, can be left blank
      homepage:
        label: Homepage URL
      instruction: 'Fill in the form with these values:'
      prefix:
        1: <li><a href="{baseUrl}/settings/developers" target="_blank" rel="noopener noreferrer nofollow">Click here</a> to go to GitHub application settings in a new window.</li>
        2: <li>Click on the "OAuth Apps" tab.</li>
        3: <li>Click the "New OAuth App" button.</li>
      suffix:
        1: <li>Click "Register application"</li>
        2: <li>Copy and paste the Client ID and Client Secret of your newly created OAuth app into the fields below</li>
    host:
      label: GitHub Enterprise Host
      placeholder: e.g. github.mycompany.example
    table:
      clientId: Client ID
      server: Server
    target:
      label: Which version of GitHub do you want to use?
      private: A private installation of GitHub Enterprise
      public: Public GitHub.com
  googleoauth:
    adminEmail: Admin Email
    domain: Domain
    oauthCredentials:
      label: OAuth Credentials
      tip: The OAuth Credentials JSON can be found in the Google API developers console.
    serviceAccountCredentials:
      label: Service Account Credentials
      tip: The Service Account Credentials JSON can be found in the service accounts section of the Google API developers console.
    steps:
      1:
        body:
          1: Login to your account. Navigate to "APIs & Services" and then select "OAuth consent screen".
          2: 'Authorized domains:'
          3: 'Application homepage link: '
          4: Under Scopes for Google APIs, enable "email", "profile", and "openid".
          5: Click on "Save".
        title: Click <a href="https://console.developers.google.com/apis/credentials" target="_blank" rel="noopener noreferrer nofollow">here</a> to open applications settings in a new window
        topPrivateDomain: 'Top private domain of:'
      2:
        body:
          1: Select the "Create Credentials" dropdown, and select "OAuth clientID", then select "Web application".
          2: 'Authorized Javascript origins:'
          3: 'Authorized redirect URIs:'
          4: Click "Create", and then click on the "Download JSON" button.
          5: Upload the downloaded JSON file in the OAuth credentials box.
        title: Navigate to the "Credentials" tab to create your OAuth client ID
      3:
        body:
          1: Create a service account.
          2: Generate a key for the service account.
          3: Add the service account as an OAuth client in your google domain.
        introduction: 'Follow <a href="{docsBase}/admin-settings/authentication/google/#3-creating-service-account-credentials" target="_blank" rel="noopener noreferrer nofollow">this</a> guide to:'
        title: Create Service Account credentials
  ldap:
    activedirectory: Configure an Active Directory account
    cert: Certificate
    customizeSchema: Customize Schema
    defaultLoginDomain:
      hint: This domain will be used if a user logs in without specifying one.
      label: Default Login Domain
      placeholder: eg mycompany
    disabledStatusBitmask: Disabled Status Bitmask
    freeipa: Configure a FreeIPA server
    groupDNAttribute: Group DN Attribute
    groupMemberMappingAttribute: Group Member Mapping Attribute
    groupMemberUserAttribute: Group Member User Attribute
    groupSearchBase:
      label: Group Search Base
      placeholder: ou=groups,dc=mycompany,dc=com
    groupUniqueIdAttribute:
      label: Group Unique ID
      tip: Use a globally unique property created by a user group to avoid losing user privileges due to a change in the value of the property
    groups: Groups
    hostname: Hostname/IP
    loginAttribute: Login Attribute
    nameAttribute: Name Attribute
    nestedGroupMembership:
      label: Nested Group Membership
      options:
        direct: Search only direct group memberships
        nested: Search direct and nested group memberships
    objectClass: Object Class
    openldap: Configure an OpenLDAP server
    password: Password
    port: Port
    searchAttribute: Search Attribute
    searchFilter: Search Filter
    serverConnectionTimeout: Server Connection Timeout
    serviceAccountDN: Service Account Distinguished Name
    serviceAccountInfo: '{vendor} needs a service account that has read-only access to all of the domains that will be able to login, so that we can determine what groups a user is a member of when they make a request with an API key.'
    serviceAccountPassword: Service Account Password
    starttls:
      label: Start TLS
      tip: Upgrades non-encrypted connections by wrapping with TLS during the connection process. Can not be used in conjunction with TLS.
    table:
      clientId: Client ID
      server: Server
    tls: TLS
    userEnabledAttribute: User Enabled Attribute
    userMemberAttribute: User Member Attribute
    userSearchBase:
      label: User Search Base
      placeholder: e.g. ou=users,dc=mycompany,dc=com
    userUniqueIdAttribute:
      label: Unique User ID
      tip: Use the globally unique user attribute created by the user to avoid losing user permissions due to changes in the value of this attribute
    username: Username
    usernameAttribute: Username Attribute
    users: Users
  localEnabled: '{vendor} is configured to allow access to accounts in its local database.'
  manageLocal: Manage Accounts
  noneEnabled: Local Authentication is always enabled, but you may select another additional authentication provider from those shown below.
  oidc:
    authEndpoint: Auth Endpoint
    cert:
      label: Certificate
      placeholder: Paste in the certificate, starting with -----BEGIN CERTIFICATE-----
    clientId: Client ID
    clientSecret: Client Secret
    customEndpoint:
      custom: Specify
      label: Endpoints
      standard: Generate
    issuer: Issuer
    key:
      label: Private Key
      placeholder: Paste in the private key, typically starting with -----BEGIN RSA PRIVATE KEY-----
    keycloak:
      realm: Keycloak Realm
      url: Keycloak URL
    keycloakoidc: Configure a Keycloak OIDC account
    oidc: Configure an OIDC account
    rancherUrl: Rancher URL
  saml:
    UID: UID Field
    adfs: Configure an AD FS account
    api: '{vendor} API Host'
    cert:
      label: Certificate
      placeholder: Paste in the certificate, starting with -----BEGIN CERTIFICATE-----
    displayName: Display Name Field
    entityID: Entity ID Field
    groups: Groups Field
    key:
      label: Private Key
      placeholder: Paste in the private key, typically starting with -----BEGIN RSA PRIVATE KEY-----
    keycloak: Configure a Keycloak account
    metadata:
      label: Metadata XML
      placeholder: Paste in the IDP Metadata XML
    okta: Configure an Okta account
    ping: Configure a Ping account
    shibboleth: Configure a Shibboleth account
    showLdap: Configure an OpenLDAP Server
    userName: User Name Field
  stateBanner:
    disabled: The {provider} authentication provider is currently disabled.
    enabled: The {provider} authentication provider is currently enabled.
  testAndEnable: Test and Enable Authentication
authGroups:
  actions:
    assignRoles: Assign Global Roles
    refresh: Refresh Group Memberships
  assignEdit:
    assignTitle: Assign Global Roles To Group
autoLogout:
  message: You have not operated in the last {autoLogoutTime} minutes, so we will auto log out
  title: Auto logout
backupRestoreOperator:
  backupFilename: Backup Filename
  deleteTimeout:
    label: Delete Timeout
    tip: Seconds to wait for a resource delete to succeed before removing finalizers to force deletion.
  deployment:
    rancherNamespace: Rancher ResourceSet Namespace
    size: Size
    storage:
      label: Default Storage Location
      options:
        defaultStorageClass: Use the default storage class ({name})
        none: No default storage location
        pickPV: Use an existing persistent volume
        pickSC: Use an existing storage class
        s3: Use an S3-compatible object store
      persistentVolume:
        label: Persistent Volume
      storageClass:
        label: Storage Class
      tip: Configure a storage location where all backups are saved by default. You will have the option to override this with each backup, but will be limited to using an S3-compatible object store.
      warning: This {type} does not have its reclaim policy set to "Retain".  Your backups may be lost if the volume is changed or becomes unbound.
  encryption: Encryption
  encryptionConfigName:
    backuptip: Any secret in the <code>cattle-resource-system</code> namespace that has an <code>encryption-provider-config.yaml</code> key. <br/>The contents of this file are necessary to perform a restore from this backup, and are not stored by Rancher Backup.
    label: Encryption Config Secret
    options:
      none: Store the contents of the backup unencrypted
      secret: Encrypt backups using an <a target="_blank" rel="noopener noreferrer nofollow" href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#understanding-the-encryption-at-rest-configuration">Encryption Config Secret</a> (Recommended)
    restoretip: If the backup was performed with encryption enabled, a secret containing the same encryption-provider-config should be used during restore.
    warning: The contents of this file are necessary to perform a restore from this backup, and are not stored by Rancher Backup.
  lastBackup: Last Backup
  nextBackup: Next Backup
  noResourceSet: You must define a ResourceSet in this namespace to create a backup CR.
  prune:
    label: Prune
    tip: Delete the resources managed by Rancher that are not present in the backup. (Recommended)
  resourceSetName: Resource Set
  restoreFrom:
    default: The default storage target
    existing: An existing backup config
    s3: An S3-compatible object store
  retentionCount:
    label: Retention Count
    units: |-
      {count, plural,
        =1 { File }
        other { Files }
      }
  s3:
    bucketName: Bucket Name
    credentialSecretName: Credential Secret
    endpoint: Endpoint
    endpointCA: Endpoint CA
    folder: Folder
    insecureTLSSkipVerify: Skip TLS Verifications
    region: Region
    storageLocation: Storage Location
    titles:
      backupLocation: Backup Source
      location: Storage Location
      s3: S3
  schedule:
    label: Schedule
    options:
      disabled: One-Time Backup
      enabled: Recurring Backups
    placeholder: e.g. @midnight or 0 0 * * *
  storageSource:
    configureS3: Use an S3-compatible object store
    useBackup: Use the s3 location specified on the Backup CR
    useDefault: Use the default storage location configured during installation
  targetBackup: Target Backup
banner:
  background: Background Color
  bannerAlignment:
    centerOption: Center
    label: Text Alignment
    leftOption: Left
    rightOption: Right
  bannerDecoration:
    bannerBold: Bold
    bannerItalic: Italic
    bannerUnderline: Underline
    label: Text Decoration
  bannerFontSize:
    label: Font Size
  buttonText: Accept Button Text
  consent: Consent Banner
  consentFootnote: 'Tip: Use \n character for line break'
  footerBanner: Footer Banner
  headerBanner: Header Banner
  label: Fixed Banners
  loginScreenBanner: Login Screen Banner
  settingName: Banners
  showAsDialog:
    defaultButtonText: Accept
    label: Show Login Consent as a modal dialog
    tooltip: Show a modal dialog on the login screen that must be accepted by a user before they can login
  showConsent: Show Consent Banner on Login Screen
  showFooter: Show Banner in Footer
  showHeader: Show Banner in Header
  text: Text
  textColor: Text Color
branding:
  color:
    label: Primary Color
    tip: You can override the primary color used throughout the UI with a custom color of your choice.
    useCustom: Use a Custom Color
  directoryName: Brand Asset Directory Name
  favicon:
    label: Favicon
    preview: Favicon Preview
    tip: Upload a icon to replace the favicon. Image width and height should be 21 pixels. Max file size is 20KB
    upload: Upload Favicon
    useCustom: Use a Custom Favicon
  label: Branding
  linkColor:
    example: Link Example
    label: Link Color
    tip: You can override the link color used throughout the UI with a custom color of your choice.
    useCustom: Use a Custom Link Color
  loginLandscape:
    label: Login Page Landscape Image/SVG
    preview: Landscape Image/SVG Preview
    tip: Upload a image/svg to replace the login page landscape image/svg. Max file size is 100KB
    upload: Upload Image/SVG
    useCustom: Use a Custom Login Page Landscape Image/SVG
  logos:
    darkPreview: Dark Theme Preview
    label: Logo
    lightPreview: Light Theme Preview
    tip: Upload a logo to replace the Rancher logo in the top-level navigation header. Image height should be 21 pixels with a max width of 200 pixels. Max file size is 20KB
    uploadDark: Upload Dark Logo
    uploadLight: Upload Light Logo
    useCustom: Use a Custom Logo
  options:
    custom: Define a Custom Theme
    default: Default Rancher Theme
    suse: SUSE Theme
  uiIssues:
    communityLinks: Show Rancher community support links
    invalidUrl: The issue reporting value must be a complete URL, including protocol.
    issuesUrl: Issue Reporting URL
    label: Support Links
  uiPL:
    label: Private Label
catalog:
  app:
    managed: Managed
    section:
      lastOperation: Last Operation
      notes: Release Notes
      openLogs: View Logs
      readme: Chart README
      resources:
        busy: The related resources will appear when {app} is fully installed.
        label: Resources
      values: Values YAML
  chart:
    errors:
      clusterToolExists: This chart has a fixed namespace and name. A matching <a href="{url}">application</a> has been found and any changes will be made to it.
    header:
      charts: Charts
    info:
      appVersion: Application Version
      chartUrls: Chart
      chartVersions:
        label: Chart Versions
        showLess: Show Less
        showMore: Show More
      home: Home
      keywords: Keywords
      maintainers: Maintainers
      related: Related
  charts:
    all: All
    categories:
      all: All Categories
    certified:
      other: Other
      partner: Partner
      rancher: '{vendor}'
    deploysOnWindows: Deploys on Windows
    header: Charts
    noCharts: There are no charts available, have you added any repos?
    noWindows: Your repos do not contain any charts capable of being deployed on a cluster with Windows nodes.
    noWindowsAndLinux: Your repos do not contain any charts capable of being deployed on a cluster with both Windows and Linux worker nodes.
    operatingSystems:
      all: All Operating Systems
      linux: Linux
      windows: Windows
    search: Filter
    versionWindowsIncompatible: Linux only version
    windowsIncompatible: Linux only
  install:
    action:
      goToUpgrade: Edit/Upgrade
    appReadmeMissing: This chart doesn't have any additional chart information.
    appReadmeTitle: Chart Information (Helm README)
    chart: Chart
    error:
      insufficientCpu: This chart requires {need, number} CPU cores, but the cluster only has {have, number} available.
      insufficientMemory: This chart requires {need} of memory, but the cluster only has {have} available.
      legacy:
        category:
          legacy: Legacy
          mcm: Multi-cluster
        enableLegacy:
          goto: Go to Feature Flag settings
          prompt: You will need to enable Legacy Features to edit this App
        label: This is a {legacyType} App and it cannot be modified here
        navigate: Navigate to {legacyType} Apps
      requiresFound: <a href="{url}">{name}</a> must be installed before you can install this chart.
      requiresMissing: This chart requires another chart that provides {name}, but none was was found.
    header:
      install: Install {name}
      installGeneric: Install Chart
      upgrade: Upgrade {name}
    helm:
      atomic: Atomic
      cleanupOnFail: Cleanup on Failure
      crds: Apply custom resource definitions
      description:
        label: Description
        placeholder: e.g. Purpose of helm command
      dryRun: Dry Run
      force: Force
      historyMax:
        label: Keep last
        unit: |-
          {value, plural,
            =1 { revision }
            other { revisions }
          }
      hooks: Execute chart hooks
      openapi: Validate OpenAPI schema
      resetValues: Reset Values
      timeout:
        label: Timeout
        unit: |-
          {value, plural,
            =1 { second }
            other { seconds }
          }
      wait: Wait
    namespaceIsInProject: This chart's target namespace, <code>{namespace}</code>, already exists and cannot be added to a different project.
    project: Install into Project
    section:
      chartOptions: Edit Options
      diff: Compare Changes
      valuesYaml: Edit YAML
    slideIn:
      dock: Dock to bottom
    steps:
      basics:
        createNamespace: Namespace <code>{namespace}</code> will be created.
        description: This process will help {action, select, install { create } upgrade { upgrade } update { update } } the {existing, select, true { app} false { chart} }. Start by setting some basic information used by {vendor} to manage the App.
        label: Metadata
        nsCreationDescription: To install the app into a new namespace enter it's name in the Namespace field and select it.
        subtext: Set App metadata
      clusterTplValues:
        description: Configure Values used by Helm that help define the Cluster.
        label: Values
        subtext: Change how the Cluster is defined
      clusterTplVersion:
        description: Select a version of the Cluster Template
        label: Version
        subtext: Select a version of the template
      helmCli:
        checkbox: Customize Helm options before install
        description: Supply additional deployment options
        label: Helm Options
        subtext: Change how the app is deployed
      helmValues:
        chartInfo:
          button: View Chart Info
          label: Chart Info
        description: Configure Values used by Helm that help define the App.
        label: Values
        subtext: Change how the App works
    version: Version
    versions:
      current: '{ver} (Current)'
      linux: '{ver} (Linux-only)'
      windows: '{ver} (Windows-only)'
  operation:
    tableHeaders:
      action: Action
      releaseName: Release Name
      releaseNamespace: Release Namespace
  os:
    chartIncompatible: This chart is not compatible with Windows nodes.
    versionIncompatible: This version is not compatible with Windows nodes.
  repo:
    action:
      refresh: Refresh
    all: All
    gitBranch:
      defaultMessage: Will default to "master" if left blank
      label: Git Branch
      placeholder: e.g. master
    gitRepo:
      label: Git Repo URL
      placeholder: e.g. https://github.com/your-company/charts.git
    name:
      rancher-charts: '{vendor}'
      rancher-partner-charts: Partners
      rancher-rke2-charts: RKE2
    target:
      git: Git repository containing Helm chart or cluster template definitions
      http: http(s) URL to an index generated by Helm
      label: Target
    tls:
      insecureSkipTLSVerify: Skip tls verify
    url:
      label: Index URL
      placeholder: e.g. https://charts.rancher.io
  tools:
    action:
      edit: Edit
      install: Install
      manage: Manage
      remove: Remove
      upgrade: Upgrade/Edit
    header: Cluster Tools
    noTools: No Cluster Tools found
changePassword:
  cancel: Cancel
  changeOnLogin:
    label: Ask user to change their password on next login
  currentPassword:
    label: Current Password
  deleteKeys:
    label: Delete all existing API keys
  errors:
    failedDeleteKey: Failed to delete key
    failedDeleteKeys: Failed to delete keys
    failedToChange: Failed to change password
    mismatchedPassword: Passwords do not match
    strengthError: Weak password strength
  generatePassword:
    label: Generate a random password
  newGeneratedPassword: Suggest a password
  randomGen:
    generated:
      label: Generated Password
  strength:
    best: best
    good: good
    label: Password strength
    tooltip1: Password must contain at least {length} characters
    tooltip2: Include at least two types of numbers, uppercase letters, lowercase letters, and symbols
    weak: weak
  title: Change Password
  userGen:
    confirmPassword:
      label: Confirm Password
    newPassword:
      label: New Password
chartHeading:
  overview: Overview
  poweredBy: 'Powered by:'
cis:
  addTest: Add Test ID
  alertNeeded: |-
    Alerting must be enabled within the CIS chart values.yaml.
    This requires that the <a tabindex="0" href="{link}">{vendor} Monitoring and Alerting app</a> is installed
    and the Receivers and Routes are <a target="_blank" rel='noopener noreferrer nofollow' href='{docsBase}/monitoring-alerting/configuration/#alertmanager-configuration/'> configured to send out alerts.</a>
  alertOnComplete: Alert on scan completion
  alertOnFailure: Alert on scan failure
  benchmarkVersion: Benchmark Version
  clusterProvider: Cluster Provider
  cronSchedule:
    label: Schedule
    placeholder: e.g. 0 * * * *
  customConfigMap: Custom Benchmark ConfigMap
  deleteBenchmarkWarning: |-
    {count, plural,
      =1 { Any profiles using this benchmark version will no longer work. }
      other { Any profiles using these benchmark versions will no longer work }
    }
  deleteProfileWarning: |-
    {count, plural,
      =1 { Any scheduled scans using this profile will no longer work. }
      other { Any scheduled scans using either of these profiles will no longer work. }
    }
  downloadAllReports: Download All Saved Reports
  downloadLatestReport: Download Latest Report
  downloadReport: Download Report
  maxKubernetesVersion: Maximum allowed Kubernetes version
  minKubernetesVersion: Minimum required Kubernetes version
  noProfiles: There are no valid ClusterScanProfiles for this cluster type to select.
  noReportFound: No scan report found
  profile: Profile
  reports: Reports
  retention: Retention Count
  scan:
    description: Description
    fail: Fail
    lastScanTime: Last Scan Time
    notApplicable: N/A
    number: Number
    pass: Pass
    remediation: Remediation
    scanDate: Scan Date
    scanReport: Scan Report
    skip: Skip
    total: Total
    warn: Warn
  scheduling:
    disable: Run scan once
    enable: Run scan on a schedule
  scoreWarning:
    label: Scan state for "warn" results
    protip: Scans with no failures will be marked "Pass" by default even if some of the tests generate "warn" output. This behavior can be changed by selecting the "fail" option from this section.
  testID: Test ID
  testsSkipped: Tests Skipped
  testsToSkip: Tests to Skip
cluster:
  addOns:
    additionalManifest:
      title: Additional Manifest
      tooltip: Additional Kubernetes Manifest YAML to be applied to the cluster on startup.
    dependencyBanner: Add-On Configurations can vary between Kubernetes versions. Changing the Kubernetes version may reset the values below.
  addonChart:
    rancher-vsphere-cpi: vSphere CPI Configuration
    rancher-vsphere-csi: vSphere CSI Configuration
    rke2-calico: Calico Configuration
    rke2-calico-crd: Calico Configuration
    rke2-canal: Canal Configuration
    rke2-cilium: Cilium Configuration
    rke2-coredns: CoreDNS Configuration
    rke2-ingress-nginx: NGINX Ingress Configuration
    rke2-kube-proxy: Kube Proxy Configuration
    rke2-metrics-server: Metrics Server Configuration
    rke2-multus: Multus Configuration
  advanced:
    agentArgs:
      label: Raise error if kernel parameters are different than the expected kubelet defaults
    argInfo:
      machineSelector:
        bannerLabel: 'Note: The last selector that matches wins and only args from it will be used.  Args from other matches above will not combined together or merged.'
        kubeApiServerTitle: Additional API Server Args
        kubeControllerManagerTitle: Additional Controller Manager Args
        kubeSchedulerTitle: Additional Scheduler Args
        label: Add Machine Selector
        listLabel: Add Argument
        subTitle: 'Use the Kubelet args:'
        title: 'For machines with labels matching:'
        titleAlt: |-
          {count, plural,
            =1 { For all machines, use the Kubelet args: }
            other { For any machines, use the Kubelet args: }
          }
      title: Additional Kubelet Args
  agentEnvVars:
    detail: Add additional environment variables to the agent container.  This is most commonly useful for configuring a HTTP proxy.
    keyLabel: Variable Name
    label: Agent Environment
  banner:
    os: 'You are attemping to add a {newOS} worker node to a cluster with one or more {existingOS} worker nodes: some installed apps may need to be upgraded or removed.'
    rke2-k3-reprovisioning: Making changes to cluster configuration may result in nodes reprovisioning. For more information see the <a target="blank" href="{docsBase}/cluster-provisioning/rke-clusters/behavior-differences-between-rke1-and-rke2/" target="_blank" rel="noopener nofollow">documentation</a>.
    warning: This cluster contains a machineSelectorConfig which this form does not fully support; use the YAML editor to manage the full configuration.
  cloudProvider:
    aws:
      label: Amazon
    azure:
      label: Azure
    external:
      label: External
    gcp:
      label: Google
    harvester:
      label: Harvester
    rancher-vsphere:
      label: vSphere
      note: <b>Important:</b> Configure the vSphere Cloud Provider and Storage Provider options in the Add-On Config tab.
  copyConfig: Copy Config to Clipboard
  credential:
    aws:
      accessKey:
        label: Access Key
        placeholder: Your AWS Access Key
      defaultRegion:
        help: The default region to use when creating clusters.  Also contacted to verify that this credential works.
        label: Default Region
      secretKey:
        label: SecretKey
        placeholder: Your AWS Secret Key
    azure:
      clientId:
        label: Client ID
      clientSecret:
        label: Client Secret
      environment:
        label: Environment
      subscriptionId:
        label: Subscription ID
      tenantId:
        label: Tenant ID
    banner:
      createCredential: |-
        {length, plural,
          =0 {First you'll need to create a credential to talk to the cloud provider}
          other {Ok, Let's create a new credential}
        }
    digitalocean:
      accessToken:
        help: Paste in a Personal Access Token from the DigitalOcean <a href="https://cloud.digitalocean.com/settings/api/tokens" target="_blank" rel="noopener noreferrer nofollow">Applications & API</a> screen.
        label: Access Token
        placeholder: Your DigitalOcean API Access Token
    gcp:
      authEncodedJson:
        help: |-
          <p>Create a <a href="https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts" target="_blank" rel="noopener noreferrer nofollow">Service Account</a> with a JSON private key and provide the JSON here.
          These IAM roles are required:</p>
          <ul>
          <li><b>Compute Engine:</b> Compute Viewer (roles/compute.viewer)</li>
          <li><b>Project:</b> Viewer (roles/viewer)</li>
          <li><b>Kubernetes Engine:</b> Kubernetes Engine Admin (roles/container.admin)</li>
          <li><b>Service Accounts:</b> Service Account User (roles/iam.serviceAccountUser)</li>
          </ul>
          More info on roles can be found <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/iam-integration" target="_blank" rel="noopener noreferrer nofollow">here</a>.
        label: Service Account
        placeholder: Service Account private key JSON file
    harvester:
      cluster: Cluster
      cpu: CPUs
      disk: Disk
      external: External Harvester (Experimental)
      image: Image
      import: Imported Harvester
      kubeconfigContent:
        label: KubeconfigContent
      memory: Memory
      namespace: Namespace
      network: Network Name
      networkData:
        label: Network Data Template
        title: 'Network Data:'
      placeholder: Namespace/Name
      sshUser: SSH User
      userData:
        label: User Data Template
        title: 'User Data:'
    label: Cloud Credential
    linode:
      accessToken:
        help: Paste in a Personal Access Token from the Linode <a href="https://cloud.linode.com/profile/tokens" target="_blank" rel="noopener noreferrer nofollow">API Tokens</a> screen.
        label: Access Token
        placeholder: Your Linode API Access Token
    name:
      label: Credential Name
      placeholder: Name for this credential (optional)
    s3:
      accessKey:
        label: Access Key
        placeholder: Your API Access Key
      defaultBucket:
        label: Default Bucket
        placeholder: 'Optional: The default bucket to use'
      defaultEndpoint:
        label: Default Endpoint
        placeholder: 'Optional: The default endpoint to use'
      defaultEndpointCA:
        label: Default Endpoint CA Cert
        placeholder: 'Optional: The default CA certificate to use to verify the endpoint'
      defaultFolder:
        label: Default Folder
        placeholder: 'Optional: The default folder to use'
      defaultRegion:
        label: Default Region
        placeholder: 'Optional: The default region to use'
      defaultSkipSSLVerify:
        label: Accept any certificate (insecure)
      secretKey:
        label: SecretKey
        placeholder: Your API Secret Key
    select:
      option:
        new: Create new...
        none: Select a credential...
    selectExisting:
      label: Select Existing
    vmwarevsphere:
      note: 'Note: The free ESXi license does not support API access. Only servers with a valid or evaluation license are supported.'
      password:
        label: Password
      port:
        label: Port
      server:
        label: vCenter or ESXi Server
        placeholder: vcenter.domain.com
      username:
        label: Username
  custom:
    advanced:
      detail: Additional control over how the node will be registered.  These values will often need to be different for each node registered.
      label: Advanced
      nodeLabel:
        label: Add Label
        title: Node Labels
      nodeName: Node Name
      privateIp: Node Private IP
      publicIp: Node Public IP
    nodeRole:
      detail: Choose what roles the node will have in the cluster.  The cluster needs to have at least one node with each role.
      label: Node Role
    registrationCommand:
      insecure: 'Insecure: Select this to skip TLS verification if your server has a self-signed certificate.'
      label: Registration Command
      linuxDetail: Run this command on each of the existing Linux machines you want to register.
      windowsDetail: Run this command in PowerShell on each of the existing Windows machines you want to register. Windows nodes can only be workers.
      windowsNotReady: The cluster must be up and running with Linux etcd, control plane, and worker nodes before the registration command for adding Windows workers will display.
      windowsWarning: Workload pods, including some deployed by Rancher charts, will be scheduled on both Linux and Windows nodes by default. Edit NodeSelector in the chart to direct them to be placed onto a compatible node.
  description:
    label: Cluster Description
    placeholder: Any text you want that better describes this cluster
  harvester:
    clusterWarning: |-
      There {count, plural,
      =1 {is 1 Harvester cluster that is not shown}
      other {are # Harvester clusters that are not shown}
      }
    importNotice: Import Harvester Clusters via
    machinePool:
      cpu:
        placeholder: e.g. 2
      disk:
        placeholder: e.g. 4
      image:
        placeholder: Please select a image
      memory:
        placeholder: e.g. 4
      namespace:
        placeholder: e.g. default
      network:
        placeholder: Please select a network
      sshUser:
        placeholder: e.g. ubuntu
        toolTip: SSH user to login with the selected OS image.
    registration:
      step1: 1. Go to the <code>Advanced / Settings</code> page of the target Harvester's UI.
      step2: 2. Find the <code>cluster-registration-url</code> setting and click the <code><i class="icon icon-actions" ></i></code> -> <code>Edit Setting</code> button.
      step3: 3. Input the following registration URL and click the <code>Save</code> button.
      step4: Registration URL
    warning:
      label: This is a Harvester Cluster - enable the Harvester feature flag to manage it
      state: Warning
  haveOneOwner: There must be at least one member with the Owner role.
  import:
    clusterRoleBindingCommand: kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user <your username from your kubeconfig>
    clusterRoleBindingInstructions: 'If you get permission errors creating some of the resources, your user may not have the <code>cluster-admin</code> role.  Use this command to apply it:'
    commandInstructions: 'Run the <code>kubectl</code> command below on an existing Kubernetes cluster running a supported Kubernetes version to import it into {vendor}:'
    commandInstructionsInsecure: 'If you get a &quot;certificate signed by unknown authority&quot; error, your {vendor} installation has a self-signed or untrusted SSL certificate.  Run the command below instead to bypass the certificate verification:'
    privateRegistry:
      description: 'Configure a default private registry for this cluster. When enabled, all images required for cluster provisioning and system add-ons startup will be pulled from this registry(Notice: This config will override system-default-registry in global config).'
      label: Private Registry
      placeholder: e.g. index.docker.io
      title: Private Registry
  importAction: Import Existing
  k3s:
    systemService:
      coredns: CoreDNS
      local-storage: Local Storage
      metrics-server: Metrics Server
      servicelb: Klipper Service LB
      traefik: Traefik Ingress
    techPreview: K3s provisioning is in Tech Preview
  kubernetesVersion:
    experimental: experimental
    label: Kubernetes Version
  legacyWarning: The legacy feature flag is enabled and not all legacy features are supported in Kubernetes 1.21+.
  log:
    connecting: Connecting…
    noData: There are no provisioning log entries.
  machineConfig:
    amazonEc2:
      ami:
        label: AMI ID
        placeholder: 'Default: A recent Ubuntu LTS'
      encryptEbsVolume: Encrypt EBS Volume
      httpEndpoint: Allow access to EC2 metadata
      httpTokens: Use tokens for metadata
      iamInstanceProfile:
        label: IAM Instance Profile Name
        tooltip: Kubernetes AWS Cloud Provider support requires an appropriate instance profile
      instanceType: Instance Type
      kmsKey:
        label: KMS Key ARN
        text: You do not have permission to list KMS keys, but may still be able to enter a Key ARN if you know one.
      privateAddressOnly: Use only private address
      region: Region
      requestSpotInstance: Request Spot Instance
      rootSize:
        label: Root Disk Size
        placeholder: 'Default: 16'
        suffix: GB
      securityGroup:
        mode:
          custom: 'Choose one or more existing security groups:'
          default: 'Standard: Automatically create and use a "{defaultGroup}"; security group'
        title: Security Group
        vpcId: (select a VPC/Subnet first)
      selectedNetwork:
        label: VPC/Subnet
        placeholder: Select a VPC or Subnet
      spotPrice:
        label: Spot Price
        placeholder: 'Default: 0.50'
        suffix: Dollars per hour
      sshUser:
        label: SSH Username for AMI
        placeholder: 'Default: ubuntu'
        tooltip: The username that exists in the selected AMI; Provisioning will SSH to the node with this.
      tagTitle: EC2 Tags
      useEbsOptimizedInstance: EBS-Optimized Instance
      volumeType:
        label: EBS Root Volume Type
        placeholder: 'Default: gp2'
      zone: Zone
    aws:
      sizeLabel: |-
        {apiName}: {cpu, plural,
        =1 {1 vCPU}
          other {# vCPUs}
        } / {memory, number} GiB Memory / {storageSize, plural,
          =0 {EBS-Only}
          other {{storageSize, number} {storageUnit} {storageType}}
        }
    azure:
      availabilitySet:
        label: Availability Set (unmanaged)
      dns:
        help: A unique DNS label for the public IP address.
        label: DNS Label
      environment:
        label: Environment
      faultDomainCount:
        help: If the availability set has already been created, the fault domain count will be ignored.
        label: Fault Domain Count
      image:
        help: Providing an ARM resource identifier requires using managed disk.
        label: Image
      location:
        label: Location
      managedDisks:
        label: Use Managed Disks
      managedDisksSize:
        label: Managed Disk Size
      nsg:
        help: When using a Rancher managed or providing an existing NSG, all nodes using this template will use the supplied NSG. If no NSG is provided, a new NSG will be created for each node.
        label: Network Security Group
      openPort:
        add: Add Port
        help: When using an existing NSG, Open Ports are ignored.
        label: Open Port
      plan:
        label: Purchase Plan
        placeholder: publisher:product:plan
      privateIp:
        label: Private IP Address
      publicIpOptions:
        header: Public IP Options
        noPublic:
          label: No Public IP
        staticPublicIp:
          label: Static Public IP
      resourceGroup:
        label: Resource Group
      size:
        label: VM Size
      sshUser:
        label: SSH Username
      storageType:
        label: Storage Type
      subnet:
        label: Subnet
      subnetPrefix:
        label: Subnet Prefix
      updateDomainCount:
        help: If the availability set has already been created, the update domain count will be ignored.
        label: Update Domain Count
      usePrivateIp:
        label: Use Private IP
      vnet:
        label: Virtual Network
        placeholder: '[resourcegroup:]name'
    banner:
      updateInfo: Create a new pool to update machine configs
    digitalocean:
      sizeLabel: |-
        {plan, select,
          s {Basic: }
          g {General: }
          gd {General: }
          c {CPU: }
          m {Memory: }
          so {Storage: }
          standard {Standard: }
          other {}
        }{memoryGb} GB, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPUs}
        }, {disk} GB Disk ({value})
      tags:
        label: Droplet Tags
        placeholder: e.g. my_server
    linode:
      typeLabel: |-
        {label}, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPUs}
        }, {disk} GB Disk ({value})
    vsphere:
      creationMethods:
        legacy: Install from boot2docker ISO (Legacy)
        library: 'Deploy from template: Content Library'
        template: 'Deploy from template: Data Center'
        vm: Clone an existing virtual machine
      customAttributes:
        add: Add custom attribute
        description: Custom attributes allow you to attach metadata to objects in the vSphere inventory to make it easier to sort and search for these objects.
        label: Custom attributes (legacy)
      guestinfo:
        add: Add Parameter
        keyPlaceholder: e.g. guestinfo.hostname
        label: Configuration Parameters used for guestinfo
        valuePlaceholder: e.g. myrancherhost
      hostOptions:
        any: Any
      instanceOptions:
        cloudConfigYaml: Cloud Config YAML
        cloudInit:
          label: Cloud Init
          note: Cloud-init file or url to set in the guestinfo
          placeholder: e.g. http://my_host/cloud-config.yml
        contentLibrary: Content library
        cpus: CPUs
        creationMethod: Creation method
        description: Choose the size and OS of the virtual machine
        disk: Disk
        label: Instance Options
        libraryTemplate: Library template
        memory: Memory
        os: Operating System
        osIsoUrl:
          label: OS ISO URL
          placeholder: 'Default: Latest rancheros-vmware image'
        template:
          label: Template
          none: No Templates Found
        virtualMachine: Virtual machine
      networks:
        add: Add Network
        label: Networks
      scheduling:
        dataCenter: Data Center
        dataStore: Data Store
        description: Choose what hypervisor the virtual machine will be scheduled to
        folder: Folder
        host:
          label: Host
          note: Specific host to create VM on (leave blank for standalone ESXi or for cluster with DRS)
        label: Scheduling
        resourcePool: Resource Pool
      tags:
        addTag: Add Tag
        description: Tags allow you to attach metadata to objects in the vSphere inventory to make it easier to sort and search for these objects.
        label: Tags
      vAppOptions:
        allocation:
          label: vApp IP allocation policy
          placeholder: e.g. fixedAllocated
          tooltip: dhcp, fixed, transient or fixedAllocated
        auto: Use vApp to configure networks with network protocol profiles
        description: Choose OVF environment properties
        disable: Do not use vApp
        label: vApp Options
        manual: Provide a custom vApp config
        properties:
          add: Add Property
          keyPlaceholder: e.g. guestinfo.interface.0.ip.0.address
          label: vApp properties
          valuePlaceholder: e.g. ip:VM Network, expression or string
        protocol:
          label: vApp IP protocol
          placeholder: e.g. IPv4
          tooltip: IPv4 or IPv6
        restoreType: Restore Type
        transport:
          label: OVF environment transport
          placeholder: e.g. com.vmware.guestInfo
          tooltip: com.vmware.guestInfo or iso
  machinePool:
    autoReplace:
      label: Auto Replace
      toolTip: If greater than 0, nodes that are unreachable for this duration will be automatically deleted and replaced.
      unit: Minutes
    drain:
      header: Drain
      label: Drain Before Delete
    labels:
      label: Kubernetes Node Labels
    name:
      label: Pool Name
      placeholder: A random one will be generated by default
    nodeTotals:
      label:
        controlPlane: '{count} Control Plane'
        etcd: '{count} etcd'
        worker: '{count} Worker'
      tooltip:
        controlPlane: |-
          {count, plural,
            =0 { A cluster needs at least one control plane node to be usable. }
            =1 { A cluster with only one control plane node is not fault-tolerant. }
            other {}
          }
        etcd: |-
          {count, plural,
            =0 { A cluster needs at least one etcd node to be usable. }
            =1 { A cluster with only one etcd node is not fault-tolerant. }
            =2 { Clusters should have an odd number of nodes.  A cluster with 2 etcd nodes is not fault-tolerant. }
            =3 {}
            =4 { Clusters should have an odd number of nodes. }
            =5 {}
            =6 { Clusters should have an odd number of nodes. }
            =7 {}
            other { More than 7 etcd nods is not recommended. }
          }
        worker: |-
          {count, plural,
            =0 { A cluster needs at least one worker node to be usable. }
            =1 { A cluster with only one worker node is not fault-tolerant. }
            other {}
          }
    quantity:
      label: Machine Count
    role:
      label: Roles
  memberRoles:
    addClusterMember:
      labelAdd: Add Member
      labelSelect: Select Member
      noResults: No results found
      placeholder: Search for a member to provide cluster access
      searchPlaceholder: Start typing to search
    removeMessage: 'Note: Removing a user will not remove their project permissions'
  name:
    label: Cluster Name
    placeholder: A unique name for the cluster
  privateRegistry:
    mode:
      advanced: Configure advanced containerd mirroring and registry authentication options
      private: Pull images for {vendor} from a private registry
      public: Pull images for {vendor} from public DockerHub
    systemDefaultRegistry:
      label: Registry hostname for {vendor} images
  provider:
    aks: Azure AKS
    aliyun: Alibaba ACK
    aliyunecs: Aliyun ECS
    aliyunkubernetescontainerservice: Alibaba ACK
    amazonec2: Amazon EC2
    amazoneks: Amazon EKS
    aws: Amazon
    azure: Azure
    azureaks: Azure AKS
    azurekubernetesservice: Azure AKS
    baidu: Baidu CCE
    baiducloudcontainerengine: Baidu CCE
    cloudca: Cloud.ca
    cloudscale: Cloudscale
    custom: Custom
    digitalocean: DigitalOcean
    docker: Docker
    eks: Amazon EKS
    exoscale: Exoscale
    gcp: Google
    gke: Google GKE
    google: Google GCE
    googlegke: Google GKE
    harvester: Harvester
    huaweicce: Huawei CCE
    import: Generic
    imported: Imported
    k3s: K3s
    kubeAdmin: KubeADM
    linode: Linode
    linodelke: Linode LKE
    local: Local
    minikube: Minikube
    oci: Oracle OCI
    openstack: OpenStack
    opentelekomcloudcontainerengine: Open Telekom Cloud CCE
    oracle: Oracle
    oracleoke: Oracle OKE
    otc: Open Telekom Cloud
    otccce: Open Telekom Cloud CCE
    other: Other
    packet: Equinix Metal
    pinganyunecs: Pinganyun ECS
    pnap: phoenixNAP
    rackspace: RackSpace
    rancherkubernetesengine: RKE
    rke: RKE1
    rke2: RKE2
    rkeWindows: Windows
    s3: S3-Compatible
    softlayer: IBM Cloud
    tencenttke: Tencent TKE
    upcloud: UpCloud
    vmwarevsphere: VMware vSphere
    zstack: ZStack
  providerGroup:
    create-custom1: Use existing nodes and create a cluster using RKE
    create-custom2: Use existing nodes and create a cluster using RKE2/K3s
    create-kontainer: Create a cluster in a hosted Kubernetes provider
    create-rke1: Provision new nodes and create a cluster using RKE
    create-rke2: Provision new nodes and create a cluster using RKE2/K3s
    create-template: Use a Catalog Template to create a cluster
    register-custom: Import any Kubernetes cluster
    register-kontainer: Register an existing cluster in a hosted Kubernetes provider
  providerTag:
    rke2:
      harvester: '{tag}'
  rke2:
    address:
      caCerts:
        label: CA Certificates
        toolTip: Certificates required for the client to successfully verify the validity of the certificate returned by the endpoint.
      clusterCidr:
        label: Cluster CIDR
      dns:
        label: Cluster DNS
      domain:
        label: Cluster Domain
      fqdn:
        toolTip: A FQDN which will resolve to the healthy control plane nodes of the cluster.
      header: Addressing
      ipv6:
        enable: Enable IPv6 support
        warning: It looks like you are using an IPv6 CIDR. Your node driver may require additional configuration to support this.
      nodePortRange:
        label: NodePort Service Port Range
      serviceCidr:
        label: Service CIDR
      tlsSan:
        label: TLS Alternate Names
      tooltip: Cluster networking values cannot be changed after the cluster is created.
    cloudProvider:
      header: Cloud Provider Config
      label: Cloud Provider
    cni:
      label: Container Network
    controlPlaneConcurrency:
      label: Control Plane Concurrency
      toolTip: This can be either a fixed number of nodes (e.g. 1) at a time or a percentage (e.g. 10%)
    defaultPodSecurityPolicyTemplateName:
      label: Default Pod Security Policy
    deleteEmptyDir: By default, pods using emptyDir volumes will be deleted on upgrade. Operations reliant on emptyDir volumes persisting through the pod's lifecycle may be impacted.
    drain:
      label: Drain Nodes
      toolTip: Draining preemptively removes the pods on each node so there are no running workloads on the nodes being upgraded.  Upgrading without draining is faster and causes less shuffling around, but pods may still be restarted depending on the upgrade being performed.
    enableNetworkPolicy:
      label: Project Network Isolation
    etcd:
      disableSnapshots:
        label: Automatic Snapshots
      exportMetric:
        false: Only available inside the cluster
        label: Metrics
        true: Exposed to the public interface
      snapshotRetention:
        label: Keep the last
      snapshotScheduleCron:
        label: Cron Schedule
    security:
      header: Security
    snapshots:
      suffix: Snapshots per node
    systemService:
      header: System Services
      rke2-coredns: CoreDNS
      rke2-ingress-nginx: NGINX Ingress
      rke2-kube-proxy: Kube Proxy
      rke2-metrics-server: Metrics Server
    workNode:
      label: Worker Nodes
    workerConcurrency:
      label: Worker Concurrency
      toolTip: This can be either a fixed number of nodes (e.g. 1) at a time or a percentage (e.g. 10%)
  rotateCertificates:
    allServices: Rotate all service certificates
    label: Rotate Certificates
    modalTitle: Rotate Cluster Certificates
    selectService: Rotate an individual service
    services: Services
  selectCredential:
    genericDescription: '{vendor} has no built-in support for this driver.  We''ve taken a guess, but consult the driver''s documentation for the fields required for authentication.'
  snapshot:
    bulkSuccessMessage: |-
      {count, plural,
        =1 { A snapshot has been requested for 1 cluster }
        other {A snapshot has been requested for {count} clusters}
      }
    bulkSuccessTitle: Snapshot Started
    errorTitle: Error Snapshotting {name}
    failed: Snapshot from {time} failed
    groupLabel: Location
    successMessage: A snapshot has been requested for {name}
    successTitle: Snapshot Started
  tabs:
    ace: Authorized Endpoint
    addons: Add-On Config
    advanced: Advanced
    agentEnv: Agent Environment Vars
    basic: Basics
    cluster: Cluster Configuration
    etcd: etcd
    log: Provisioning Log
    machinePools: Machine Pools
    machines: Machines
    memberRoles: Member Roles
    networking: Networking
    registration: Registration
    registry: Registries
    upgrade: Upgrade Strategy
  toggle:
    v1: RKE1
    v2: RKE2/K3s
  toolsTip: Use the new Cluster Tools to manage and install Monitoring, Logging and other tools
  validation:
    iamInstanceProfileName: If the Amazon cloud provider is selected the "IAM Instance Profile Name" must be defined for each Machine Pool
clusterBadge:
  addLabel: Add Cluster Badge
  editLabel: Edit Cluster Badge
  modal:
    badgeAsIcon: Customize cluster icon
    badgeBgColor: Badge background color
    badgeTextColor: Badge text color
    buttonAction: Apply
    checkbox: Show badge for this cluster
    description: Custom description
    iconText: Icon Text
    maxCharsTooltip: Maximum two characters
    previewTitle: 'Cluster icon and name presentation:'
    title: Custom Cluster Badge
clusterConnectMode:
  actions:
    restartConfirm: Are You Sure You Want To Save Connect Mode And Restart {name} Cluster Controller？
    saveAndRestart: Save And Restart
    yes: Yes
  apiEndpoint:
    label: API Endpoint
    overrideLabel: Override API Endpoints
    placeholder: e.g. https://10.43.0.1:443
    required: API Endpoint is required
  connectMode:
    label: Connect Mode
  connectStatus:
    address: Address
    apiEndpoint: API Endpoint
    driver: Driver
    host: Host
    label: Connect Status
    provider: Provider
    timeout: Timeout
  detail: View cluster connection mode and API Endpoints
  testConnect:
    error: Connect Failed
    label: Test
    success: Connect Success
  title: Cluster connect mode
clusterIndexPage:
  hardwareResourceGauge:
    consumption: '{useful} of {total} {units} {suffix}'
    cores: Cores
    pods: Pods
    ram: Memory
    reserved: Reserved
    used: Used
  header: Cluster Dashboard
  resourceGauge:
    totalResources: Total Resources
  sections:
    alerts:
      label: Alerts
    capacity:
      label: Capacity
    clusterMetrics:
      label: Cluster Metrics
    componentStatus:
      controller-manager: Controller Manager
      etcd: Etcd
      scheduler: Scheduler
    etcdMetrics:
      label: Etcd Metrics
    events:
      date:
        label: Date
      label: Events
      resource:
        label: Resource
    gatekeeper:
      buttonText: Configure Gatekeeper
      disabled: OPA Gatekeeper is not configured.
      label: OPA Gatekeeper Constraint Violations
      noRows: There are no constraints with violations to show.
    k8sMetrics:
      label: Kubernetes Components Metrics
    nodes:
      label: Unhealthy Nodes
      noRows: There are no unhealthy nodes to show.
configmap:
  tabs:
    binaryData:
      label: Binary Data
    data:
      label: Data
      protip: Use this area for anything that's UTF-8 text data
containerResourceLimit:
  cpuPlaceholder: e.g. 1000
  gpuPlaceholder: e.g. 1
  helpText: Configure how much of the resources the container can consume by default.
  helpTextDetail: The amount of resources the container can consume by default.
  label: Container Default Resource Limit
  limitsCpu: CPU Limit
  limitsGpu: NVIDIA GPU Limit/Reservation
  limitsMemory: Memory Limit
  maxCpu: Max CPU
  maxMemory: Max Memory
  memPlaceholder: e.g. 128
  minCpu: Min CPU
  minMemory: Min Memory
  requestsCpu: CPU Reservation
  requestsMemory: Memory Reservation
cruResource:
  backBody: You will lose any changes made to the YAML.
  backToForm: Back to Form
  cancelBody: You will lose any changes made to the YAML.
  confirmBack: Okay
  confirmCancel: Okay
  previewYaml: Edit as YAML
  reviewForm: Keep editing YAML
  reviewYaml: Keep editing YAML
detailText:
  binary: '<Binary Data: {n, number} bytes>'
  collapse: Hide
  empty: <Empty>
  plusMore: |-
    {n, plural,
      =1 {+ 1 more char}
      other {+ {n, number} more chars}
    }
  unsupported: <Value not supported by UI, see YAML>
drainNode:
  action: Drain
  actionStop: Stop Drain
  deleteLocalData: Delete Empty Dir Data
  force: Force
  gracePeriod:
    custom: 'Ignore the defaults and give each pod:'
    default: Honor the default from each pod
    placeholder: e.g. 30
    title: Grace period for pods to terminate themselves
  safe:
    helpText: If a node has standalone pods or ephemeral data it will be cordoned but not drained.
    label: Safe
  timeout:
    custom: 'Give up after:'
    default: Keep trying forever
    placeholder: e.g. 60
    title: Drain timeout
  titleMultiple: Drain {count} Nodes
  titleOne: Drain {name}
embedding:
  retry: Retry
  unavailable: Cluster Manager UI is not available
etcdInfoBanner:
  failedProposals: 'Number of failed proposals:'
  hasLeader: 'Etcd has a leader:'
  leaderChanges: 'Number of leader changes:'
featureFlags:
  label: Feature Flags
  promptActivate: Please confirm that you want to activate the feature flag "{flag}"
  promptDeactivate: Please confirm that you want to deactivate the feature flag "{flag}"
  restart:
    title: Waiting for Restart
    wait: This may take a few moments
  restartRequired: 'Note: Updating this feature flag requires a restart'
  warning: |-
    Feature flags allow {vendor} to gate certain features behind flags.
    Features that are off by default should be considered experimental functionality.
    Some features require a restart of the {vendor} server to change.
    This will result in a short outage of the API and UI, but not affect running clusters or workloads.
fleet:
  bundles:
    harvester: |-
      {count, plural,
      =1 {1 bundle is hidden as it belongs to a Harvester cluster that can not be used with Continuous Delivery}
      other {# bundles are hidden as they belong to Harvester clusters that can not be used with Continuous Delivery}
      }
  cluster:
    nonReady: Non-Ready Bundles
    summary: Resource Summary
  clusterGroup:
    selector:
      label: Cluster Selectors
      matchesAll: Matches all {total, number} existing clusters
      matchesNone: Matches no existing clusters
      matchesSome: |-
        {matched, plural,
          =1 {Matches 1 of {total, number} existing clusters: "{sample}"}
          other {Matches {matched, number} of {total, number} existing clusters, including "{sample}"}
        }
  clusters:
    harvester: |-
      There {count, plural,
      =1 {is 1 Harvester cluster that is hidden as this can not be used with Continuous Delivery}
      other {are # Harvester clusters that are hidden as they can not be used with Continuous Delivery}
      }
  dashboard:
    collapseAll: Collapse All
    expandAll: Expand All
    getStarted: Get started
    gitOpsScale: GitOps at scale.
    learnMore: Learn More.
    learnMoreLink: https://fleet.rancher.io
    menuLabel: Dashboard
    noRepo: You don't have any Git Repositories in your Workspaces
    pageTitle: Continuous Delivery Dashboard
    thereIsMore: |-
      {count, plural,
      =1 { There is one other workspace with no repositories}
      other { There are { count } other workspaces with no repositories}
      }
    welcome: Welcome to Fleet Continuous Delivery
  fleetSummary:
    noClustersGitRepo: This git repo is not targeting any clusters
    state:
      error: Error
      info: Transitioning
      notReady: Not Ready
      ready: Ready
      success: Ready
      unknown: Unknown
      waitApplied: Wait Applied
      warning: Warning
  gitRepo:
    auth:
      git: Git Authentication
      helm: Helm Authentication
      label: Authentication
    caBundle:
      label: Certificates
      placeholder: Paste in one or more certificates, starting with -----BEGIN CERTIFICATE----
    createLocalBanner: When deploying a Git Repo to the Local workspace you are unable to target any specific Cluster or Cluster Groups
    paths:
      addLabel: Add Path
      empty: The root of the repo is used by default.  To use one or more different directories, add them here.
      label: Paths
      placeholder: e.g. /directory/in/your/repo
    ref:
      branch: A Branch
      branchLabel: Branch Name
      branchPlaceholder: e.g. master
      label: Watch
      revision: A Revision
      revisionLabel: Tag or Commit Hash
      revisionPlaceholder: e.g. v1.0.0
    repo:
      addRepo: Add Repository
      label: Repository URL
      noRepos: No repositories have been added
      placeholder: e.g. https://github.com/rancher/fleet-examples.git
    serviceAccount:
      label: Service Account Name
      placeholder: 'Optional: Use a service account in the target clusters'
    tabs:
      resources: Resources
      unready: Non-Ready
    target:
      advanced: Advanced
      cluster: Cluster
      clusterGroup: Cluster Group
      label: Deploy To
      labelLocal: Deploy With
      selectLabel: Target
    targetDisplay:
      advanced: Advanced
      all: All
      cluster: Cluster
      clusterGroup: Group
      local: Local
      none: None
    targetNamespace:
      label: Target Namespace
      placeholder: 'Optional: Require all resources to be in this namespace'
    tls:
      label: TLS Certificate Verification
      skip: Accept any certificate (insecure)
      specify: Specify additional certificates to be accepted
      verify: Require a valid certificate
    warningTooltip:
      cluster: There are no clusters available
      clusterGroup: There are no clusters in this Cluster Group
    workspace:
      label: Workspace
  tokens:
    harvester: |-
      {count, plural,
      =1 {1 token is hidden as it belongs to a Harvester cluster that can not be used with Continuous Delivery}
      other {# tokens are hidden as they belong to Harvester clusters that can not be used with Continuous Delivery}
      }
footer:
  docs: Docs
  download: Download CLI
  forums: Forums
  issue: File an Issue
  mirror: Download Mirror
  slack: Slack
formReservation:
  limitCpu:
    label: '{component} CPU Limit'
    placeholder: e.g. 1000
  limitMemory:
    label: '{component} Memory Limit'
    placeholder: e.g. 1000
  requestCpu:
    label: '{component} CPU Reservation'
    placeholder: e.g. 1000
  requestMemory:
    label: '{component} Memory Reservation'
    placeholder: e.g. 1000
formScheduling:
  addCustom: Add Custom Rule
  addRule: Add Rule
  autoPick:
    container: 'Automatically pick nodes for each pod matching scheduling rules:'
    host: 'Automatically pick a node matching scheduling rules:'
    vm: 'Automatically pick nodes for each virtual machine matching scheduling rules:'
  autoRun: 'Automatically run on every node matching scheduling rules:'
  canRequestHost:
    containers: Run <b>all</b> pods for this workload on a specific node
    vm: Run <b>all</b> virtual machines on a specific node
  condition: Condition
  detail: Configure what nodes the pods can be deployed to.
  effect: Effect
  field: Field
  hostMax: Maximum Nodes
  key: Label Key
  noRules: No rules.
  noToleration: No tolerations.
  nodeSelector:
    custom:
      placeholder: e.g. foo > 42 && bar != baz
    multiple:
      placeholder: e.g. foo, bar, baz
    operator:
      eq: =
      exists: is set
      ge: |
        &ge;
      gt: '>'
      in: in list
      le: |
        &le;
      lt: <
      ne: |
        &ne;
      notExists: is not set
      notIn: not in list
    preferred: 'Prefer Any of:'
    requireAll: 'Require ALL of:'
    requireAny: 'Require Any of:'
  operator: Operator
  perHost: per host
  priority:
    label: Priority
    placeholder: e.g. 3
  priorityClassName:
    label: Priority Class Name
    placeholder: e.g. high
  runSpecific: Run this pod on a specific node
  scaleIncrement: Scale Increment
  scaleMax: Maximum Scale
  scaleMin: Minimum Scale
  scaling:
    hostMaxDetail: If set, schedule containers for this service to a maximum of this many hosts.
    incrementDetail: If set, the scale must be a multiple of the increment
    minMaxDetail: If set, the scale will not be allowed to be adjusted by user or API call above or below these limits.
  scheduler:
    label: Scheduler
    placeholder: e.g. myScheduler
  status: |
    {count, plural,
    =0 {No rules}
    =1 {# rule}
    other {# rules}
    }
  time: Toleration Seconds
  title: Node Scheduling
  toleration:
    add: Add Toleration
    title: Tolerations
    workloadTitle: Tolerations for {workload} pod
  value: Value
gatekeeperConstraint:
  match:
    title: Match
  tab:
    enforcementAction:
      title: Enforcement Action
    namespaces:
      sub:
        excludedNamespaces: Excluded Namespaces
        namespaceSelector:
          addNamespace: Add Namespace
          title: Namespace Selector
        namespaces: Namespaces
        scope:
          title: Scope
      title: Namespaces
    parameters:
      addParameter: Add Parameter
      editAsForm: Edit as Form
      editAsYaml: Edit as YAML
      title: Parameters
    rules:
      sub:
        labelSelector:
          addLabel: Add Label
          title: Label Selector
      title: Rules
  template: Template
  violations:
    title: Violations
gatekeeperIndex:
  poweredBy: OPA Gatekeeper
  unavailable: OPA + Gatekeeper is not available in the system-charts catalog.
  violations: Violations
generic:
  add: Add
  all: All
  back: Back
  cancel: Cancel
  clear: Clear
  close: Close
  comingSoon: Coming Soon
  completed: Completed
  copy: Copy
  create: Create
  created: Created
  customize: Customize
  default: Default
  deprecated: Deprecated
  disable: Disable
  disabled: Disabled
  done: Done
  enable: Enable
  enabled: Enabled
  experimental: Experimental
  hideAdvanced: Hide Advanced
  id: ID
  ignored: Ignored
  imagePullPolicy:
    always: Always
    ifNotPresent: IfNotPresent
    never: Never
  invalidCron: Invalid cron schedule
  key: Key
  labelsAndAnnotations: Labels & Annotations
  links: Links
  loading: Loading&hellip;
  members: Members
  moreInfo: More Info
  na: n/a
  name: Name
  never: Never
  no: No
  none: None
  notFound: Not Found
  notification:
    title:
      error: Error
      info: Info
      succeed: Succeed
      warning: Warning
  number: '{prefix}{value, number}{suffix}'
  overview: Overview
  placeholder: e.g. {text}
  plusMore: + {n} more
  privateRegistry: Private Registry
  provisioning: —
  readFromFile: Read from File
  register: Register
  remove: Remove
  resource: |-
    {count, plural,
    one  {resource}
    other {resources}
    }
  resourceCount: |-
    {count, plural,
    one  {1 resource}
    other {# resources}
    }
  save: Save
  showAdvanced: Show Advanced
  techPreview: Tech Preview
  type: Type
  units:
    time:
      10s: 10s
      15m: 15m
      1d: 1d
      1h: 1h
      1m: 1m
      2h: 2h
      30d: 30d
      30m: 30m
      30s: 30s
      5m: 5m
      5s: 5s
      6h: 6h
      7d: 7d
  unknown: Unknown
  value: Value
  yes: Yes
glance:
  clusterInfo: Cluster Information
  cpu: CPU Usage
  created: Created
  installMonitoring: Install Monitoring
  memory: Memory
  monitoringDashboard: Monitoring Dashboard
  nodes:
    total:
      label: |-
        {count, plural,
          =1 { Node }
          other { Total Nodes }
        }
  pods: Pods
  provider: Provider
  v1MonitoringInstalled: V1 Monitoring Installed
  version: Kubernetes Version
globalMonitoringDashboard:
  globalMonitoring:
    description: Global Monitoring
    label: Global Monitoring
  grafana:
    description: Metrics Dashboards
    label: Grafana
  thanos:
    description: Cluster Component System
    label: Prometheus Thanos
globalMonitoringPage:
  cluster: Global Monitoring Cluster
  confirmDisable: Are you sure?  Click again to disable global monitoring
  customAnswers:
    addAnswerLabel: Add Answer
    answer:
      label: Answers
    detail: Configure custom answers.
    title: Custom Answers
  disable: Disable
  disabled: Global Monitoring is not enabled yet. Please click Enable button to enable it. You will be able to query your metrics across multiple clusters if cluster monitoring <code>v0.0.7000</code> or above enabled inside the clusters.
  enableActionLabel: Enable
  enableMonitoring:
    cluster: Cluster
    title: Monitoring Store
    warning: To configure an endpoint for scraping Prometheus data of the downstream cluster, the Thanos Sidecar monitoring function must still be enabled in the downstream cluster
  enabled: Global Monitoring is enabled. You can query your metrics across multiple clusters if cluster monitoring <code>v0.0.7000</code> or above enabled inside the clusters.
  globalMonitoringClusterUnavailable: Cluster {clusterName} is unavailable.
  grafana:
    detail: Global Grafana and {appName} Global Dashboard configuration.
    enableGrafanaSidecar:
      label: Enable Grafana Dashboard Provisioning Sidecar
    enablePersistence:
      label: Enable Persistent Storage for Grafana
    favicon:
      label: favicon
      placeholder: Please enter the favicon address
    header: Global Dashboard
    logo:
      label: logo
      placeholder: Please enter the logo address
    serverUrl:
      label: serverUrl
      placeholder: e.g. http://rancher.cattle-system
    serviceType:
      label: Grafana UI Service
    size:
      label: Grafana Persistent Volume Size
      placeholder: e.g. 10Gi
    storageClass:
      label: Default StorageClass for Grafana
      placeholder: Use the default class
    tabTitle:
      label: Tab Title
      placeholder: e.g. grafana
    title:
      label: Title
      placeholder: e.g. grafana
  header: Global Monitoring (Experimental)
  links:
    globalMonitoring:
      label: Global Dashboard
    grafana:
      label: Grafana UI
    thanos:
      label: Thanos UI
  noAvailableClusters: No active clusters. Please add a cluster first.
  noTemplate: Failed to load global monitoring catalog templates.
  nodeSelector:
    addSelectorLabel: Add Selector
    helpText: Select the nodes where {component} workloads will be scheduled to
  notReady: Installing Global Monitoring into the system project of global monitoring cluster...
  objectStorageWarning: Thanos sidecar in each cluster requires the object storage crednetials. So cluster owners will also be able to see the object storage crednetials in the System projects.
  store:
    aliyunoss:
      accessKey:
        label: Aliyun OSS Access Key
        placeholder: Your Aliyun access key
      bucketName:
        label: Aliyun OSS Bucket Name
        placeholder: e.g. backups
      endpoint:
        beijing: oss-cn-beijing
        chengdu: oss-cn-chengdu
        east-1: oss-us-east-1
        eu-central-1: oss-eu-central
        eu-west-1: oss-eu-west-1
        hangzhou: oss-cn-hangzhou
        heyuan: oss-cn-heyuan
        hongkong: oss-cn-hongkong
        huhehaote: oss-cn-huhehaote
        label: Aliyun OSS Region
        me-east-1: oss-me-east-1
        northeast-1: oss-ap-northeast-1
        qingdao: oss-cn-qingdao
        shanghai: oss-cn-shanghai
        shenzhen: oss-cn-shenzhen
        south-1: oss-ap-south-1
        southeast-1: oss-ap-southeast-1
        southeast-2: oss-ap-southeast-2
        southeast-3: oss-ap-southeast-3
        southeast-5: oss-ap-southeast-5
        west-1: oss-us-west-1
        zhangjiakou: oss-cn-zhangjiakou
      label: Aliyun OSS
      secretKey:
        label: Aliyun OSS Secret Key
        placeholder: Your Aliyun secret key
        provided: Provided
    azure:
      bucketName:
        label: Container Name
        placeholder: e.g. mycontainer
      endpoint:
        label: Endpoint
        placeholder: e.g. http://mystorageaccount.blob.core.windows.net
      label: Azure Storage
      maxRetries:
        label: Max Retries
        placeholder: e.g. 0
      storageAccount:
        label: Storage Account
        placeholder: Your Azure Storage Account
      storageAccountKey:
        label: Storage Account Key
        placeholder: Your Azure Storage Account Key
    detail: Store Prometheus metrics across multiple clusters to object storage for unlimited time.
    enabled:
      label: Store Prometheus metrics to object storage
    gcs:
      bucketName:
        label: Bucket Name
        placeholder: e.g. backups
      label: Google Cloud Storage
      serviceAccount:
        label: Service Account
        placeholder: Your Google service account
    s3:
      accessKey:
        label: S3 Access Key
        placeholder: Your AWS access key
      bucketName:
        label: S3 Bucket Name
        placeholder: e.g. backups
      endpoint:
        label: S3 Region Endpoint
        placeholder: e.g. s3.us-west-2.amazonaws.com
      label: S3
      secretKey:
        label: S3 Secret Key
        placeholder: Your AWS secret key
        provided: Provided
    tencentcloudcos:
      appid:
        label: APP ID
        placeholder: e.g. 1250000000
      bucketName:
        label: Bucket Name
        placeholder: e.g. backups
      label: Tencent COS
      region:
        label: Region
        placeholder: e.g. cos.ap-beijing-1.myqcloud.com
      secretId:
        label: Secret Id
        placeholder: Your Secret Id
      secretKey:
        label: Secret Key
        placeholder: Your Secret Key
    title: Object Storage
  svc:
    clusterIp: '{appName} Proxy'
    loadBalancer: L4 Load Balancer
    nodePort: NodePort
  thanos:
    detail: Query Prometheus metrics across multiple clusters.
    serviceType:
      label: Thanos Query UI Service
    title: Thanos Query
  tls:
    ca:
      label: CA Certificate
      placeholder: Paste in the certificate, starting with -----BEGIN CERTIFICATE-----
    cert:
      label: Certificate
      placeholder: Paste in the certificate, starting with -----BEGIN CERTIFICATE-----
    header: Certificate
    key:
      label: Private Key
      placeholder: Paste in the private key, typically starting with -----BEGIN RSA PRIVATE KEY-----
    serverName:
      label: Server Name
    warning: If TLS is used for access, the downstream monitoring deployment must also enable TLS authentication simultaneously.
  uninstallV1:
    promptDescription: <div class="mt-20 mb-20">You are trying to disable V1 global monitoring.</div>
    success1: V1 global monitoring successfully uninstalled.
    warning1: V1 global monitoring has been deployed. Before enabling V2 global monitoring, you need to disable it.
  updating: Updating Global Monitoring in the system project of global monitoring cluster...
  version: Global Monitoring Version
  warning:
    undefindChart: Current cluster chart undefined.
gpuReservation:
  label: NVIDIA GPU Limit/Reservation
  memUnit: GiB
  placeholder: e.g. 1
  set: Limit to
  shared: Shared GPU Memory
  sharedTips: While setting the shared GPU memory, Rancher will automatically set the GPU scheduler name for the workload
  unit: GPUs
grafanaDashboard:
  failedToLoad: Failed to load graph
  grafana: Grafana
  reload: Reload
graphOptions:
  detail: Detail
  range: Range
  refresh: Refresh
  summary: Summary
harvester:
  action:
    abortMigration: Abort Migration
    addHotplug: Add Volume
    addTemplateVersion: Add templateVersion
    backup: Take Backup
    cancelExpand: Cancel Expand
    cordon: Cordon
    createTemplate: Generate Template
    createVM: Create a Virtual Machine
    disableMaintenance: Disable Maintenance Mode
    ejectCDROM: Eject CDROM
    enableMaintenance: Enable Maintenance Mode
    exportImage: Export Image
    launchFormTemplate: Launch instance from template
    migrate: Migrate
    modifyTemplate: Modify template (Create new version)
    pause: Pause
    restart: Restart
    restore: Restore
    restoreExistingVM: Replace Existing
    restoreNewVM: Restore New
    setDefaultVersion: Set default version
    softreboot: Soft Reboot
    start: Start
    stop: Stop
    uncordon: Uncordon
    unpause: Unpause
    viewlogs: View Logs
  backup:
    backupTargetTip: The endpoint used to access the backupstore. NFS and S3 are supported.
    createText: Restore Backup
    label: Backups
    matchTarget: The current backup target does not match the existing one.
    message:
      errorTip:
        middle: Setting
        prefix: Backup Target value in
        suffix: 'is invalid, error: '
      noSetting:
        middle: setting
        prefix: You must configure the backup target in
        suffix: before creating a new backup.
      viewSetting:
        middle: here
        prefix: Click
        suffix: to view the backup config.
    restore:
      backup: Backup
      createNew: Create new
      deletePreviousVolumes: Delete Previous Volumes
      replaceExisting: Replace existing
      virtualMachineName: Virtual Machine Name
    title: Restore Virtual Machine
  cloudTemplate:
    label: Cloud Config Templates
    networkData: Network Data
    templateType: Template Type
    userData: User Data
  dashboard:
    hardwareResourceGauge:
      cpu: CPU
      memory: Memory
      storage: Storage
    header: 'Harvester Cluster: {cluster}'
    label: Dashboard
    sections:
      events:
        label: Events
      vmMetrics:
        label: VM Metrics
    version: Version
  fields:
    PhysicalNic: Physical NIC
    cpu: Cpu
    image: Image
    ipv4Address: IPv4 Address
    macAddress: Mac Address
    memory: Memory
    model: Model
    name: Name
    network: Network
    port: Port
    promiscuous: Promiscuous
    protocol: Protocol
    remove: REMOVE
    size: Size
    type: Type
    version: Version
    virtualName: Virtual machine name
    volume: Volume
  generic:
    close: Close
    cpu: CPU
    hideMore: Hide More
    memory: Memory
    noFileChosen: No file chosen
    open: Open
    showMore: Show More
    storage: Storage
  host:
    cordon:
      protip: This operation will mark the node { node } as unschedulable.
      title: Cordon
    detail:
      compute: Compute Node
      consoleUrl: Console URL
      containerRuntime: Container Runtime
      create: Creation Time
      customName: Custom Name
      hostIP: Host IP
      kernel: Kernel
      management: Management Node
      more: More Information
      networkType: Type
      nic: Physical NIC
      notRecommended: Not recommended
      os: Operating System
      role: Role
      storage: Storage
      title:
        network: Network Configuration
      update: Last Update Time
      uuid: UUID
    disk:
      add: Add Disk
      allowScheduling:
        label: Scheduling
      description:
        label: Description
      error: Host has unready or unschedulable disks.
      evictionRequested:
        label: Eviction Requested
      fileSystem:
        info: Current file system is {system}, You can format it manually.
      forceFormatted:
        label: Force Formatted
        toolTip: Force formatted will cleanup disk data, make sure you backup all available data to prevent data loss.
        yes: Yes (Ext4 File System)
      lastFormattedAt:
        info: The disk has already been force-formatted.
      notification:
        success: Update host "{name}" configurations successfully.
      path:
        label: Path
      storageReserved:
        label: Storage Reserved
    enableMaintenance:
      protip: The operation will migrate all virtual machines on this node to other nodes.
      title: Enable Maintenance Mode
    inconsistentIP: 'Host IP is inconsistent, current IP: { currentIP }, initial IP: { initIP }'
    label: Hosts
    promote:
      failed: promote failed
      none: ' '
      promoteRestart: restarting
      promoteSucceed: promote completed
      running: promoting
      unknown: promote halted
    tabs:
      basics: Basics
      disk: Disks
      instance: Virtual Machines
      labels: Labels
      monitor: Monitor Data
      network: Network
      overview: Overview
  image:
    fileName: File Name
    label: Images
    size: Size
    source: Source
    sourceType:
      download: URL
      upload: File
    tabs:
      basics: Basics
    uploadFile: Upload File
    url: URL
    urlTip: supports the <code>raw</code> and <code>qcow2</code> image formats which are supported by <a href="https://www.qemu.org/docs/master/system/images.html#disk-image-file-formats" target="_blank">qemu</a>. Bootable ISO images can also be used and are treated like <code>raw</code> images.
    warning:
      uploading: |-
        {count, plural,
        =1 {1 image is uploading, please do not refresh or close the page.}
        other {{count} images are uploading, please do not refresh or close the page.}
        }
  manager:
    cluster:
      description: Harvester is a modern Hyperconverged infrastructure (HCI) solution built for bare metal servers using enterprise-grade open source technologies including Kubernetes, Kubevirt and Longhorn.
      label: Harvester Clusters
      learnMore: Learn more about Harvester from the <a target="_blank" href="https://harvesterhci.io/" rel="noopener noreferrer nofollow">Harvester Web Site</a> or read the the <a target="_blank" href="https://docs.harvesterhci.io/" rel="noopener noreferrer nofollow">Harvester Docs</a>
      none: There are no Harvester Clusters
  modal:
    backup:
      addBackup: Add Backup
      success: Backup { backUpName } has been initiated.
    bundle:
      description: Description
      requiredDesc: Description is required!
      title: Generate Support Bundle
      titleDescription: Collect system-related log in Harvester, to help with troubleshooting and support.
      url: Issue URL
    createTemplate:
      description: Description
      message:
        failed: Failed generated template!
        success: Template { templateName } created successfully.
        tip: Please enter a template name!
      name: Name
      title: Generate Template
    ejectCDROM:
      delete: Delete
      operationTip: 'Select the volume you want to delete:'
      title: Eject CDROM
      warnTip: Eject volume will restart the virtual machine.
    exportImage:
      message:
        success: Image { name } created successfully.
      name: Name
      namespace: Namespace
      title: Export to Image
    hotplug:
      success: Volume { diskName } is mounted to the VM { vm }.
      title: Add Volume
    hotunplug:
      success: Volume { name } is detach successfully.
    migration:
      failedMessage: Latest migration failed!
      fields:
        nodeName:
          label: Target Node
          placeholder: Choose Target Node
      title: Migration
    restore:
      message:
        backup: Please select the backup that needs to be restored.
      selectBackup: Select Backup
      success: Restore { name } created successfully.
      title: Backup and restore
  namespace:
    label: Namespaces
  network:
    label: Networks
    layer3Network:
      cidr:
        label: CIDR
        placeholder: e.g. 172.16.0.1/24
      gateway:
        label: Gateway
        placeholder: e.g. 172.16.0.1
      mode:
        auto: Auto(DHCP)
        label: Mode
        manual: Manual
      serverIPAddr:
        label: DHCP Server IP
    message:
      errorTip:
        middle: Setting
        prefix: Physical NIC value in
        suffix: 'is invalid, error: '
      premise:
        middle: Settings
        prefix: You must configure a network in
        suffix: before creating a new network.
      viewSetting:
        middle: here
        prefix: Click
        suffix: to view default cluster network config.
      vlanInactive: VLAN network is inactive at {name} host
    tabs:
      basics: Basics
      layer3Network: Route
  notification:
    title:
      error: Error
      info: Info
      succeed: Succeed
      warning: Warning
  projectNamespace:
    label: Projects/Namespaces
  service:
    healthCheckEnabled:
      label: Health Check
    healthCheckFailureThreshold:
      description: The backend server will stop forwarding traffic if the number of health check failures reaches the failure threshold.
      label: Health Check Failure Threshold
    healthCheckPeriod:
      label: Health Check Period
    healthCheckPort:
      label: Health Check Port
    healthCheckSuccessThreshold:
      description: If the number of times the prober continuously detects an address successfully reaches the success threshold, then the backend server can start to forward traffic.
      label: Health Check Success Threshold
    healthCheckTimeout:
      label: Health Check Timeout
    ipam:
      label: IPAM
    title: Add-on Config
  setting:
    defaultPhysicalNIC: Default Network Interface
    harvesterMonitoring:
      label: Harvester Monitoring
      section:
        prometheus: Prometheus Configuration
        prometheusNodeExporter: Prometheus Node Exporter Configuration
      tips:
        evaluation: Interval between consecutive evaluations
        retention: How long to retain metrics
        retentionSize: Maximum size of metrics
        scrape: Interval between consecutive scrapes
    label: Settings
    message:
      ca:
        middle: here
        prefix: Click
        suffix: to add a custom certificate.
    percentTip: The value in parentheses represents the distribution percentage of the network interface on all hosts. If an interface less than 100% is selected, the user needs to manually specify the network interface on the host where the vlan network configuration fails.
    placeholder:
      accessKeyId: specify your access key id
      cert: upload a self-signed SSL certificate
      secretAccessKey: specify your secret access key
    sslCertificates:
      ca: CA
      privateKey: Private Key
      publicCertificate: Public Certificate
    supportBundleImage:
      imagePullPolicy: Pull Policy
      repo: Repository
      tag: Tag
    upgrade:
      checksum: Checksum
      chooseFile: Please select to upload an image.
      imageUrl: Please input a valid image url.
      selectExitImage: Please select the OS image to upgrade.
    validation:
      physicalNIC: DefaultPhysicalNIC
    vlanChangeTip: The newly modified default network interface only applies to newly added nodes, not existing ones.
    vmForceDeletionPolicy:
      period: Period
  sshKey:
    keypair: SSH Key
    label: SSH Keys
    tabs:
      basics: Basics
  sslParameters:
    ciphers:
      label: Ciphers
    protocols:
      label: Protocols
  support:
    kubeconfig:
      title: Download KubeConfig
      titleDescription: Download kubeconfig for debugging.
    title: Harvester Support
  tab:
    accessCredentials: Access Credentials
    advanced: Advanced Options
    network: Networks
    volume: Volumes
  tableHeaders:
    actions: Actions
    attachedVM: Attached VM
    backupTarget: Backup Target
    fingerprint: Fingerprint
    hostIp: Host IP
    message: Message
    network:
      type: Type
      vlan: Vlan ID
    phase: Phase
    progress: Progress
    readyToUse: Ready To Use
    size: Size
    targetVm: Target VM
    value: Value
    vm:
      defaultVersion: Default Version
      ipAddress: IP Address
      node: Node
  upgradePage:
    createRepository: Creating Upgrade Repository
    currentVersion: CURRENT VERSION
    dismissMessage: Dismiss it
    osUpgrade: OS Upgrade
    pending: Pending
    repoInfo:
      fail: Fail
      harvesterChart: Harvester Chart
      kubernetes: Kubernetes
      monitoringChart: Monitoring Chart
      ongoing: on-going
      os: OS
      success: Success
      upgradeStatus: Upgrade Status
    selectExisting: Select Existing Image
    succeeded: Succeeded
    upgrade: Upgrade
    upgradeApp: Upgrade Software
    upgradeImage: Download Upgrade Image
    upgradeNode: Upgrading Node
    upgradeSysService: Upgrading System Service
    upgradeTip: Please select the version you want to upgrade to
    uploadNew: Upload New Image
    versionLabel: AVAILABLE COMPATIBLE VERSIONS
  validation:
    custom:
      tooLongName: '"Name" cannot be more than {max} characters.'
    image:
      ruleFileTip: The file you have chosen ends in an extension that we do not support. We only accept image files that end in .img, .iso, .qcow, .qcow2, .raw.
      ruleTip: The URL you have entered ends in an extension that we do not support. We only accept image files that end in .img, .iso, .qcow, .qcow2, .raw.
    vm:
      memory: '"Memory" is required!'
      name: name is required
      network:
        duplicatedName: network with this name already exists!.
        duplicatedPortName: Duplicate name of the port.
        duplicatedPortNumber: Duplicate number of the port
        error: 'network {prefix}: {message}'
        macFormat: Invalid MAC address format.
        name: Network Name is required
      volume:
        docker: '"Docker Image" is required!'
        duplicatedName: volume with this name already exists!.
        error: 'volume {prefix}: {message}'
        image: '"Image" is required!'
        needImageOrExisting: At least an image volume or an existing root-disk volume is required!
        size: '"Size" is required!'
        type: '"Type" is required!'
        volume: '"Volume" is required!'
  vip:
    add:
      label: Add IP Pools
    cidr:
      invalid: '"CIRD" is invalid.'
      label: CIDR
    namespace:
      label: Namespace
  virtualMachine:
    accessCredentials:
      duplicatedUser: User already exist.
      injectSSH:
        addUser: Add User
        label: Add SSHKey
        users: Select Users
      invalidUser: Invalid Username.
      resetPwd:
        label: Add Basic Auth
      tips: qemu-guest-agent must be installed to enable Access Credentials, the VM should be restarted after credentials added. Need to enter the VM to edit password or remove SSH-Key after deleting the credentials.
      userTips: The user to be added must already exist; otherwise, the credentials will not take effect.
    cloudConfig:
      cloudInit:
        label: Cloud Init
        placeholder: Select a template
      createNew: Create new...
      createTemplateTitle: Create {name}.
      network:
        label: Network Data Template
        tip: The network-data configuration allows you to customize the instance’s networking interfaces by assigning subnet configuration, virtual device creation (bonds, bridges, vlans) routes and DNS configuration. <a href='https://cloudinit.readthedocs.io/en/latest/topics/network-config-format-v1.html' target='_blank'>Learn more</a>
        title: 'Network Data:'
      title: Cloud Config
      user:
        label: User Data Template
        tip: You can specify user data to configure an instance or run a configuration script during launch. If you launch more than one instance at a time, the user data is available to all the instances in that reservation. <a href='https://cloudinit.readthedocs.io/en/latest/topics/examples.html' target='_blank'>Learn more</a>
        title: 'User Data:'
    console:
      novnc: Open in Web VNC
      serial: Open in Serial Console
    createSSHKey: Create a New...
    detail:
      GuestAgentNotInstalled: Guest agent required
      console:
        down: This Virtual Machine is down. Please start it to access its console.
      details:
        CDROMs: CD-ROMs
        affinityRules: Affinity Rules
        annotations: Annotations
        bootOrder: Boot Order
        created: Created
        dedicatedResources: Dedicated Resources
        description: Description
        down: VM not running
        ended: Ended
        flavor: Flavor
        hostname: Hostname
        ipAddress: IP Address
        kernelRelease: Kernel Release
        labels: Labels
        name: Name
        namespace: Namespace
        node: Node
        nodeSelector: Node Selector
        operatingSystem: Operating System
        owner: Owner
        pod: Pod
        sourceNode: Source Node
        started: Started
        status: Status
        targetNode: Target Node
        template: Template
        title:
          requirements: Scheduling and resources requirements
          services: Services
          users: Logged in users
          vmDetails: Virtual Machine Details
        tolerations: Tolerations
        workloadProfile: Workload Profile
      events:
        down: No events in the past hour
        from: Generated from
      noOwner: No Owner
      notAvailable: Not available
      tabs:
        basics: Basics
        cloudConfig: Cloud Config
        configurations: Configurations
        console: Console
        details: Details
        disks: Disks
        environment: Environment
        events: Events
        hostBasic: Basic Attributes
        instance: Virtual Machines
        inventory: Inventory
        keypairs: SSH Keys
        metrics: VM Metrics
        migration: Migration
        monitor: Monitor Data
        networkInterfaces: Network Interfaces
        networks: Networks
        overview: Overview
    efiEnabled: Booting in EFI mode
    enableUsb: Enable USB Tablet
    imageTip: An external URL to the .iso, .img, .qcow2 or .raw that the virtual machine should be created from.
    input:
      MachineType: Machine Type
      image: Image
      memory: Memory
      name: Name
      password: Password
      reservedMemory: Reserved Memory
      sshKey: SSHKey
      sshKeyValue: SSH-Key
      username: Username
    installAgent: Install guest agent
    instance:
      multiple:
        count: Count
        countTip: Count should be between 1 and 10
        host:
          label: Host Prefix Name
          placeholder: default to the virtual machine name.
        label: Multiple Instance
        nameLabel: Name Prefix
        nameNsDescription: Name prefix for each instance
      multipleInstance:
      single:
        host:
          label: Hostname
          placeholder: default to the virtual machine name.
        label: Single Instance
        nameLabel: Name
      singleInstance:
    label: Virtual Machines
    machineTypeTip: 'Specify a processor architecture to emulate. To see a list of supported architectures, run: qemu-system-x86_64 -cpu ?'
    network:
      addNetwork: Add Network
      addPort: Add Port
      title: Network
    osType: OS Type
    promptRemove:
      deleteAll: Delete All
      title: 'Select the volume you want to delete:'
    restartNow: Restart Now
    restartTip: Restart the virtual machine now to take effect of the configuration changes.
    runStrategy: Run Strategy
    scheduling:
      affinity:
        anyNode: Run VM on any available node
        schedulingRules: Run VM on node(s) matching scheduling rules
        specificNode: Run VM on specific node(s) - (Live migration is not supported)
    secureBoot: Secure Boot
    sshTitle: Add Public SSH Key
    unplug:
      actionLabel: Detach
      detachVolume: Detach Volume
      title: Are you sure that you want to detach volume {name} ?
    usbTip: Provides an absolute pointer device which often helps with getting a consistent mouse cursor position in VNC.
    useTemplate:
      label: 'Use VM Template:'
      template:
        label: template
      version:
        label: version
    volume:
      addContainer: Add Container
      addExistingVolume: Add Existing Volume
      addVmImage: Add VM Image
      addVolume: Add Volume
      bootOrder: Boot Order
      bus: Bus
      dockerImage: Docker Image
      dragTip: Drag and drop volumes, or use the volume's arrows, to change the boot order.
      edit: Edit
      macTip: MAC address as seen inside the guest system.
      saveVolume: Update Volume
      setFirst: Set as root volume
      size: Size
      title:
        container: Container
        existingVolume: Existing Volume
        vmImage: Image Volume
        volume: Volume
      type: Type
      unmount:
        message: Are you sure you want to unmount this volume?
        title: Are you sure?
      volume: Volume
      volumeTip: The VM only contains a cd-rom volume. You may want to add additional disk volumes.
      volumeUpdate: Set volume { name } successfully
  virtualizationManagement:
    manage: Manage
  vmTemplate:
    label: Templates
    nameNsDescription:
      name: Template Name
    tabs:
      basics: Basics
  volume:
    image: Image
    label: Volumes
    size: Size
    source: Source
    sourceOptions:
      new: New
      vmImage: VM Image
    tabs:
      basics: Basics
hpa:
  detail:
    currentMetrics:
      header: Current Metrics
      noMetrics: No Current Metrics
    metricHeader: '{source} Metric'
  metricIdentifier:
    name:
      label: Metric Name
      placeholder: e.g. packets-per-second
    selector:
      label: Add Selector
  metricTarget:
    averageVal:
      label: Average Value
    quantity:
      label: Quantity
    type:
      label: Type
    utilization:
      label: Average Utilization
    value:
      label: Value
  metrics:
    headers:
      metricName: Name
      objectKind: Object Kind
      objectName: Object Name
      quantity: Quantity
      resource: Resource Name
      targetName: Target Name
      value: Value
    source: Source
  objectReference:
    api:
      label: Referent API Version
      placeholder: e.g. apps/v1beta1
    kind:
      label: Referent Kind
      placeholder: e.g. Deployment
    name:
      label: Referent Name
      placeholder: e.g. php-apache
  tabs:
    labels: Labels
    metrics: Metrics
    target: Target
    workload: Workload
  types:
    cpu: CPU
    memory: Memory
  warnings:
    custom: In order to use custom metrics with HPA, you need to deploy the custom metrics server such as prometheus adapter.
    external: In order to use external metrics with HPA, you need to deploy the external metrics server such as prometheus adapter.
    noMetric: In order to use resource metrics with HPA, you need to deploy the metrics server.
    resource: The selected target reference does not have the correct resource requests on the spec. Without this the HPA metric will have no effect.
  workloadTab:
    current: Current Replicas
    last: Last Scale Time
    max: Maximum Replicas
    min: Minimum Replicas
    targetReference: Target Reference
import:
  defaultNamespace:
    label: Default Namespace
  success: |-
    Applied {count, plural,
    =1 {1 Resource}
    other {# Resources}
    }
  title: Import YAML
ingress:
  certificates:
    addCertificate: Add Certificate
    addHost: Add Host
    certificate:
      doesntExist: The selected certificate does not exist
      label: Certificate - Secret Name
    defaultCertLabel: Default Ingress Controller Certificate
    headers:
      certificate: Certificate
      hosts: Hosts
    host:
      label: Host
      placeholder: e.g. example.com
    label: Certificates
    removeHost: Remove
  defaultBackend:
    label: Default Backend
    noServiceSelected: No default backend is configured.
    port:
      label: Port
      placeholder: e.g. 80 or http
    targetService:
      doesntExist: The selected service does not exist
      label: Target Service
    warning: 'Warning: Default backend is used globally for the entire cluster.'
  rules:
    addPath: Add Path
    addRule: Add Rule
    headers:
      certificates: Certificates
      path: Path
      pathType: Path Type
      port: Port
      target: Target Service
    hostname: Hostname
    path:
      label: Path
      placeholder: e.g. /foo
    port:
      label: Port
      placeholder: e.g. 80 or http
    removePath: Remove
    requestHost:
      label: Request Host
      placeholder: e.g. example.com
    target:
      doesntExist: The selected service does not exist
      label: Target Service
    title: Rules
  rulesAndCertificates:
    defaultCertificate: default
    title: Rules and Certificates
  target:
    default: Default
internalExternalIP:
  none: None
istio:
  cni: Enabled CNI
  customOverlayFile:
    label: Custom Overlay File
    tip: The <a target="_blank" rel="noopener noreferrer nofollow" href="https://istio.io/latest/docs/setup/additional-setup/customize-installation/#patching-the-output-manifest">overlay file</a> allows for additional configuration on top of the base {vendor} Istio installation. You can utilize the <a href="https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/" target="_blank" rel="noopener noreferrer nofollow" >IstioOperator API</a> to make changes and additions for all components and apply those changes via this overlay YAML file.
  description: '{vendor} Istio helm chart installs a minimal Istio configuration for you to get started integrating with your applications. If you would like to get additional information about Istio, visit <a target="_blank" href="https://istio.io/latest/docs/concepts/what-is-istio" rel="noopener noreferrer nofollow">https://istio.io/latest/docs/concepts/what-is-istio/</a>'
  destinationRule:
    connectionPool:
      connectTimeout:
        help: TCP connection timeout.
        label: TCP Connection Timeout
        placeholder: e.g. 30ms
      detail: Configure the volume of connections to an upstream service
      http1MaxPendingRequests:
        help: Maximum number of pending HTTP requests to a destination.
        label: HTTP1 Max Pending Requests
        placeholder: e.g. 1024
      http2MaxRequests:
        help: Maximum number of requests to a backend.
        label: HTTP2 Max Requests
        placeholder: e.g. 1024
      label: Connection Pool
      maxConnections:
        help: Maximum number of HTTP1 /TCP connections to a destination host.
        label: TCP Max Connections
        placeholder: e.g. 1024
      maxRequestsPerConnection:
        help: Maximum number of requests per connection to a backend. Setting this parameter to 1 disables keep alive.
        label: HTTP Max Requests Per Connection
        placeholder: e.g. 10
      maxRetries:
        help: Maximum number of retries that can be outstanding to all hosts in a cluster at a given time.
        label: HTTP Max Retries
        placeholder: e.g. 1024
    host:
      error: Host is required.
      label: Input a host
    loadBalancer:
      consistentHash:
        httpCookie:
          name:
            error: Cookie Name is required.
            label: Cookie Name
            placeholder: e.g. username
          path:
            label: Cookie Path
            placeholder: e.g. /
          ttl:
            error: TTL is required.
            label: TTL
            placeholder: e.g. 0s
        httpHeaderName:
          error: HTTP Header Name is required.
          label: HTTP Header Name
          placeholder: e.g. end-user
        label: Use consistent hash-based load balancing for soft session affinity
        minimumRingSize:
          label: Minimum Ring Size
          placeholder: e.g. 1024
        mode:
          cookie:
            label: Hash based on HTTP cookie
          header:
            label: Hash based on a specific HTTP header
          label: Hash Mode
          sourceIp:
            label: Hash based on the source IP address
      detail: Configure the load balancer algorithms
      label: Algorithm
      simple:
        label: Use standard load balancing algorithms
        leastConn:
          label: Least Request Load Balancer
        passthrough:
          label: Passthrough
        random:
          label: Random Load Balancer
        roundRobin:
          label: Round Robin Policy
      title: Load Balancer
    name:
      placeholder: e.g. myrule
    outlierDetection:
      baseEjectionTime:
        help: Minimum ejection duration. A host will remain ejected for a period equal to the product of minimum ejection duration and the number of times the host has been ejected.
        label: Base Ejection Time
        placeholder: e.g. 30s
      consecutiveErrors:
        help: Number of errors before a host is ejected from the connection pool.
        label: Consecutive Errors
        placeholder: e.g. 5
      detail: Configure eviction of unhealthy hosts from the load balancing pool
      interval:
        help: Time interval between ejection sweep analysis.
        label: Interval
        placeholder: e.g. 10s
      label: Outlier Detection
      maxEjectionPercent:
        help: Maximum % of hosts in the load balancing pool for the upstream service that can be ejected.
        label: Max Ejection Percent
        placeholder: e.g. 10
    port:
      label: Port
      placeholder: e.g. 8080 or myport
    subsets:
      addSubsetLabel: Add Subset
      label: Subsets
      labels:
        error: Please input at least one label for subset.
      name:
        error: Subset Name is required.
        label: Name
        placeholder: e.g. v1
      noSubsets: No Subsets
      removeSubsetLabel: Remove Subset
    title:
      edit: Edit Destination Rule
      new: Add Destination Rule
      view: 'Destination Rule: {name}'
    tls:
      caCertificates:
        label: CA Certificates
        placeholder: e.g. /etc/certs/rootcacerts.pem
      clientCertificate:
        error: Client Certificate is required.
        label: Client Certificate
        placeholder: e.g. /etc/certs/myclientcert.pem
      detail: Configure TLS related settings for connections to the upstream service
      label: TLS
      mode:
        disable:
          label: Disable - Do not setup a TLS connection to the upstream endpoint
        istio:
          label: Istio Mutual - Secure connections to the upstream using mutual TLS by Istio
        label: TLS Mode
        mutual:
          label: Mutual - Secure connections to the upstream using mutual TLS by presenting client certificates for authentication
        none:
          label: NONE
        simple:
          label: Simple - Originate a TLS connection to the upstream endpoint
      privateKey:
        error: Private Key is required.
        label: Private Key
        placeholder: e.g. /etc/certs/client_private_key.pem
      sni:
        label: SNI
        placeholder: e.g. nginx.example.com
      subjectAltNames:
        add: Add Subject Alternative Name
        label: Subject Alternative Names
        placeholder: e.g. example.com
  egressGateway: Enabled Egress Gateway
  ingressGateway: Enabled Ingress Gateway
  istiodRemote: Enabled istiodRemote
  kiali: Enabled Kiali
  links:
    disabled: '{app} is not installed'
    jaeger:
      description: Monitor and Troubleshoot microservices-based distributed systems.
      label: Jaeger
    kiali:
      description: Visualization of services within a service mesh and how they are connected. For Kiali to display data, you need Prometheus installed. If you need a monitoring solution, install <a tabindex="0" href="{link}">{vendor} monitoring</a>.
      label: Kiali
  pilot: Enabled Pilot
  policy: Enabled Policy
  poweredBy: Powered by <a target="_blank" rel="noopener noreferrer nofollow" href='https://istio.io/latest/'>Istio</a>
  telemetry: Enabled Telemetry
  titles:
    advanced: Advanced Settings
    components: Components
    customAnswers: Custom Answers
    description: Description
  tracing: Enabled Jaeger Tracing (limited)
  v1Warning: Please uninstall the current Istio version in the <code>istio-system</code> namespace before attempting to install this version.
keyValue:
  keyPlaceholder: e.g. foo
  protip: 'Paste lines of <em>key=value</em> or <em>key: value</em> into any key field for easy bulk entry'
  valuePlaceholder: e.g. bar
labels:
  addAnnotation: Add Annotation
  addLabel: Add Label
  addSetLabel: Add/Set Label
  addTag: Add Tag
  addTaint: Add Taint
  annotations:
    title: Annotations
  labels:
    title: Labels
landing:
  clusters:
    cores: |-
      {count, plural,
      =1 {core}
      other {cores}}
    cpuUsed: CPU Used
    explore: Explore
    explorer: Explorer
    kubernetesVersion: Kubernetes Version
    memoryUsed: Memory Used
    provider: Provider
    title: Clusters
  commercial:
    body: Learn about commercial support
    title: Commercial Support
  community:
    docs: Docs
    forums: Forums
    title: Community Support
  gettingStarted:
    body: Take a look at the the quick getting started guide. For Cluster Manager users, learn more about where you can find your favorite features in the Dashboard UI.
    title: Getting Started
  landingPrefs:
    body: You can change where you land when you login
    options:
      custom: 'Take me to cluster:'
      homePage: Take me to the home page
      lastVisited: Take me to the area I last visited
    title: You can change what you see when you login via preferences
    userPrefs: Preferences
  learnMore: Learn More
  seeWhatsNew: Learn more about the improvements and new capabilities in this version.
  support: Support
  welcomeToRancher: Welcome to {vendor}
  whatsNewLink: What's new in 2.6
legacy:
  alerts: Alerts
  apps: Apps
  catalogs: Catalogs
  cis-scans: CIS Scans
  configMaps: Config Maps
  configuration: Configuration
  globalDnsEntries: Global DNS Entries
  globalDnsProviders: Global DNS Providers
  istio: Istio
  logging: Logging
  monitoring: Monitoring
  notifiers: Notifiers
  pipelines: Pipelines
  project:
    label: Project
    select: Use the Project/Namespace filter at the top of the page to select a Project in order to see legacy Project features.
  psps: Pod Security Policies
  secrets: Secrets
locale:
  en-us: English
  none: (None)
  zh-hans: 简体中文
  zh-hant: 繁體中文
  zh-hant-tw: 台灣繁體
logging:
  awsElasticsearch:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    url: URL
  azurestorage:
    accessKey: Access Key from Secret
    container: Container
    path: Path
    storageAccount: Account from Secret
    storeAs: Store As
  cloudwatch:
    endpoint: Endpoint
    keyId: Key Id from Secret
    logGroupName: Log Group Name
    logStreamName: Log Stream Name
    region: Region
    secretKey: Secret Key from Secret
  clusterFlow:
    noOutputsBanner: There are no cluster outputs in the selected namespace.
  datadog:
    apiKey: API Key from Secret
    host: Host
    useCompression: Use Compression
    useSSL: Use SSL
  elasticsearch:
    caFile:
      label: CA File from Secret
    clientCert:
      label: Client Cert from Secret
      placeholder: Paste in the CA certificate
    clientKey:
      label: Client Key from Secret
      placeholder: Paste in the client key
    clientKeyPass: Client Key Pass from Secret
    host: Host
    indexName: Index Name
    password: Password from Secret
    port: Port
    scheme: Scheme
    sslVersion: SSL Version
    user: User
    verifySsl: Verify SSL
  file:
    path: Path
  flow:
    clusterOutputs:
      doesntExistTooltip: This cluster output doesn't exist
      label: Cluster Outputs
    filters:
      label: Filters
    matches:
      addExclude: Add Exclude Rule
      addSelect: Add Include Rule
      label: Matches
    outputs:
      doesntExistTooltip: This output doesn't exist
      label: Outputs
  forward:
    clientCertPath: Client Cert Path from Secret
    clientPrivateKeyPassphrase: Client Private Key Passphrase from Secret
    clientPrivateKeyPath: Client Private Key Path from Secret
    host: Host
    password: Password from Secret
    port: Port
    sharedKey: Shared Key from Secret
    username: Username from Secret
  gcs:
    bucket: Bucket
    credentialsJson: Credentials from Secret
    overwriteExistingPath: Overwrite Existing Path
    path: Path
    project: Project
  gelf:
    host: Host
    port: Port
    protocol: Protocol
    tls: Enable TLS
    tlsOptions:
      allCiphers: Allow any ciphers to be used
      clientCert: Client Cert
      clientKey: Client Cert Key
      noVerify: Skip TLS verification
      tlsVersion: TLS version
  install:
    default: /run/log/journal
    dockerRootDirectory: Docker Root Directory
    enableAdditionalLoggingSources: Enable enhanced cloud provider logging
    k3sContainerEngine: K3S Container Engine
    systemdLogPath: systemd Log Path
    tooltip: Some kubernetes distributions log to <code>journald</code>. In order to collect these logs the <code>systemdLogPath</code> needs to be defined. While the <code>/run/log/journal</code> directory is used by default, some Linux distributions do not default to this path.
    url: <a href="https://rancher.com/docs/rancher/v2.6/en/logging/helm-chart-options/" target="_blank" rel="noopener nofollow noreferrer">Learn more</a>
  kafka:
    brokers: Brokers
    defaultTopic: Default Topic
    password: Password from Secret
    saslOverSsl: SASL Over SSL
    scramMechanism: Scram Mechanism
    sslCaCert:
      label: CA Cert from Secret
      placeholder: Paste in the CA certificate
    sslClientCert:
      label: Cert from Secret
      placeholder: Paste in the client cert
    sslClientCertChain:
      label: Cert Chain from Secret
      placeholder: Paste in the client cert chain
    sslClientCertKey: Cert Key from Secret
    username: Username from Secret
  kinesisStream:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    streamName: Stream Name
  logdna:
    apiKey: API Key
    app: App
    hostname: Hostname
  logz:
    enableCompression: Enable Compression
    port: Port
    token: Api Token from Secret
    url: URL
  loki:
    caCert: CA Cert from Secret
    cert: Cert from Secret
    configureKubernetesLabels: Configure Kubernetes metadata in a Prometheus like format
    dropSingleKey: If a record only has 1 key, then just set the log line to the value and discard the key
    extractKubernetesLabels: Extract Kubernetes labels as Loki labels
    key: Key from Secret
    password: Password from Secret
    tenant: Tenant
    url: URL
    username: User from Secret
  newrelic:
    apiKey: API Key from Secret
    baseURI: Base URI
    licenseKey: License Key from Secret
  output:
    buffer:
      label: Output Buffer
    sections:
      access: Access
      certificate: Connection
      configuration: Configuration
      labels: Labels
      target: Target
    selectBanner: Select to configure an output
    selectOutputs: Select Outputs
  outputProviders:
    awsElasticsearch: Amazon Elasticsearch
    azurestorage: Azure Storage
    cloudwatch: Cloudwatch
    datadog: Datadog
    elasticsearch: Elasticsearch
    file: File
    forward: Fluentd
    gcs: GCS
    gelf: GELF
    kafka: Kafka
    kinesisStream: Kinesis Stream
    logdna: LogDNA
    logz: LogZ
    loki: Loki
    newrelic: New Relic
    s3: S3
    splunkHec: Splunk
    sumologic: SumoLogic
    syslog: Syslog
    unknown: Unknown
  overview:
    clusterLevel: Cluster-Level
    namespaceLevel: Namespace-Level
    poweredBy: Banzai Cloud
  provider: Provider
  s3:
    bucket: Bucket
    endpoint: Endpoint
    keyId: Key Id from Secret
    overwriteExistingPath: Overwrite Existing Path
    path: Path
    secretKey: Secret Key from Secret
  splunk:
    caFile: CA File from Secret
    caPath: CA Path from Secret
    clientCert: Client Cert from Secret
    clientKey: Client Key from Secret
    host: Host
    index: Index
    indexName: Index Name
    insecureSsl: Insecure SSL
    port: Port
    protocol: Protocol
    source: Source
    token: Token from Secret
  sumologic:
    endpoint: Endpoint from Secret
    sourceName: Source Name
  syslog:
    buffer:
      chunkLimitRecords: Chunk Limit chunkLimitRecords
      chunkLimitSize: Chunk Limit Size
      flushInterval: Flush Interval
      tags: Tags
      timekey: Timekey
      timekeyUseUTC: Timekey Use UTC
      timekeyWait: Timekey Wait
      title: Buffer
      totalLimitSize: Total Limit Size
    format:
      addNewLine: Add New Line
      messageKey: Message Key
      title: Format
      type: Type
    host: Host
    insecure: insecure
    port: Port
    transport: Transport
    trustedCaPath: CA Path from Secret
login:
  clientError: Invalid username or password. Please try again.
  error: An error occurred logging in. Please try again.
  howdy: Howdy!
  loggedIn: Logged in
  loggedOut: You have been logged out.
  loggingIn: Logging in...
  loginAgain: Log in again to continue.
  loginWithLocal: Log in with Local User
  loginWithProvider: Log in with {provider}
  password: Password
  remember:
    label: Remember Username
  serverError:
    authFailed: 'Logging in failed: Your account may not be authorized to log in.'
    authFailedCreds: 'Logging in failed: Check credentials, or your account may not be authorized to log in.'
    invalidSamlAttrs: Invalid saml attributes
    noResponse: No response received
    unknown: An unknown error occurred while attempting to login. Please contact your system administrator.
  useLocal: Use a local user
  useNonLocal: Use a non-local user
  useProvider: Use a {provider} user
  username: Username
  welcome: Welcome to {vendor}
longhorn:
  overview:
    linkedList:
      longhorn:
        description: Manage storage system via UI
        label: Longhorn
        na: Resource Unavailable
    subtitle: 'Powered By: <a href=''https://github.com/longhorn'' target=''_blank'' rel=''noopener nofollow noreferrer''>Longhorn</a>'
    title: Overview
manager:
  cloudCredentials:
    label: Cloud Credentials
  drivers:
    label: Drivers
  nodeTemplates:
    label: Node Templates
  rkeTemplates:
    label: RKE Templates
members:
  clusterMembers: Cluster Members
  clusterPermissions:
    createProjects: Create Projects
    custom:
      description: Choose individual roles for this user.
      label: Custom
    description: Controls what access users have to the Cluster
    label: Cluster Permissions
    manageClusterBackups: Manage Cluster Backups
    manageClusterCatalogs: Manage Cluster Catalogs
    manageClusterMembers: Manage Cluster Members
    manageNavlinks: Manage Navlinks
    manageNodes: Manage Nodes
    manageStorage: Manage Storage
    member:
      description: Members can manage the resources inside the Cluster but not change the Cluster itself.
      label: Member
    noDescription: User created - no description
    owner:
      description: Owners have full control over the Cluster and all resources inside it.
      label: Owner
    viewAllProjects: View All Projects
    viewClusterCatalogs: View Cluster Catalogs
    viewClusterMembers: View Cluster Members
    viewNodes: View Nodes
  createActionLabel: Add
membershipEditor:
  label: Members
  role: Role
  user: User
modalDownLoadFileComponent:
  container: Container
  filePath: File Path
  noSuchFile: File does not exist
  notice: Downloading files over 600MiB may cause your browser to crash.
  placeholder: Please enter the path of the file in the container
  serverError: An error occurred on the service break
  title: Container file download
  validateContainer: Please select a container
  validatePath: Please enter the path to the file you want to download.
##############################
# Model Properties
##############################
model:
  account:
    kind:
      admin: Admin
      agent: Agent
      project: Environment
      registeredAgent: Registered Agent
      service: Service
      user: User
  authConfig:
    description:
      cas: CAS
      ldap: LDAP
      oauth: OAuth
      oidc: OIDC
      saml: SAML
    name:
      keycloak: Keycloak (SAML)
      keycloakoidc: Keycloak (OIDC)
    provider:
      activedirectory: ActiveDirectory
      adfs: ADFS
      azuread: AzureAD
      cas: CAS
      freeipa: FreeIPA
      github: GitHub
      googleoauth: Google
      keycloak: Keycloak
      keycloakoidc: Keycloak
      ldap: LDAP
      local: Local
      multiple: Multiple
      oidc: OIDC
      okta: Okta
      openldap: OpenLDAP
      ping: Ping Identity
      shibboleth: Shibboleth
      system: System
  catalog.cattle.io.app:
    firstDeployed: First Deployed
    lastDeployed: Last Deployed
  cluster:
    name: Cluster Name
  ingress:
    displayKind: L7 Ingress
  machine:
    role:
      controlPlane: Control Plane
      etcd: etcd
      worker: Worker
  openldapconfig:
    domain:
      help: Only users below this base will be used.
      label: User Search Base
      placeholder: e.g. ou=Users,dc=mycompany,dc=com
    server:
      label: Hostname or IP Address
    serviceAccountPassword:
      label: Service Account Password
    serviceAccountUsername:
      label: Service Account Username
  projectMember:
    role:
      member: Member
      owner: Owner
      readonly: Read-Only
      restricted: Restricted
  service:
    displayKind:
      generic: Service
      loadBalancer: L4 Balancer
monitoring:
  accessModes:
    many: ReadWriteMany
    once: ReadWriteOnce
    readOnlyMany: ReadOnlyMany
  aggregateDefaultRoles:
    label: Aggregate to Default Kubernetes Roles
    tip: Adds labels to the ClusterRoles deployed by the Monitoring chart to <a target="_blank" rel="noopener nofollow noreferrer" href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles"> aggregate to the corresponding default k8s admin, edit, and view ClusterRoles.</a>
  alerting:
    config:
      label: Alert Manager Config
    enable:
      label: Deploy Alertmanager
    secrets:
      additional:
        info: Secrets should be mounted at <pre class='inline-block m-0'>/etc/alertmanager/secrets/</pre>
        label: Additional Secrets
      existing: Choose an existing config secret
      info: |
        <span class="text-bold">Create default config</span>: A Secret containing your Alertmanager Config will be created in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace on deploying this chart under the name <pre class='inline-block m-0'>alertmanager-rancher-monitoring-alertmanager</pre>. By default, this Secret will never be modified on an uninstall or upgrade of this chart. <br />
        Once you have deployed this chart, you should edit the Secret via the UI in order to add your custom notification configurations that will be used by Alertmanager to send alerts. <br /> <br />
        <span class="text-bold">Choose an existing config secret</span>: You must specify a Secret that exists in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace. If the namespace does not exist, you will not be able to select an existing secret.
      label: Alertmanager Secret
      new: Create default config
      radio:
        label: Config Secret
    templates:
      keyLabel: File Name
      label: Template Files
      valueLabel: YAML Template
    title: Configure Alertmanager
  alertmanagerConfig:
    auth:
      basicAuthPassword: Secret with Basic Auth Password
      basicAuthUsername: Secret with Basic Auth Username
      bearerTokenSecret: Bearer Token Secret
    deprecationWarning: The Route and Receiver resources are deprecated. Going forward, routes and receivers should not be managed as separate Kubernetes resources on this page. They should be configured as YAML fields in an AlertmanagerConfig resource.
    description: Routes and receivers for project alerting and cluster alerting are configured within AlertmanagerConfig resources.
    disabledReceiverButton: The receiver form is available after the AlertmanagerConfig is created
    email:
      password: Secret with Auth Password
      username: Auth Username
    empty: Alerts have not been configured for any accessible namespaces.
    getStarted: Get started by clicking Create to configure an alert.
    opsgenie:
      apiKey: Secret with API Key
    pagerDuty:
      routingKey: Secret with Routing Key
      serviceKey: Secret with Service Key
    receiverFormNames:
      create: Create Receiver in AlertmanagerConfig
      detail: Receiver in AlertmanagerConfig
      edit: Edit Receiver in AlertmanagerConfig
      editYaml: Edit AlertmanagerConfig
    receiverTooltip: This route will direct alerts to the selected receiver, which must be defined in the same AlertmanagerConfig.
    routeInfo: This form supports configuring one route that directs traffic to a receiver. Alerts can be directed to more receiver(s) by configuring child routes in YAML.
    slack:
      apiUrl: Secret with Slack Webhook URL
    webhook:
      url: URL
      urlSecret: URL Secret
      urlSecretTooltip: urlSecret takes precedence over url. One of urlSecret and url should be defined.
  clusterType:
    label: Cluster Type
    placeholder: Select cluster type
  createDefaultRoles:
    label: Create Default Monitoring Cluster Roles
    tip: Creates <code>monitoring-admin</code>, <code>monitoring-edit</code>, and <code>monitoring-view</code> ClusterRoles that can be assigned to users to provide permissions to CRDs installed by the Monitoring chart.
  etcdNodeDirectory:
    label: etcd Node Certificate Directory
    tooltip: For clusters that use RancherOS for the etcd nodes, this option should be set to <pre class='inline-block m-0'>/opt/rke/etc/kubernetes/ssl</pre>. Hybrid environments that require specifying multiple certificate directories (e.g. an etcd plane composed of both RancherOS and Ubuntu hosts) are not supported.
  grafana:
    storage:
      annotations: PVC Annotations
      className: Storage Class Name
      existingClaim: Use Existing Claim
      finalizers: PVC Finalizers
      label: Grafana Storage
      mode: Access Mode
      selector: Selector
      size: Size
      subpath: Use Subpath
      type: Persistent Storage Types
      types:
        existing: Enable With Existing PVC
        statefulset: Enable with StatefulSet Template
        template: Enable with PVC Template
      volumeMode: Volume Mode
      volumeName: Volume Name
    title: Configure Grafana
  hostNetwork:
    label: Use Host Network For Prometheus Operator
    tip: If you are using a managed Kubernetes cluster with custom CNI (e.g. Calico), you must enable this option to allow a managed control plane to contact the admission webhook exposed by Prometheus Operator to mutate or validate incoming PrometheusRules.
  installSteps:
    uninstallV1:
      promptDescription: <div class="mt-20 mb-20">You are attempting to uninstall V1 Monitoring. Please ensure you have read the migration steps.</div>
      stepSubtext: Uninstall Previous Monitoring
      stepTitle: Uninstall V1
      success1: V1 monitoring successfully uninstalled.
      success2: Press Next to continue
      warning1: V1 Monitoring is currently deployed. This needs to be uninstalled before V2 monitoring can be installed.
      warning2: <a target="blank" href="{docsBase}/monitoring-alerting/guides/migrating/" target='_blank' rel='noopener nofollow'>Learn more</a> about the migration steps to V2 Monitoring.
  monitors: Monitors
  overview:
    alertsList:
      ends:
        label: Ends At
      label: Active Alerts
      message:
        label: Message
      severity:
        label: Severity
      start:
        label: Starts At
    linkedList:
      alertManager:
        description: Active Alerts
        label: Alertmanager
      grafana:
        description: Metrics Dashboards
        label: Grafana
      na: Resource Unavailable
      prometheusPromQl:
        description: PromQL Graph
        label: Prometheus Graph
      prometheusRules:
        description: Configured Rules
        label: PrometheusRules
      prometheusTargets:
        description: Configured Targets
        label: Prometheus Targets
    subtitle: 'Powered By: <a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener noreferrer nofollow">Prometheus</a>'
    title: Dashboard
  projectMonitoring:
    detail:
      error: 'Unable to fetch Dashboard values with status: '
    list:
      banner: Project Monitoring Configuration is stored in ProjectHelmChart resources
      empty:
        canCreate: Get started by clicking Create to add monitoring to a project
        cannotCreate: Contact the admin to add project monitoring
        message: Project Monitoring has not been configured for any projects
  projectMonitors: Project Monitoring
  prometheus:
    config:
      adminApi: Admin API
      evaluation: Evaluation Interval
      ignoreNamespaceSelectors:
        help: Ignoring Namespace Selectors allows Cluster Admins to limit teams from monitoring resources outside of namespaces they have permissions to but can break the functionality of Apps that rely on setting up Monitors that scrape targets across multiple namespaces, such as Istio.
        label: Namespace Selectors
        radio:
          enforced: 'Use: Monitors can access resources based on namespaces that match the namespace selector field'
          ignored: 'Ignore: Monitors can only access resources in the namespace they are deployed in'
      limits:
        cpu: CPU Limit
        memory: Memory Limit
      requests:
        cpu: Requested CPU
        memory: Requested Memory
      resourceLimits: Resource Limits
      retention: Retention
      retentionSize: Retention Size
      scrape: Scrape Interval
    storage:
      className: Storage Class Name
      label: Persistent Storage for Prometheus
      mode: Access Mode
      selector: Selector
      selectorWarning: If you are using a dynamic provisioner (e.g. Longhorn), no Selectors should be specified since a PVC with a non-empty selector can't have a PV dynamically provisioned for it.
      size: Size
      volumeMode: Volume Mode
      volumeName: Volume Name
    title: Configure Prometheus
    warningInstalled: |
      Warning: Prometheus Operators are currently deployed. Deploying multiple Prometheus Operators onto one cluster is not currently supported. Please remove all other Prometheus Operator deployments from this cluster before trying to install this chart.
      If you are migrating from an older version of {vendor} with Monitoring enabled, please disable Monitoring on this cluster completely before attempting to install this chart.
  receiver:
    addReceiver: Add Receiver
    fields:
      name: Name
    tls:
      caFilePath:
        label: CA File Path
        placeholder: e.g. ./ca-file.csr
      certFilePath:
        label: Cert File Path
        placeholder: e.g. ./cert-file.crt
      keyFilePath:
        label: Key File Path
        placeholder: e.g. ./key-file.pfx
      label: SSL
      secretsBanner: The file paths below must be referenced in <pre class="inline-block m-0 p-0 vertical-middle">alertmanager.alertmanagerSpec.secrets</pre> when deploying the Monitoring chart. For more information see our <a href="{docsBase}/monitoring-alerting/" target="_blank" rel="noopener noreferrer nofollow">documentation</a>.
  route:
    fields:
      groupBy: Group By
      groupInterval: Group Interval
      groupWait: Group Wait
      receiver: Receiver
      repeatInterval: Repeat Interval
    label: Route
  routesAndReceivers: Routes and Receivers (Deprecated)
  tabs:
    alerting: Alerting
    general: General
    grafana: Grafana
    projectMetrics: Project Metrics
    prometheus: Prometheus
    thanos: Thanos
  thanos:
    sidecar:
      label: Enable Thanos Sidecar
    title: Configure Thanos
    tls:
      label: Enable TLS
  v1Warning: Monitoring is currently deployed from Cluster Manager. If you are migrating from an older version of {vendor} with monitoring enabled, please disable monitoring in Cluster Manager before attempting to install the new {vendor} Monitoring chart in Cluster Explorer.
  volume:
    modes:
      block: Block
      file: Filesystem
monitoringReceiver:
  addButton: Add {type}
  auth:
    authType: Auth Type
    basicAuth:
      label: Basic Auth
    bearerToken:
      label: Bearer Token
      placeholder: e.g. secret-token
    bearerTokenFile:
      label: Bearer Token File
      placeholder: e.g. ./user_token
    label: Auth
    none:
      label: None
    password: Password
    username: Username
  custom:
    info: The YAML provided here will be directly appended to your receiver within the Alertmanager Config Secret.
    label: Custom
    title: Custom Config
  email:
    label: Email
    title: Email Config
  opsgenie:
    label: Opsgenie
    title: Opsgenie Config
  pagerduty:
    info: You can find additional info on creating an Integration Key for PagerDuty <a href='https://www.pagerduty.com/docs/guides/prometheus-integration-guide/' target='_blank' rel='noopener nofollow' class='flex-right'>here</a>.
    label: PagerDuty
    title: PagerDuty Config
  pandariaWebhook:
    add:
      aliyunSMS: Aliyun SMS
      dingTalk: Ding Talk
      msTeams: MS Teams
      serviceNow: Service Now
    aliyunSMS:
      accessKeyIdLabel: Access Key
      accessKeyIdPlaceholder: Aliyun Access Key
      accessKeySecretLabel: Access Key Secret
      accessKeySecretPlaceholder: Aliyun Access Key Secret
      phoenNumberButton: Add Phone Number
      phoneNumberLabel: Phone Number
      phoneNumberPlaceholder: e.g. 112314
      signatureNameLabel: Signature Name
      signatureNamePlaceholder: e.g. mysign
      templateCodeLabel: Template Code
      templateCodePlaceholder: e.g. mytemplate
    banner: To use Ding Talk, AliCloud SMS or MS Teams you will need to have <pre class="inline-block m-0 p-0 vertical-middle">pandaria-alerting-drivers</pre> installed first.
    dingTalk:
      secretLabel: Secret
      secretPlaceholder: Only for webhook with sign enabled
    label: Pandaria Webhook
  shared:
    proxyUrl:
      label: Proxy URL
      placeholder: e.g. http://my-proxy/
    sendResolved:
      label: Enable send resolved alerts
  slack:
    info: You can find additional info on creating Incoming Webhooks for Slack <a href='https://rancher.slack.com/apps/A0F7XDUAZ-incoming-webhooks' target='_blank' rel='noopener noreferrer nofollow'>here</a> .
    label: Slack
    title: Slack Config
  tls:
    ca: Secret with CA
    cert: Secret with Client Cert
    key: Secret with Client Key
    serverName: Server Name
    serverNameTooltip: Used to verify the hostname for the targets.
  webhook:
    add:
      alibabaCloudSms: SMS
      generic: Generic
      msTeams: MS Teams
      selectWebhookType: Select Webhook Type
    banner: To use MS Teams or SMS you will need to have at least one instance of <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> installed first.
    label: Webhook
    modifyNamespace: If <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> default values were changed, please update the url below in the format http://&lt;new_service_name&gt;.&lt;new_namespace&gt.svc.&lt;port&gt/&lt;path&gt
    title: Webhook Config
    urlTooltip: For some webhooks this a url that points to the service DNS
monitoringRoute:
  groups:
    addGroupByLabel: Labels to Group Alerts By
    label: Group By
  info: This is the top-level Route used by Alertmanager as the default destination for any Alerts that do not match any other Routes. This Route must exist and cannot be deleted.
  interval:
    label: Group Interval
  matching:
    addMatcher: Add Matcher
    info: The root route has to match everything so matching cannot be configured.
    label: Match
    matchType: Match Type
    name: Name
    nameTooltip: Label to match
    value: Value
    valueTooltip: Label value to match
  receiver:
    add: Add Receiver
    addMatch: Add match
    label: Receiver
    oneOrMoreLabel: One or More Receivers
    type: Receiver Type
  regex:
    label: Match Regex
  repeatInterval:
    label: Repeat Interval
  wait:
    label: Group Wait
moveModal:
  description: 'You are moving the following namespaces:'
  moveButtonLabel: Move
  targetProject: Target Project
  title: Move to a new project?
nameNsDescription:
  description:
    label: Description
    placeholder: Any text you want that better describes this resource
  name:
    label: Name
    placeholder: A unique name
  namespace:
    label: Namespace
    placeholder: ""
  workspace:
    label: Workspace
    placeholder:
namespace:
  containerResourceLimit: Container Resource Limit
  disableAutoInjection: Disable Istio Auto Injection
  enableAutoInjection: Enable Istio Auto Injection
  move: Move
  project:
    label: Project
  resourceQuotas: Resource Quotas
  resourceStates:
    error: Error
    info: Transitioning
    paused:
      longDescription: Deployment is paused. Pausing stops the controller from deploying revisions.
      shortDescription: Deployment is paused
      stateName: Inactive
    success: Active
    unknown: Unknown
    warning: Warning
  resources: Resources
  total: Total
  workloads: Workloads
namespaceFilter:
  more: +{more}
  noMatchingOptions: No matching options
  selected:
    label: |-
      {total, plural,
      one {1 item selected}
      other {{total} items selected}
      }
namespaceList:
  addLabel: Add Namespace
  selectLabel: Namespace
nav:
  apps: Apps
  auditLog: Audit Log
  backToRancher: Cluster Manager
  categories:
    configuration: Configuration
    explore: Explore Cluster
    legacy: Legacy Apps
    multiCluster: Global Apps
  cisF5:
    controllers: F5 Ingress
    tls: TLS
  clusterTools: Cluster Tools
  editConnectMode: Connect Mode
  failWhale:
    reload: Reload
    separator: or
  globalMonitoring:
    dashboard: Dashboard
    label: Global Monitoring
  group:
    RKE1Configuration: RKE1 Configuration
    admission: Admission
    advanced: Advanced
    apps: Apps
    cluster: Cluster
    clusterProvisioning: Cluster Provisioning
    core: Core
    globalMonitoring: Global Monitoring
    imageRepo: Image Repo
    inUse: More Resources
    monitoring: Monitoring
    rbac: RBAC
    serviceDiscovery: Service Discovery
    starred: Starred
    storage: Storage
    workload: Workload
  header:
    restoreCards: Restore hidden cards
    setLoginPage: Set as login page
  home: Home
  imageRepo:
    config: Configuration
    logs: Logs
    #registries: Registries
    projects: Image Management
  import: Import YAML
  kubeconfig:
    copy: Copy KubeConfig to Clipboard
    download: Download KubeConfig
    options: KubeConfig Options
  manageUI: Cluster Manager UI
  ns:
    all: All Namespaces
    clusterLevel: Only Cluster Resources
    namespace: '{name}'
    namespaced: Only Namespaced Resources
    orphan: Not in a Project
    project: 'Project: {name}'
    system: Only System Namespaces
    user: Only User Namespaces
  quotas: Quotas
  resourceSearch:
    label: Resource Search
    placeholder: Type to search for a resource...
    toolTip: Resource Search {key}
  restoreSnapshot: Restore Snapshot
  rotateCertificates: Rotate Certificates
  rotateEncryptionKeys: Rotate Encryption Keys
  saveAsRKETemplate: Save as RKE Template
  search:
    noResults: No matching clusters
    placeholder: Type to search clusters
  shell: Kubectl Shell
  shellShortcut: Kubectl Shell {key}
  support: |-
    {hasSupport, select,
      true {Support}
      other {Get Support}
    }
  takeSnapshot: Take Snapshot
  tools:
    cisF5: F5 CIS
    tab: tools
  userMenu:
    accountAndKeys: Account & API Keys
    logOut: Log Out
    preferences: Preferences
  vlanSubnet:
    label: Flat Network
navLink:
  iframe:
    failedToLoad: Page loading failed
    reload: Reload
  label:
    label: Display name
    placeholder: Text displayed for the link
  name:
    label: Name
    placeholder: e.g. foo-bar
  tabs:
    group:
      description:
        label: Link description
      group:
        label: Group name
        placeholder: Please enter a group name
        tooltip: Assign link to a group
      iconSrc:
        label: Add image
      label: Group
      sideLabel:
        label: Link Label
    link:
      label: Link type
      toService:
        path:
          label: Path
          placeholder: e.g. proxy/?orgId=1
        port:
          label: Port
          placeholder: e.g. 80
        scheme:
          label: Scheme
          placeholder: e.g. http
        service:
          label: Service (namespace/name)
          placeholder: e.g. cattle-system/rancher-webhook
      toURL:
        label: Destination URL
        placeholder: e.g. https://rancher.com
      type:
        label: Link type
        service: Link to service
        url: Link to URL
    target:
      label: Window target
      namedValue:
        label: Window name
      option:
        blank: New window
        iframe: Use iframe
        named: Custom named window
        self: Replace window
networkpolicy:
  config:
    label: Configuration
  egress:
    enable: Configure egress rules to restrict outgoing traffic
    label: Egress Rules
    portHint: Outgoing traffic is only allowed to connect to the configured ports
    ruleHint: Outgoing traffic is only allowed to the configured targets
    ruleLabel: Targets
  ingress:
    enable: Configure ingress rules to restrict incoming traffic
    label: Ingress Rules
    portHint: Incoming traffic is only allowed to connect to the configured ports
    ruleHint: Incoming traffic is only allowed from the configured sources
    ruleLabel: Sources
  labelsAnnotations:
    label: Labels & Annotations
  rules:
    addPort: Add allowed port
    egress:
      add: Add allowed traffic target
    ingress:
      add: Add allowed traffic source
    ipBlock:
      addExcept: Add exception
      cidr:
        label: CIDR
        placeholder: e.g. 1.1.1.0/24
      exceptions: Exceptions
      invalidCidr: Invalid CIDR
      invalidExceptionCidrs: 'Invalid Exceptions: '
      label: IP block
    namespaceSelector:
      label: Namespace Selector
    podSelector:
      label: Pod Selector
    ports:
      label: Allowed ports
      port:
        label: Port
        placeholder: e.g. 8080
      protocol: Protocol
    ruleLabel: Rule {index}
    type: Rule type
  selectors:
    hint: The NetworkPolicy is applied to the selected Pods
    label: Selectors
    matchingNamespaces:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} namespaces}
          =1 {Matches 1 of {total, number} namespaces: "{sample}"}
          other {Matches {matched, number} of {total, number} existing namespaces, including "{sample}"}
        }
    matchingPods:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} pods}
          =1 {Matches 1 of {total, number} pods: "{sample}"}
          other {Matches {matched, number} of {total, number} existing pods, including "{sample}"}
        }
neuvector:
  overview:
    linkedList:
      neuvector:
        description: Full Lifecycle Container Security
        label: NeuVector
        na: Resource Unavailable
    subtitle: 'Powered by: <a href=''https://github.com/neuvector'' target=''_blank'' rel=''noopener nofollow noreferrer''>NeuVector</a>'
    title: Overview
node:
  actions:
    downloadNodeConfig: Download Keys
    downloadSSHKey: Download SSH Key
    forceDelete: Force Delete
    scaleDown: Scale Down
  detail:
    detailTop:
      containerRuntime: Container Runtime
      externalIP: External IP
      internalIP: Internal IP
      os: OS
      version: Version
    glance:
      consumptionGauge:
        amount: '{used} of {total} {unit}'
        cpu: CPU
        memory: MEMORY
        pods: PODS
        used: Used
      diskPressure: Disk Pressure
      kubelet: kubelet
      memoryPressure: Memory Pressure
      pidPressure: PID Pressure
    tab:
      conditions: Conditions
      images: Images
      info:
        key:
          architecture: Architecture
          bootID: Boot ID
          containerRuntimeVersion: Container Runtime Version
          kernelVersion: Kernel Version
          kubeProxyVersion: Kube Proxy Version
          kubeletVersion: Kubelet Version
          machineID: Machine ID
          operatingSystem: Operating System
          osImage: Image
          systemUUID: System UUID
        label: Info
      metrics: Metrics
      pods: Pods
      taints: Taints
  list:
    noNodes: This pool is empty
    nodeTaint: Taints
    pool: Pool
    poolDescription:
      noLocation: No Location
      noSize: No Size
    scaleDown: Scale Pool Down
    scaleUp: Scale Pool Up
notifications:
  header: Custom notifications
  loginError:
    header: Login Failed Banner
    messageLabel: Text to display
    showCheckboxLabel: Show custom login error
  menuLabel: Custom Notifications
persistentVolume:
  awsElasticBlockStore:
    label: Amazon EBS Disk
    volumeId:
      label: Volume ID
      placeholder: e.g. volume1
  azureDisk:
    cachingMode:
      label: Caching Mode
      none: None
      readOnly: Read Only
      readWrite: Read Write
    diskName:
      label: Disk Name
      placeholder: e.g. kubernetes-pvc
    diskURI:
      label: Disk URI
      placeholder: e.g. https://example.com/disk
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    kind:
      dedicated: Dedicated
      label: Kind
      managed: Managed
      shared: Shared
    label: Azure Disk
    readOnly:
      label: Read Only
  azureFile:
    label: Azure Filesystem
    shareName:
      label: Share Name
      placeholder: e.g. abc
  capacity:
    label: Capacity
  cephfs:
    label: Ceph Filesystem (Unsupported)
    path:
      label: Path
      placeholder: e.g. /var
    secretFile:
      label: Secret File
      placeholder: e.g. secret
    user:
      label: User
      placeholder: e.g. root
  cinder:
    label: Openstack Cinder Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. vol
  csi:
    controllerExpandSecretName:
      label: Controller Expand Secret Name
      placeholder: e.g. secret
    controllerExpandSecretNamespace:
      label: Controller Expand Secret Namespace
      placeholder: e.g. default
    controllerPublishSecretName:
      label: Controller Publish Secret Name
      placeholder: e.g. secret
    controllerPublishSecretNamespace:
      label: Controller Publish Secret Namespace
      placeholder: e.g. default
    driver:
      label: Driver
      placeholder: e.g. driver.longhorn.io
    label: CSI (Unsupported)
    nodePublishSecretName:
      label: Node Publish Secret Name
      placeholder: e.g. secret
    nodePublishSecretNamespace:
      label: Node Publish Secret Namespace
      placeholder: e.g. default
    nodeStageSecretName:
      label: Node Stage Secret Name
      placeholder: e.g. secret
    nodeStageSecretNamespace:
      label: Node Stage Secret Namespace
      placeholder: e.g. default
    volumeAttributes:
      add: Add Volume Attribute
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
  customize:
    accessModes:
      label: Access Modes
      readOnlyMany: Many Nodes Read-Only
      readWriteMany: Many Nodes Read-Write
      readWriteOnce: Single Node Read-Write
    affinity:
      addLabel: Add Node Selector
      label: Node Selectors
    assignToStorageClass:
      label: Assign to Storage Class
    label: Customize
    mountOptions:
      addLabel: Add Option
      label: Mount Options
  fc:
    label: Fibre Channel (Unsupported)
    lun:
      label: Lun
      placeholder: e.g. 2
    targetWWNS:
      add: Add Target WWN
    wwids:
      add: Add WWID
  flexVolume:
    driver:
      label: Driver
      placeholder: e.g. driver
    label: Flex Volume (Unsupported)
    options:
      add: Add Option
  flocker:
    datasetName:
      label: Dataset Name
      placeholder: e.g. dataset
    datasetUUID:
      label: Dataset UUID
      placeholder: e.g. uuid
    label: Flocker (Unsupported)
  gcePersistentDisk:
    label: Google Persistent Disk
    persistentDiskName:
      label: Persistent Disk Name
      placeholder: e.g. abc
  glusterfs:
    endpoints:
      label: Endpoints
      placeholder: e.g. glusterfs-cluster
    label: Gluster Volume (Unsupported)
    path:
      label: Path
      placeholder: e.g. kube-vol
  hostPath:
    label: HostPath
    mustBe:
      anything: 'Anything: do not check the target path'
      directory: A directory, or create if it does not exist
      existingBlock: An existing block device
      existingCharacter: An existing character device
      existingDirectory: An existing directory
      existingFile: An existing file
      existingSocket: An existing socket
      file: A file, or create if it does not exist
      label: The Path on the Node must be
    pathOnTheNode:
      label: Path on the Node
      placeholder: /mnt/disks/ssd1
  iscsi:
    chapAuthDiscovery:
      label: Chap Auth Discovery
    chapAuthSession:
      label: Chap Auth Session
    initiatorName:
      label: Initiator Name
      placeholder: iqn.1994-05.com.redhat:1df7a24fcb92
    iqn:
      label: IQN
      placeholder: iqn.2001-04.com.example:storage.kube.sys1.xyz
    iscsiInterface:
      label: iSCSI Interface
      placeholder: e.g. interface
    label: iSCSI Target (Unsupported)
    lun:
      label: Lun
      placeholder: e.g. 2
    portals:
      add: Add Portal
    targetPortal:
      label: Target Portal
      placeholder: e.g. portal
  local:
    label: Local
    path:
      label: Path
      placeholder: e.g. /mnt/disks/ssd1
  longhorn:
    label: Longhorn
    options:
      addLabel: Add
      label: Options
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
  nfs:
    label: NFS Share
    path:
      label: Path
      placeholder: e.g. /var
    server:
      label: Server
      placeholder: e.g. 10.244.1.4
  photonPersistentDisk:
    label: Photon Volume (Unsupported)
    pdId:
      label: PD ID
      placeholder: e.g. abc
  plugin:
    label: Volume Plugin
  pluginConfiguration:
    label: Plugin configuration
  portworxVolume:
    label: Portworx Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. abc
  quobyte:
    group:
      label: Group
      placeholder: e.g. abc
    label: Quobyte Volume (Unsupported)
    registry:
      label: Registry
      placeholder: e.g. abc
    user:
      label: User
      placeholder: e.g. root
    volume:
      label: Volume
      placeholder: e.g. vol
  rbd:
    image:
      label: Image
      placeholder: e.g. image
    keyRing:
      label: Key Ring
      placeholder: e.g. /etc/ceph/keyring
    label: Ceph RBD (Unsupported)
    pool:
      label: Pool
      placeholder: e.g. rbd
    user:
      label: User
      placeholder: e.g. root
  scaleIO:
    gateway:
      label: Gateway
      placeholder: e.g. https://localhost:443/api
    label: ScaleIO Volume (Unsupported)
    protectionDomain:
      label: Protection Domain
      placeholder: e.g. pd01
    sslEnabled:
      label: SSL Enabled
    storageMode:
      label: Storage Mode
      placeholder: e.g. ThinProvisioned
    storagePool:
      label: Storage Pool
      placeholder: e.g. sp01
    system:
      label: System
      placeholder: e.g. scaleio
    volumeName:
      label: Volume Name
      placeholder: e.g. vol-0
  shared:
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    monitors:
      add: Add Monitor
    partition:
      label: Partition
      placeholder: e.g. 1; 0 for entire device
    readOnly:
      label: Read Only
    secretName:
      label: Secret Name
      placeholder: e.g. secret
    secretNamespace:
      label: Secret Namespace
      placeholder: e.g. default
  storageos:
    label: StorageOS (Unsupported)
    volumeName:
      label: Volume Name
      placeholder: e.g. vol
    volumeNamespace:
      label: Volume Namespace
      placeholder: e.g. default
  vsphereVolume:
    label: VMWare vSphere Volume
    storagePolicyId:
      label: Storage Policy ID
      placeholder: e.g. sp1
    storagePolicyName:
      label: Storage Policy Name
      placeholder: e.g. sp
    volumePath:
      label: Volume Path
      placeholder: e.g. /
persistentVolumeClaim:
  accessModes: Access Modes
  accessModesOptions:
    manyNodeR: Many-Node Read-Only
    manyNodeRW: Many-Node Read/Write
    singleNodeRW: Single-Node Read/Write
  capacity: Capacity
  customize:
    accessModes:
      readOnlyMany: Many Nodes Read-Only
      readWriteMany: Many Nodes Read-Write
      readWriteOnce: Single Node Read-Write
    label: Customize
  name: Persistent Volume Claim Name
  source:
    label: Source
    options:
      existing: Use an existing Persistent Volume
      new: Use a Storage Class to provision a new Persistent Volume
  status:
    label: Status
  storageClass: Storage Class
  useDefault: Use the default class
  volumeClaim:
    label: Volume Claim
    persistentVolume: Persistent Volume
    requestStorage: Request Storage
    storageClass: Storage Class
  volumeName: Persistent Volume Name
  volumes: Persistent Volumes
podAffinity:
  addLabel: Add Pod Selector
prefs:
  advanced: Advanced
  clusterToShow:
    label: Number of clusters to show in side menu
    value: '{count, number}'
  dateFormat:
    label: Date Format
  dev:
    label: Enable Developer Tools & Features
  formatting: Formatting
  helm:
    "false": Show Releases Only
    label: Helm Charts
    "true": Include Prerelease Versions
  hideDesc:
    label: Hide All Type Description Boxes
  keymap:
    emacs: Emacs
    label: YAML Editor Key Mapping
    sublime: Normal human
    vim: Vim
  landing:
    ember: Cluster Manager
    label: Login Landing Page
    vue: Cluster Explorer
  perPage:
    label: Table Rows per Page
    value: '{count, number}'
  theme:
    auto: Auto
    autoDetail: Auto uses OS preference if available, or dark from {pm} to {am}
    dark: Dark
    label: Theme
    light: Light
  timeFormat:
    label: Time Format
  title: Preferences
principal:
  error: Unable to fetch principal info
  loading: Loading&hellip;
  loginName: Username
  name: Name
  type: Type
probe:
  checkInterval:
    label: Check Interval
    placeholder: 'Default: 10'
  command:
    label: Command to run
    placeholder: e.g. cat /tmp/health
  failureThreshold:
    label: Failure Threshold
    placeholder: 'Default: 3'
  httpGet:
    headers:
      label: Request Headers
    path:
      label: Request Path
      placeholder: e.g. /healthz
    port:
      label: Check Port
      placeholder: e.g. 80
      placeholderDeux: e.g. 25
  initialDelay:
    label: Initial Delay
    placeholder: 'Default: 0'
  successThreshold:
    label: Success Threshold
    placeholder: 'Default: 1'
  timeout:
    label: Timeout
    placeholder: 'Default: 3'
  type:
    label: Type
    placeholder: Select a check type
product:
  apps: Apps
  auth: Users & Authentication
  backup: Rancher Backups
  cis: CIS Benchmark
  clusterManagement: Cluster Management
  ecm: Cluster Manager
  explorer: Cluster Explorer
  fleet: Continuous Delivery
  gatekeeper: OPA Gatekeeper
  harvester: Harvester
  harvesterManager: Virtualization Management
  istio: Istio
  logging: Logging
  longhorn: Longhorn
  manager: Cluster Management
  mcapps: Multi-cluster Apps
  monitoring: Monitoring
  rancher: Rancher
  settings: Global Settings
project:
  containerDefaultResourceLimit: Container Default Resource Limit
  haveOneOwner: There must be at least one member with the Owner role.
  members:
    label: Members
  membersEditOnly: Only permissions equal to or below those of the current user can be applied
  psp:
    current: '{value} (Current)'
    default: Cluster Default
    label: Pod Security Policy
  resourceQuotas: Resource Quotas
  vmDefaultResourceLimit: VM Default Resource Limit
projectMembers:
  project:
    label: Project
  projectPermissions:
    configmapsManage: Manage Config Maps
    configmapsView: View Config Maps
    createNs: Create Namespaces
    custom:
      description: Choose individual roles for this user.
      label: Custom
    description: Controls what access users have to the Project
    ingressManage: Manage Ingress
    ingressView: View Ingress
    label: Project Permissions
    member:
      description: Members can manage the resources inside the Project but not change the Project itself.
      label: Member
    monitoringUiView: View Monitoring
    noDescription: User created - no description
    owner:
      description: Owners have full control over the Project and all resources inside it.
      label: Owner
    persistentvolumeclaimsManage: Manage Volumes
    persistentvolumeclaimsView: View Volumes
    projectcatalogsManage: Manage Project Catalogs
    projectcatalogsView: View Project Catalogs
    projectroletemplatebindingsManage: Manage Project Members
    projectroletemplatebindingsView: View Project Members
    readOnly:
      description: Members can only view the resources inside the Project but not change the resources.
      label: Read Only
    searchForMember: Search for a member to provide project access
    secretsManage: Manage Secrets
    secretsView: View Secrets
    serviceaccountsManage: Manage Service Accounts
    serviceaccountsView: View Service Accounts
    servicesManage: Manage Services
    servicesView: View Services
    workloadsManage: Manage Workloads
    workloadsView: View Workloads
projectNamespaces:
  createNamespace: Create Namespace
  createProject: Create Project
  label: Projects/Namespaces
  noNamespaces: There are no namespaces defined.
  noProjectNoNamespaces: All namespaces are in a project
prometheusRule:
  alertingRules:
    addLabel: Add Alert
    annotations:
      description:
        input: Description Annotation Value
        label: Description
      label: Annotations
      message:
        input: Message Annotation Value
        label: Message
      runbook:
        input: Runbook URL Annotation Value
        label: Runbook URL
      summary:
        input: Summary Annotation Value
        label: Summary
    bannerText: When firing alerts, the annotations and labels will be passed to the configured AlertManagers to allow them to construct the notification that will be sent to any configured Receivers.
    for:
      label: Wait to fire for
      placeholder: "60"
    label: Alerting Rules
    labels:
      label: Labels
      severity:
        choices:
          critical: critical
          label: Severity Label Value
          none: none
          warning: warning
        label: Severity
    name: Alert Name
    removeAlert: Remove Alert
  groups:
    add: Add Rule Group
    groupInterval:
      label: Override Group Interval
      placeholder: "60"
    groupRowLabel: Rule Group {index}
    label: Rule Groups
    name: Group Name
    none: Please add at least one rule group that contains at least one alerting or one recording rule.
    removeGroup: Remove Group
    responseStrategy:
      label: Partial Response Strategy
  promQL:
    label: PromQL Expression
  recordingRules:
    addLabel: Add Record
    label: Recording Rules
    labels: Labels
    name: Time Series Name
    removeRecord: Remove Record
promptForceRemove:
  confirmName: 'Enter in the pool name below to confirm:'
  forceDelete: Force Delete
  modalTitle: Are you sure?
  removeWarning: There was an issue with deleting underlying infrastructure. If you proceed with this action, the Machine <b>{nameToMatch}</b> will be deleted from Rancher only. It's highly recommended to manually delete any referenced infrastructure.
promptRemove:
  andOthers: |-
    {count, plural,
    =0 {.}
    =1 { and <b>one other</b>.}
    other { and <b>{count} others</b>.}
    }
  attemptingToRemove: You are attempting to delete the {type}
  confirmName: 'Enter <b>{nameToMatch}</b> below to confirm:'
  protip: 'Tip: Hold the {alternateLabel} key while clicking delete to bypass this confirmation'
  title: Are you sure?
promptRemoveApp:
  removeCrd: Delete the CRD associated with this app
promptRestore:
  date: Date
  fromS3: Restore from S3
  label: Snapshot
  name: Name
  notification:
    message: Restoring snapshot { selectedSnapshot } has started...
    title: Restore Snapshot
  placeholder: Select a snapshot to restore
  title: Restore Snapshot
promptRollback:
  attemptingToRollBack: Attempting to roll back workload...
  currentLabel: (Current)
  differences: Differences
  dropdownTitle: Roll Back to Revision
  modalTitle: Roll Back {workloadName}
  multipleWorkloadError: Only one workload can be rolled back at a time.
  placeholder: Choose a Revision...
  revisionOption: Revision {revisionNumber}, created {revisionAge} {units} ago {currentLabel}
  singleRevisionBanner: There are no revisions to roll back to.
promptRotateEncryptionKey:
  description: The last backup {name} was performed on {date}
  error: No backup found
  title: Rotate Encryption Keys
  warning: Before proceeding, ensure a successful ETCD backup of the cluster has been completed.
promptSaveAsRKETemplate:
  description: Create a new RKE cluster template and initial revision from the current cluster configuration.
  name: Cluster Template Name
  title: Convert {cluster} to new RKE Template
  warning: This will modify the cluster, setting it up to use the newly created cluster template and revision. This can not be undone.
promptScaleMachineDown:
  attemptingToRemove: You are attempting to delete {count} {type}
  retainedMachine1: At least one Machine must exist for roles Control Plane and Etcd.
  retainedMachine2: <b>{ name }</b> will remain
rancherAlertingDrivers:
  msTeams: Enable Microsoft Teams
  selectOne: You must select at least one of the options below.
  sms: Enable SMS
rbac:
  displayRole:
    fleetworkspace-admin: Admin
    fleetworkspace-member: Member
    fleetworkspace-readonly: Read-Only
  globalRoles:
    assignOnlyRole: This role is already assigned
    role:
      admin:
        description: Administrators have full control over the entire installation and all resources in all clusters.
        label: Administrator
      authn-manage:
        description: Allows the user to enable, configure, and disable all Authentication provider settings.
        label: Configure Authentication
      base:
        label: Login Access
      catalogs-manage:
        description: Allows the user to add, edit, and remove management.cattle.io based catalogs resources.
        label: Legacy Configure Catalogs
      catalogs-use:
        description: Allows the user to see and deploy Templates from the Catalog.  Standard Users have this permission by default.
        label: Use Catalogs
      clusters-create:
        description: Allows the user to create new clusters and become the owner of them.  Standard Users have this permission by default.
        label: Create new Clusters
      clusters-manage:
        description: Allows the user to manage all clusters, including ones they are not a member of.
        label: Manage all Clusters
      clusterscans-manage:
        description: Allows the user to launch new and manage CIS cluster scans.
        label: Manage CIS Cluster Scans
      clustertemplaterevisions-create:
        label: Create RKE Template Revisions
      clustertemplates-create:
        description: Allows the user to create new RKE cluster templates and become the owner of them.
        label: Create new RKE Cluster Templates
      features-manage:
        description: Allows the user to enable and disable custom features via feature flag settings.
        label: Configure Feature Flags
      kontainerdrivers-manage:
        description: Allows the user to create new cluster drivers and become the owner of them.
        label: Create new Cluster Drivers
      nodedrivers-manage:
        description: Allows the user to enable, configure, and remove all Node Driver settings.
        label: Configure Node Drivers
      nodetemplates-manage:
        description: Allows the user to define, edit, and remove Node Templates.
        label: Manage Node Templates
      nodetemplates-use:
        description: Allows the user to deploy new Nodes using any existing Node Templates.
        label: Use Node Templates
      podsecuritypolicytemplates-manage:
        description: Allows the user to define, edit, and remove PSPs.
        label: Manage Pod Security Policies (PSPs)
      read-only-pandaria:
        description: A read-only administrator can access all resources in all downstream clusters, but cannot access the local cluster
        label: Read-Only Administrator
      restricted-admin:
        description: Restricted Admins have full control over all resources in all downstream clusters but no access to the local cluster.
        label: Restricted Administrator
      roles-manage:
        description: Allows the user to define, edit, and remove Role definitions.
        label: Manage Roles
      settings-manage:
        description: Allows the user to manage {vendor} Settings.
        label: Manage Settings
      user:
        description: Standard Users can create new clusters and manage clusters and projects they have been granted access to.
        label: Standard User
      user-base:
        description: User-Base users have login-access only.
        label: User-Base
      users-manage:
        description: Allows the user to create, remove, and set passwords for all Users.
        label: Manage Users
      view-rancher-metrics:
        description: Allows the user to view Metrics through the API.
        label: View {vendor} Metrics
    types:
      builtin:
        description: Additional roles to define more fine-grain permissions model.
        label: Built-in
      custom:
        description: Roles not created by {vendor}.
        label: Custom
      global:
        description: |-
          Controls what access the {isUser, select,
          true {user}
          false {group}} has to administer the overall {appName} installation.
        label: Global Permissions
    unknownRole:
      description: No description provided
  members:
    label: Members
  roleBinding:
    add: Add Member
    noData: There are no members associated with this resource.
    role:
      label: Role
    user:
      label: User
  roletemplate:
    label: Roles
    locked:
      label: Locked
      no: No
      yes: 'Yes: New bindings are not allowed to use this role'
    newUserDefault:
      no: No
      tooltip: This does not affect any bindings to the role that already exist.
    subtypes:
      CLUSTER:
        createButton: Create Cluster Role
        defaultLabel: Cluster Creator Default
        label: Cluster
        yes: 'Yes: Default role for new cluster creation'
      GLOBAL:
        createButton: Create Global Role
        defaultLabel: New User Default
        label: Global
        yes: 'Yes: Default role for new users'
      NAMESPACE:
        createButton: Create Project/Namespaces Role
        defaultLabel: Project Creator Default
        label: Project/Namespaces
        yes: 'Yes: Default role for new project creation'
      RBAC_CLUSTER_ROLE:
        label: Cluster Role
      RBAC_ROLE:
        label: Role
      noContext:
        label: No Context
    tabs:
      grantResources:
        deprecatedLabel: (deprecated)
        label: Grant Resources
        noApiGroupClusterScope: Core K8s API, Cluster Scoped
        noApiGroupNamespaceScope: Core K8s API, Namespaced
        resourceOptionInfo: The resource options are not a complete list of every resource available in every Rancher-managed Kubernetes cluster. Resources and API groups may need to be manually entered in advanced use cases.
        tableHeaders:
          apiGroups: API Groups
          nonResourceUrls: Non-Resource URLs
          resources: Resource
          verbs: Verbs
registryConfig:
  addLabel: Add Registry
  header: Registry Authentication
  toolTip: When an image needs to be pulled from the given registry hostname, this information will be used to verify the identity of the registry and authenticate to it.
registryMirror:
  addLabel: Add Mirror
  header: Mirrors
  toolTip: Mirrors can be used to redirect requests for images from one registry to actually come from a list of endpoints you specify instead.  For example you could point docker.io to always talk to your internal registry and instead of ever going to the actual DockerHub on the internet.
resourceDetail:
  detailTop:
    annotations: Annotations
    created: Created
    deleted: Deleted
    description: Description
    endpoints: Endpoints
    hideAnnotations: |-
      {annotations, plural,
      =1 {Hide 1 annotation}
      other {Hide {annotations} annotations}}
    hideLabels: Hide system labels
    labels: Labels
    name: Name
    namespaces: Namespaces
    ownerReferences: |-
      {count, plural,
      =1 {Owner}
      other {Owners}}
    showAnnotations: |-
      {annotations, plural,
      =1 {Show 1 annotation}
      other {Show {annotations} annotations}}
    showLabels: Show all labels
  header:
    clone: Clone from {subtype} {name}
    create: Create {subtype}
    edit: '{subtype} {name}'
    import: Import {subtype}
    stage: Stage from {subtype} {name}
    view: '{subtype} {name}'
  masthead:
    age: Age
    config: Config
    defaultBannerMessage:
      error: This resource is currently in an error state, but there isn't a detailed message available.
      transitioning: This resource is currently in a transitioning state, but there isn't a detailed message available.
    detail: Detail
    managedWarning: |-
      This {type} is managed by {hasName, select,
        no {a {managedBy} app}
        yes {the {managedBy} app {appName}}}; changes made here will likely be overwritten the next time {managedBy} runs.
    namespace: Namespace
    project: Project
    restartCount: Pod Restarts
    sensitive:
      hide: Hide Sensitive Values
      show: Show Sensitive Values
    workspace: Workspace
    yaml: YAML
resourceList:
  head:
    create: Create
    createFromYaml: Create from YAML
    createResource: Create {resourceName}
resourceQuota:
  add:
    label: Add Resource
  configMaps: Config Maps
  headers:
    limit: Limit
    namespaceDefaultLimit: Namespace Default Limit
    projectLimit: Project Limit
    projectResourceAvailability: Project Resource Availability
    resourceType: Resource Type
  helpText: Configure how much of the resources the namespace as a whole can consume.
  helpTextDetail: The amount of resources the namespace as a whole can consume.
  label: Resource Quotas
  limitsCpu: CPU Limit
  limitsMemory: Memory Limit
  namespaceDefaultLimit:
    cpuPlaceholder: e.g. 500
    label: Namespace Default Limit
    memoryPlaceholder: e.g. 1024
    storagePlaceholder: e.g. 10
    unitlessPlaceholder: e.g. 10
  namespaceLimit:
    label: Limit
  persistentVolumeClaims: Persistent Volume Claims
  pods: Pods
  projectLimit:
    cpuPlaceholder: e.g. 2000
    label: Project Limit
    memoryPlaceholder: e.g. 2048
    storagePlaceholder: e.g. 50
    unitlessPlaceholder: e.g. 50
  replicationControllers: Replication Controllers
  requestsCpu: CPU Reservation
  requestsGpuCount: GPU Count
  requestsGpuMemory: GPU Memory
  requestsMemory: Memory Reservation
  requestsStorage: Storage Reservation
  requestsStorageClassPVC: Storage Class PVC
  requestsStorageClassStorage: Storage Class Storage
  resourceType:
    label: Resource Type
  secrets: Secrets
  services: Services
  servicesLoadBalancers: Services Load Balancers
  servicesNodePorts: Service Node Ports
resourceTable:
  groupBy:
    namespace: Group by Namespace
    node: Group by Node
    none: Flat List
    project: Group by Project
  groupLabel:
    cluster: <span>Cluster:</span> {name}
    machinePool: <span>Pool:</span> {name}
    namespace: <span>Namespace:</span> {name}
    node: <span>Node:</span> {name}
    nodePool: <span>Pool:</span> {name} ({count})
    notInAMachinePool: Not In A Deployment
    notInANamespace: Not Namespaced
    notInANodePool: Not in a Pool
    notInAProject: Not in a Project
    notInAWorkspace: Not in a Workspace
    project: <span>Project:</span> {name}
    workspace: <span>Workspace:</span> {name}
resourceTabs:
  conditions:
    tab: Conditions
  events:
    tab: Recent Events
  related:
    from: Referred To By
    tab: Related Resources
    to: Refers To
resourceYaml:
  buttons:
    continue: Continue Editing
    diff: Show Diff
    edit: Edit YAML
    hideDiff: Hide Diff
    split: Split
    unified: Unified
  errors:
    namespaceRequired: This resource is namespaced, so a namespace must be provided.
secret:
  authentication: Authentication
  basic:
    password: Password
    username: Username
  certificate:
    certificate: Certificate
    certificatePlaceholder: Paste in the CA certificate, starting with -----BEGIN CERTIFICATE----
    cn: Domain Name
    expires: Expires
    issuer: Issuer
    plusMore: + {n} more
    privateKey: Private Key
    privateKeyPlaceholder: Paste in the private key, typically starting with -----BEGIN RSA PRIVATE KEY-----
  data: Data
  initials:
    bootstrap.kubernetes.io/token: Boot
    fleet.cattle.io/cluster-registration-values: F
    helm.sh/release.v1: Helm
    istio.io/key-and-cert: Ist
    kubernetes.io/basic-auth: HTTP
    kubernetes.io/dockercfg: R
    kubernetes.io/dockerconfigjson: R
    kubernetes.io/service-account-token: SAT
    kubernetes.io/ssh-auth: SSH
    kubernetes.io/tls: TLS
    opaque: O
    provisioning.cattle.io/cloud-credential: CC
    s3: S3
  registry:
    address: Registry
    domainName: Registry Domain Name
    password: Password
    username: Username
  relatedWorkloads: Related Workloads
  serviceAcct:
    ca: CA Certificate
    token: Token
  ssh:
    keys: Keys
    private: Private Key
    privatePlaceholder: Paste in your private key
    public: Public Key
    publicPlaceholder: Paste in your public key
  type: Type
  typeDescriptions:
    Opaque:
      description: Default type of Secret using key-value pairs
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#opaque-secrets
    kubernetes.io/basic-auth:
      description: Authentication with a username and password
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#basic-authentication-secret
    kubernetes.io/dockerconfigjson:
      description: Authenticated registry for pulling container images
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#docker-config-secrets
    kubernetes.io/ssh-auth:
      description: Public key and private key for SSH authentication
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#ssh-authentication-secrets
    kubernetes.io/tls:
      description: Store a certificate and key for TLS
      docLink: https://kubernetes.io/docs/concepts/configuration/secret/#tls-secrets
  types:
    bootstrap.kubernetes.io/token: Bootstrap Token
    fleet.cattle.io/cluster-registration-values: Fleet Cluster
    helm.sh/release.v1: Helm Release
    istio.io/key-and-cert: Istio Certificate
    kubernetes.io/basic-auth: HTTP Basic Auth
    kubernetes.io/dockercfg: Registry
    kubernetes.io/dockerconfigjson: Registry
    kubernetes.io/service-account-token: Svc Acct Token
    kubernetes.io/ssh-auth: SSH Key
    kubernetes.io/tls: TLS Certificate
    opaque: Opaque
    provisioning.cattle.io/cloud-credential: Cloud Credential
    rke.cattle.io/auth-config: RKE Auth Config
selectOrCreateAuthSecret:
  basic:
    password: Password
    username: Username
  chooseExisting: 'Choose an existing secret:'
  createBasic: Create a HTTP Basic Auth Secret
  createS3: Create a S3-Compatible Auth Secret
  createSsh: Create a SSH Key Secret
  label: Authentication
  namespaceGroup: 'Namespace: {name}'
  options:
    aws: AWS/S3
    basic: HTTP Basic Auth
    custom: Secret Name
    none: None
    ssh: SSH Key
  s3:
    accessKey: Access Key
    secretKey: Secret Key
  ssh:
    privateKey: Private Key
    publicKey: Public Key
serverUpgrade:
  message: The page reloaded because the version of {vendor} running on your server changed.
  title: '{vendor} Server Changed'
serviceAccount:
  automount: Automount Service Account Token
  imagePullSecrets: Image Pull Secrets
  tabs:
    serviceAccount:
      label: Service Account
servicePorts:
  header:
    label: Port Rules
  rules:
    listening:
      label: Listening Port
      placeholder: e.g. 8080
    name:
      label: Port Name
      placeholder: e.g. myport
    node:
      label: Node Port
      placeholder: e.g. 30000
    protocol:
      label: Protocol
    target:
      label: Target Port
      placeholder: e.g. 80 or http
serviceTypes:
  clusterip: Cluster IP
  externalname: External Name
  headless: Headless
  loadbalancer: Load Balancer
  nodeport: Node Port
servicesPage:
  affinity:
    actionLabels:
      clientIp: ClientIP
      none: There is no session affinity configured.
    helpText: Map connections to a consistent target based on their source IP.
    label: Session Affinity
    timeout:
      label: Session Sticky Time
      placeholder: e.g. 10800
  anyNode: Any Node
  externalName:
    define: External Name
    helpText: External Name is intended to specify a canonical DNS name. This is a required field. To hardcode an IP address, use a Headless service.
    input:
      label: DNS Name
    label: External Name
    placeholder: e.g. my.database.example.com
  ips:
    clusterIpHelpText: The Cluster IP address must be within the CIDR range configured for the API server.
    define: Service Ports
    external:
      label: External IPs
      placeholder: e.g. 1.1.1.1
      protip: List of IP addresses for which nodes in the cluster will also accept traffic for this service.
    input:
      label: Cluster IP
      placeholder: e.g. 10.43.xxx.xxx
    label: IP Addresses
    loadBalancerIp:
      helpText: If you specify a loadBalancerIP but your cloud provider does not support the feature, the loadBalancerIP field that you set is ignored.
      label: Load Balancer IP
      placeholder: e.g. 192.0.xxx.xxx
  labelsAnnotations:
    label: Labels & Annotations
  pods:
    label: Pods
  ports:
    label: Ports
  selectors:
    helpText: ""
    label: Selectors
    matchingPods:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} pods. If no selector is created, manual endpoints must be made.}
          =1 {Matches 1 of {total, number} pods: "{sample}"}
          other {Matches {matched, number} of {total, number} existing pods, including "{sample}"}
        }
  serviceTypes:
    clusterIp:
      abbrv: IP
      description: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. This is the default type.
      label: Cluster IP
    externalName:
      abbrv: EN
      description: Maps the service to the contents of the `externalName` field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up.
      label: External Name
    headless:
      abbrv: H
      description: Neither a cluster IP or load balancer is defined. These are used to interface with other service discovery mechanisms outside of Kubernetes implementation. A cluster IP is not allocated and kube-proxy does not handle these services.
      label: Headless
    loadBalancer:
      abbrv: LB
      description: Exposes the service externally using a cloud provider's load balancer.
      label: Load Balancer
    nodePort:
      abbrv: NP
      description: Exposes the service on each node's IP at a static port (the `NodePort`). You'll be able to contact this type of service, from outside the cluster, by requesting `&lt;NodeIP&gt;:&lt;NodePort&gt;`.
      label: Node Port
  typeOpts:
    label: Service Type
setup:
  confirmPassword: Confirm New Password
  currentPassword: Bootstrap Password
  defaultPassword:
    dockerPrefix: 'For a "docker run" installation:'
    dockerPs: 'Find your container ID with <code>docker ps</code>, then run:'
    dockerSuffix: ""
    helmPrefix: 'For a Helm installation, run:'
    helmSuffix: ""
    intro: It looks like this is your first time visiting {vendor}; if you pre-set your own bootstrap password, enter it here.  Otherwise a random one has been generated for you.  To find it:<br/><br/>
  eula: I agree to the <a href="https://rancher.com/eula" target="_blank" rel="noopener noreferrer nofollow">terms and conditions</a> for using {name}.
  newPassword: New Password
  newUserSetPassword: The first order of business is to set a strong password. We suggest using this random one generated just for you, but enter your own if you like.
  serverUrl:
    label: Server URL
    skip: Skip
    tip: What URL should be used for this {vendor} installation? All the nodes in your clusters will need to be able to reach this.
  setPassword: The first order of business is to set a strong password for the default <code>{username}</code> user. We suggest using this random one generated just for you, but enter your own if you like.
  telemetry: Allow collection of <a href="{docsBase}/faq/telemetry/" target="_blank" rel="noopener noreferrer nofollow">anonymous statistics</a> to help us improve {vendor}.
  useManual: Set a specific password to use
  useRandom: Use a randomly generated password
  welcome: Welcome to {vendor}!
sortableTable:
  actionAvailability:
    selected: '{actionable} selected'
    some: Affects {actionable} of {total}
  noActions: No actions available
  noData: There are no rows which match your search query.
  noRows: There are no rows to show.
  paging:
    generic: |-
      {pages, plural,
      =0 {No Items}
      =1 {{count} {count, plural, =1 {Item} other {Items}}}
      other {{from} - {to} of {count} Items}}
    resource: |-
      {pages, plural,
      =0 {No {pluralLabel}}
      =1 {{count} {count, plural, =1 {{singularLabel}} other {{pluralLabel}}}}
      other {{from} - {to} of {count} {pluralLabel}}}
  search: Filter
storageClass:
  actions:
    resetDefault: Reset Default
    setAsDefault: Set as Default
  aws-ebs:
    availabilityZone:
      automatic: 'Automatic: Zones the cluster has a node in'
      label: Availability Zone
      manual: 'Manual: Choose specific zones'
      placeholder: us-east-1d, us-east-1c
    encryption:
      disabled: Disabled
      enabled: Enabled
      label: Encryption
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    keyId:
      automatic: 'Automatic: Generate a key'
      label: KMS Key ID for Encryption
      manual: 'Manual: Use a specific key (full ARN)'
    title: Amazon EBS Disk
    volumeType:
      gp2: GP2 - General Purpose SSD
      io1: IO1 - Provisioned IOPS SSD
      label: Volume Type
      provisionedIops:
        label: Provisioned IOPS
        suffix: per second, per GB
      sc1: SC1 - Cold-Storage HDD
      st1: ST1 - Throughput-Optimized HDD
  azure-disk:
    kind:
      dedicated: Dedicated (unmanaged disk)
      label: Kind
      managed: Managed
      shared: Shared (unmanaged disk)
    storageAccountType:
      label: Storage Account Type
      placeholder: e.g. Standard_LRS
    title: Azure Disk
  azure-file:
    location:
      label: Location
      placeholder: e.g. eastus
    skuName:
      label: Sku Name
      placeholder: e.g. Standard_LRS
    storageAccount:
      label: Storage Account
      placeholder: e.g. azure_storage_account_name
    title: Azure File
  cinder:
    availabilityZone:
      automatic: 'Automatic: Zones the cluster has a node in'
      label: Availability Zone
      manual:
        label: 'Manual: Choose specific zones'
        placeholder: e.g. nova
    title: Openstack Cinder Volume (Unsupported)
    volumeType:
      label: Volume Type
      placeholder: e.g. fast
  custom:
    addLabel: Add Parameter
  customize:
    allowVolumeExpansion:
      disabled: Disabled
      enabled: Enabled
      label: Allow Volume Expansion
    label: Customize
    mountOptions:
      addLabel: Add Option
      label: Mount Options
    reclaimPolicy:
      delete: Delete volumes and underlying device when volume claim is deleted
      label: Reclaim Policy
      retain: Retain the volume for manual cleanup
    volumeBindingMode:
      label: Volume Binding Mode
      later: Bind and provision a persistent volume once a Pod using the PersistentVolumeClaim is created
      now: Bind and provision a persistent volume once the PersistentVolumeClaim is created
  gce-pd:
    availabilityZone:
      automatic: 'Automatic: Zones the cluster has a node in'
      label: Availability Zone
      manual: 'Manual: Choose specific zones'
      placeholder: us-east-1d, us-east-1c
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    replicationType:
      label: Replication Type
      regional: Regional
      zonal: Zonal
    title: Google Persistent Disk
    volumeType:
      label: Volume Type
      ssd: SSD
      standard: Standard
  glusterfs:
    clusterId:
      label: Cluster ID
      placeholder: e.g. 630372ccdc720a92c681fb928f27b53f
    gidMax:
      label: GID MAX
      placeholder: e.g. 50000
    gidMin:
      label: GID MIN
      placeholder: e.g. 40000
    restUrl:
      label: REST URL
      placeholder: e.g. http://127.0.0.1:8081
    restUser:
      label: REST User
      placeholder: e.g. admin
    restUserKey:
      label: REST User Key
      placeholder: e.g. password
    secretName:
      label: Secret Name
      placeholder: e.g. heketi-secret
    secretNamespace:
      label: Secret Namespace
      placeholder: e.g. default
    title: Gluster Volume (Unsupported)
    volumeType:
      label: Volume Type
      placeholder: e.g. replicate:3
  longhorn:
    addLabel: Add Parameter
    title: Longhorn
  no-provisioner:
    title: Local Storage (Unsupported)
  parameters:
    label: Parameters
  portworx-volume:
    aggregationLevel:
      label: Aggregation Level
      placeholder: e.g. 0
    blockSize:
      label: Block Size
      placeholder: e.g. 32
    ephemeral:
      label: Ephemeral
      placeholder: e.g. true
    filesystem:
      label: Filesystem
      placeholder: e.g. ext4
    ioPriority:
      label: I/O Priority
      placeholder: e.g. low
    repl:
      label: Repl
      placeholder: e.g.1; 0 for entire device
    snapshotsInterval:
      label: Snapshots Interval
      placeholder: e.g. 70
    title: Portworx Volume (Unsupported)
  quobyte:
    adminSecretName:
      label: Admin Secret Name
      placeholder: e.g. quobyte-admin-secret
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. kube-system
    group:
      label: Group
      placeholder: e.g. root
    quobyteApiServer:
      label: Quobyte API Server
      placeholder: e.g. http://138.68.74.142:7860
    quobyteConfig:
      label: Quobyte Config
      placeholder: e.g. BASE
    quobyteTenant:
      label: Quobyte Tenant
      placeholder: e.g. DEFAULT
    registry:
      label: Registry
      placeholder: e.g. 138.68.74.142:7861
    title: Quobyte Volume (Unsupported)
    user:
      label: User
      placeholder: e.g. root
  rbd:
    adminId:
      label: Admin ID
      placeholder: e.g. kube
    adminSecret:
      label: Admin Secret
      placeholder: e.g. Secret
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. kube-system
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    imageFeatures:
      label: Image Features
      placeholder: e.g. layering
    imageFormat:
      label: Image Format
      placeholder: e.g. 2
    monitors:
      label: Monitors
      placeholder: e.g. 10.16.153.105:6789
    pool:
      label: Pool
      placeholder: e.g. kube
    title: Ceph RBD (Unsupported)
    userId:
      label: User ID
      placeholder: e.g. kube
    userSecretName:
      label: User Secret Name
      placeholder: e.g. ceph-secret-user
    userSecretNamespace:
      label: User Secret Namespace
      placeholder: e.g. default
  scaleio:
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. xfs
    gateway:
      label: Gateway
      placeholder: e.g. https://192.168.99.200:443/api
    protectionDomain:
      label: Protection Domain
      placeholder: e.g. pd0
    readOnly:
      label: Read Only
    secretRef:
      label: Secret Ref
      placeholder: e.g. sio-secret
    storageMode:
      label: StorageMode
      thick: Thick Provisioned
      thin: Thin Provisioned
    storagePool:
      label: Storage Pool
      placeholder: e.g. sp1
    system:
      label: System
      placeholder: e.g. scaleio
    title: ScaleIO Volume (Unsupported)
  storageos:
    adminSecretName:
      label: Admin Secret Name
      placeholder: e.g. storageos-secret
    adminSecretNamespace:
      label: Admin Secret Namespace
      placeholder: e.g. default
    description:
      label: Description
      placeholder: e.g. Kubernetes volume
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    pool:
      label: Pool
      placeholder: e.g. default
    title: StorageOS (Unsupported)
  vsphere-volume:
    cacheReservation:
      label: Cache Reservation
      placeholder: e.g. 20
    datastore:
      label: Datastore
      placeholder: e.g. VSANDatastore
    diskFormat:
      eagerzeroedthick: Eager Zeroed Thick
      label: Disk Format
      thin: Thin
      zeroedthick: Zeroed Thick
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext3
    hostFailuresToTolerate:
      label: Host Failures To Tolerate
      placeholder: e.g. 2
    storagePolicyName:
      label: Storage Policy Name
      placeholder: e.g. gold
    title: VMWare vSphere Volume
suffix:
  cores: Cores
  cpus: CPUs
  gb: GB
  gpus: GPUs
  ib: iB
  mib: MiB
  milliCpus: milli CPUs
  percent: '%'
  revisions: |-
    {count, plural,
      =1 { Revision }
      other { Revisions }
    }
  sec: Sec
  seconds: |-
    {count, plural,
      =1 { Second }
      other { Seconds }
    }
  times: |-
    {count, plural,
      =1 { Time }
      other { Times }
    }
##############################
### Support Page
##############################
support:
  community:
    learnMore: Find out more about SUSE Rancher Support
    linksTitle: Community Support
    pricing: Contact us for pricing
    title: SUSE Rancher provides world-class support
  promos:
    four:
      text: Take advantage of our certified compatibility with a wide range of Kubernetes providers, operating systems, and open source software.
      title: Innovate with Freedom
    one:
      text: We provide tightly defined SLAs, and offer round the clock support options.
      title: 24x7 Support
    three:
      text: We focus on uncovering the root cause of any issue, whether it is related to Rancher Labs products, Kubernetes, Docker or your underlying infrastructure.
      title: Troubleshooting
    two:
      text: Run SUSE Rancher products with confidence, knowing that the developers who built them are available to quickly resolve issues.
      title: Issue Resolution
  subscription:
    addLabel: 'Please enter a valid Subscription ID:'
    addSubscription: Add a Subscription ID
    addTitle: Add your SUSE Subscription ID
    haveSupport: Already have support?
    removeBody: 'Note: This will not affect your subscription.'
    removeSubscription: Remove your Subscription ID
    removeTitle: Remove your ID?
  suse:
    access:
      action: SUSE Customer Center
      text: Login to SUSE Customer Center to access support for your subscription
      title: Get Support
    editBrand: Customize UI Theme
    title: Great News - You're covered
tableHeaders:
  accessKey: Access Key
  address: Address
  age: Age
  apiGroup: API Groups
  apikey: API Key
  attachedVM: Attached VM
  authRoles:
    clusterDefault: Cluster Creator Default
    globalDefault: New User Default
    projectDefault: Project Creator Default
  backupTarget: Backup Target
  branch: Branch
  builtIn: Built In
  builtin: Built-In
  bundleDeploymentsReady: Deployments
  bundlesReady: Bundles Ready
  chart: Chart
  clusterCreatorDefault: Cluster Creator Default
  clusterFlow: Cluster Flow
  clusterGroups: Cluster Groups
  clusterOutput: Cluster Output
  clusters: Clusters
  clustersReady: Clusters Ready
  commit: Commit
  condition: Condition
  cpu: CPU
  currentReplicas: Current Replicas
  customVerbs: Custom Verbs
  data: Data
  date: Date
  default: Default
  defaultVersion: Default version
  description: Description
  destination: Target
  diskState: Disk State
  download: Download
  effect: Effect
  endpoints: Endpoints
  expires: Expires
  fingerprint: Fingerprint
  fleetBundleType: Type
  flow: Flow
  gitRepos: Git Repos
  groupName: Group Name
  groupRoleNames: Group Role Names
  health: Health
  host: Host
  hostIp: Host IP
  hpaReference: Workload
  id: ID
  image: Image
  imageSize: Size
  ingressDefaultBackend: Default
  ingressTarget: Target
  internalExternalIp: External/Internal IP
  ipAddress: IP Address
  jobs: Jobs
  key: Key
  keys: Data
  lastSeen: Last Seen
  lastUpdated: Last Updated
  loggingOutputProviders: Provider
  machineNodeName: Node
  machines: Machines
  manual: Manual
  matches: Matches
  maxKubernetesVersion: Max Kubernetes Version
  maxReplicas: Maximum Replicas
  memory: Memory
  message: Message
  minKubernetesVersion: Min Kubernetes Version
  minReplicas: Minimum Replicas
  name: Name
  nameDisplay: Display Name
  nameUnlinked: Name
  namespace: Namespace
  namespaceName: Name
  namespaceNameUnlinked: Name
  networkType: Type
  networkVlan: Vlan ID
  node: Node
  nodeName: Name
  nodePort: Node Port
  nodesReady: Nodes Ready
  object: Object
  operatingSystem: OS
  output: Output
  p95: 95%tile
  persistentVolumeClaim: Persistent Volume Claim
  persistentVolumeSource: Source
  phase: Phase
  podImages: Image
  podRestarts: Restarts
  pods: Pods
  port: Port
  progress: Progress
  project: Project
  protocol: Protocol
  provider: Provider
  providers: Providers
  publicPorts: Public Ports
  ram: RAM
  rbac:
    create: Create
    delete: Delete
    get: Get
    list: List
    patch: Patch
    update: Update
    watch: Watch
  ready: Ready
  readyToUse: Ready To Use
  reason: Reason
  receiverTypes: Receiver Types
  receivers: Receivers
  reclaimPolicy: Reclaim Policy
  registrationNamespace: Registration Namespace
  replicas: Replicas
  repo: Repo
  repoName: Repository Name
  reposReady: Repos Ready
  repositories: Repositories
  reqRate: Req Rate
  resource: Resource
  resources: Resources
  resourcesReady: Resources Ready
  restart: Restart Required
  restarts: Restarts
  role: Role
  roles: Roles
  routeConnectivity: Route Connectivity
  routes: Routes
  scale: Scale
  scope: Scope
  selector: Selector
  simpleName: Name
  simpleScale: Scale
  simpleType: Type
  size: Size
  started: Started
  state: State
  status: Status
  storage: Storage Size
  storage_class_provisioner: Provisioner
  subType: Kind
  subject: Subject
  success: Success
  summary: Summary
  taints: Taints
  target: Target
  targetKind: Target Type
  targetPort: Target
  targetVm: Target VM
  type: Type
  updated: Updated
  upgrade: Upgradable
  url: URL
  userDisplayName: Display Name
  userId: ID
  userStatus: Status
  username: Local Username
  value: Value
  version: Version
  weight: Weight
target:
  router:
    label: Router
    placeholder: Select a router
  service:
    label: Service
    placeholder: Select a service
  title: Target
  version:
    label: Version
    placeholder: Select a version
typeDescription:
  catalog.cattle.io.app: An installed application is a Helm 3 chart that was installed either via our charts or through the Helm CLI.
  catalog.cattle.io.clusterrepo: A chart repository is a Helm repository or {vendor} git based application catalog. It provides the list of available charts in the cluster.
  catalog.cattle.io.clusterrepo.local: ' A chart repository is a Helm repository or {vendor} git based application catalog. It provides the list of available charts in the cluster. Cluster Templates are deployed via Helm charts.'
  catalog.cattle.io.operation: An operation is the list of recent Helm operations that have been applied to the cluster.
  # Map of
  # type: Description to be shown on the top of list view describing the type.
  #       Should fit on one line.
  #       If you link to anything external, it MUST have
  #       target="_blank" rel="noopener noreferrer nofollow"
  chart: All charts have at least one version that is installable on clusters with Linux and Windows nodes unless otherwise indicated.
  cis.cattle.io.clusterscan: A scan is created to trigger a CIS scan on the cluster based on the defined profile. A report is created after the scan is completed.
  cis.cattle.io.clusterscanbenchmark: A benchmark version is the name of benchmark to run using kube-bench as well as the valid configuration parameters for that benchmark.
  cis.cattle.io.clusterscanprofile: A profile is the configuration for the CIS scan, which is the benchmark versions to use and any specific tests to skip in that benchmark.
  cis.cattle.io.clusterscanreport: A report is the result of a CIS scan of the cluster.
  cluster.x-k8s.io.machine: A Machine encapsulates the configuration of a Kubernetes Node. Use this view to see what happens after updating a cluster.
  cluster.x-k8s.io.machinedeployment: A Machine Deployment orchestrates deployments via templates over a collection of Machine Sets (similar to a Deployment). Use this view to see what happens after updating a cluster.
  cluster.x-k8s.io.machineset: A Machine Set ensures the desired number of Machine resources are up and running at all times (similar to a ReplicaSet). Use this view to see what happens after updating a cluster.
  group.principal: Assigning global roles to a group only works with external auth providers that support groups. Local authorization does not support groups.
  harvesterhci.io.management.cluster: Virtualization Management is in Tech Preview.
  logging.banzaicloud.io.clusterflow: Logs from the cluster will be collected and logged to the selected Cluster Output.
  logging.banzaicloud.io.clusteroutput: A cluster output defines which logging providers that logs can be sent to and is only effective when deployed in the namespace that the logging operator is in.
  logging.banzaicloud.io.flow: A flow defines which logs to collect and filter as well as which output to send the logs. The flow is a namespaced resource, which means logs will only be collected from the namespace that the flow is deployed in.
  logging.banzaicloud.io.output: An output defines which logging providers that logs can be sent to. The output needs to be in the same namespace as the flow that is using it.
  management.cattle.io.feature: Feature Flags allow certain {vendor} features to be toggled on and off.  Features that are off by default should be considered experimental functionality.
  monitoring.coreos.com.alertmanager: An alert manager is deployment whose configuration will be specified by a secret in the same namespace, which determines which alerts should go to which receiver.
  monitoring.coreos.com.podmonitor: A pod monitor defines the group of pods that Prometheus will scrape for metrics. The common way is to use service monitors, but pod monitors allow you to handle any situation where a service monitor wouldn't work.
  monitoring.coreos.com.prometheus: A Prometheus server is a Prometheus deployment whose scrape configuration and rules are determined by selected ServiceMonitors, PodMonitors, and PrometheusRules and whose alerts will be sent to all selected Alertmanagers with the custom resource's configuration.
  monitoring.coreos.com.prometheusrule: A Prometheus Rule resource defines both recording and/or alert rules. A recording rule can pre-compute values and save the results. Alerting rules allow you to define conditions on when to send notifications to AlertManager.
  monitoring.coreos.com.servicemonitor: A service monitor defines the group of services and the endpoints that Prometheus will scrape for metrics. This is the most common way to define metrics collection.
  node: The base Kubernetes Node resource represents a virtual or physical machine which hosts deployments. To manage the machine lifecycle, if available, go to Cluster Management.
  resources.cattle.io.backup: A backup is created to perform one-time backups or schedule recurring backups based on a ResourceSet.
  resources.cattle.io.resourceset: A resource set defines which CRDs and resources to store in the backup.
  resources.cattle.io.restore: A restore is created to trigger a restore to the cluster based on a backup file.
typeLabel:
  catalog.cattle.io.app: |-
    {count, plural,
      one { Installed App }
      other { Installed Apps }
    }
  catalog.cattle.io.clusterrepo: |-
    {count, plural,
      one { Repository }
      other { Repositories }
    }
  catalog.cattle.io.operation: |-
    {count, plural,
      one { Recent Operation }
      other { Recent Operations }
    }
  catalog.cattle.io.repo: |-
    {count, plural,
      one { Namespaced Repo }
      other { Namespaced Repos }
    }
  chartinstallaction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  chartupgradeaction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  cis.cattle.io.clusterscan: |-
    {count, plural,
      one { Scan }
      other { Scans }
    }
  cis.cattle.io.clusterscanbenchmark: |-
    {count, plural,
      one { Benchmark Version }
      other { Benchmark Versions }
    }
  cis.cattle.io.clusterscanprofile: |-
    {count, plural,
      one { Profile }
      other { Profiles }
    }
  cloudcredential: |-
    {count, plural,
      one { Cloud Credential }
      other { Cloud Credentials }
    }
  cluster.x-k8s.io.cluster: |-
    {count, plural,
      one { CAPI Cluster }
      other { CAPI Clusters }
    }
  endpoints: |-
    {count, plural,
      one { Endpoint }
      other { Endpoints }
    }
  fleet.cattle.io.bundle: |-
    {count, plural,
      one { Bundle }
      other { Bundles }
    }
  fleet.cattle.io.cluster: |-
    {count, plural,
      =1 { Cluster }
      other {Clusters }
    }
  fleet.cattle.io.clustergroup: |-
    {count, plural,
      one { Cluster Group }
      other {Cluster Groups }
    }
  fleet.cattle.io.clusterregistrationtoken: "{count, plural,\n  one { Cluster Registration Token }\n  other { Cluster Registration Tokens }\n} "
  fleet.cattle.io.gitrepo: |-
    {count, plural,
      one { Git Repo }
      other {Git Repos }
    }
  group.principal: |-
    {count, plural,
      one { Group }
      other { Groups }
    }
  harvesterhci.io.cloudtemplate: |-
    {count, plural,
      one { Cloud Config Template }
      other { Cloud Config Templates }
    }
  harvesterhci.io.host: |-
    {count, plural,
      one { Host }
      other { Hosts }
    }
  harvesterhci.io.keypair: |-
    {count, plural,
      one { SSH Key }
      other { SSH Keys }
    }
  harvesterhci.io.management.cluster: |-
    {count, plural,
      one { Harvester Cluster }
      other { Harvester Clusters }
    }
  harvesterhci.io.networkattachmentdefinition: |-
    {count, plural,
      one { Network }
      other { Networks }
    }
  harvesterhci.io.setting: |-
    {count, plural,
      one { Setting }
      other { Settings }
    }
  harvesterhci.io.user: |-
    {count, plural,
      one { User }
      other { Users }
    }
  harvesterhci.io.virtualmachinebackup: |-
    {count, plural,
      one { Backup }
      other { Backups }
    }
  harvesterhci.io.virtualmachineimage: |-
    {count, plural,
      one { Image }
      other { Images }
    }
  harvesterhci.io.virtualmachinetemplateversion: |-
    {count, plural,
      one { Template }
      other { Templates }
    }
  harvesterhci.io.volume: |-
    {count, plural,
      one { Volume }
      other { Volumes }
    }
  helm.cattle.io.projecthelmchart: |-
    {count, plural,
      one { Project Monitor }
      other { Project Monitors }
    }
  k8s.cni.cncf.io.networkattachmentdefinition: |-
    {count, plural,
      one { Network Attachment Definition }
      other { Network Attachment Definitions }
    }
  kubevirt.io.virtualmachine: |-
    {count, plural,
      one { Virtual Machine }
      other { Virtual Machines }
    }
  management.cattle.io.authconfig: |-
    {count, plural,
      one { Authentication Provider }
      other { Authentication Providers }
    }
  management.cattle.io.cluster: |-
    {count, plural,
      one { Mgmt Cluster }
      other { Mgmt Clusters }
    }
  management.cattle.io.clusterroletemplatebinding: |-
    {count, plural,
      one { Cluster Member }
      other { Cluster Members }
    }
  management.cattle.io.feature: |-
    {count, plural,
      one { Feature Flag }
      other { Feature Flags }
    }
  management.cattle.io.fleetworkspace: |-
    {count, plural,
      one { Workspace }
      other { Workspaces }
    }
  management.cattle.io.setting: |-
    {count, plural,
      one { Setting }
      other { Settings }
    }
  management.cattle.io.token: |-
    {count, plural,
      one { API Key }
      other { API Keys }
    }
  management.cattle.io.user: |-
    {count, plural,
      one { User }
      other { Users }
    }
  monitoring.coreos.com.alertmanager: |-
    {count, plural,
      one { Alertmanager }
      other { Alertmanagers }
    }
  monitoring.coreos.com.alertmanagerconfig: |-
    {count, plural,
      one { AlertmanagerConfigs }
      other { AlertmanagerConfigs }
    }
  monitoring.coreos.com.podmonitor: |-
    {count, plural,
      one { Pod Monitor }
      other { Pod Monitors }
    }
  # pruh-mee-thee-eyes https://www.prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus
  monitoring.coreos.com.prometheus: |-
    {count, plural,
      one { Prometheus }
      other { Prometheis }
    }
  monitoring.coreos.com.prometheusrule: |-
    {count, plural,
      one { PrometheusRule }
      other { PrometheusRules }
    }
  monitoring.coreos.com.receiver: |-
    {count, plural,
      one { Receiver }
      other { Receivers }
    }
  monitoring.coreos.com.route: |-
    {count, plural,
      one { Route }
      other { Routes }
    }
  monitoring.coreos.com.servicemonitor: |-
    {count, plural,
      one { Service Monitor }
      other { Service Monitors }
    }
  monitoring.coreos.com.thanosruler: |-
    {count, plural,
      one { Thanos Rule }
      other { Thanos Rules }
    }
  namespace: |-
    {count, plural,
      one { Namespace }
      other { Namespaces }
    }
  node: |-
    {count, plural,
      one { Node }
      other { Nodes }
    }
  provisioning.cattle.io.cluster: |-
    {count, plural,
      one { Cluster }
      other { Clusters }
    }
  token: |-
    {count, plural,
      one { API Key }
      other { API Keys }
    }
  workload: |-
    {count, plural,
      one { Workload }
      other { Workloads }
    }
unit:
  day: |-
    {count, plural,
      one { day }
      other { days }
    }
  hour: |-
    {count, plural,
      one { hour }
      other { hours }
    }
  min: mins
  sec: secs
user:
  detail:
    clusterRoles:
      description: Roles granted to this user for individual clusters
      label: Cluster Roles
      tableHeaders:
        cluster: Cluster
    generic:
      tableHeaders:
        granted: Granted
        role: Role
    globalPermissions:
      adminMessage: This user is an administrator and has all permissions
      description: Access to manage resources that affect the entire installation
      label: Global Permissions
      readOnlyAdminMessage: This user is a read-only administrator and has read-only access to subordinate cluster objects
      tableHeaders:
        permission: Permission
    projectRoles:
      description: Roles granted to this user for individual projects
      label: Project Roles
      tableHeaders:
        project: Project
    username: Username
  edit:
    credentials:
      displayName:
        label: Display Name
        placeholder: e.g. John Smith
      label: Credentials
      userDescription:
        label: Description
        placeholder: e.g. This account is for John Smith
      username:
        exists: Username is already in use. Please choose a new username
        label: Username
        placeholder: e.g. jsmith
  list:
    errorRefreshingGroupMemberships: Error refreshing group memberships
v1ClusterTools:
  istio:
    description: Legacy V1 Istio. Istio v1.5 has been deprecated since Rancher 2.5.0. <a target="blank" href="{docsBase}/istio/#migrate-from-previous-istio-version">Learn more</a> about migrating to the latest version.
    label: Istio (Legacy)
  logging:
    description: Legacy V1 logging. V1 Logging is deprecated since Rancher 2.5.0. <a target="blank" href="{docsBase}/logging/migrating/">Learn more</a> about migrating to V2 Logging.
    label: Logging (Legacy)
  monitoring:
    description: Legacy V1 monitoring. V1 Monitoring is deprecated since Rancher 2.5.0. <a target="blank" href="{docsBase}/monitoring-alerting/guides/migrating/">Learn more</a> about the migration steps to V2 Monitoring.
    label: Monitoring (Legacy)
vGpuReservation:
  label: Orion X GPU Reservation
  placeholder: e.g. 1
  set: Limit to
  unit: vGPUs
validation:
  arrayLength:
    between: '"{key}" should contain between {min} and {max} {max, plural, =1 {item} other {items}}'
    exactly: '"{key}" should contain {count, plural, =1 {# item} other {# items}}'
    max: '"{key}" should contain at most {count} {count, plural, =1 {item} other {items}}'
    min: '"{key}" should contain at least {count} {count, plural, =1 {item} other {items}}'
  boolean: '"{key}" must be a boolean value.'
  chars: '"{key}" contains {count, plural, =1 {an invalid character} other {# invalid characters}}: {chars}'
  cluster:
    name: Cluster name cannot be 'local' or take the form 'c-xxxxx'
  conflict: |-
    This resource has been modified since you started editing it, and some of those modifications conflict with your changes.
    This screen has been updated to reflect the current values on the cluster. Review and reapply the changes you wanted to make, then Save again.
    Conflicting {fieldCount, plural, =1 {field} other {fields}}: {fields}
  custom:
    missing: No validator exists for { validatorName }! Does the validator exist in custom-validators? Is the name spelled correctly?
  dns:
    doubleHyphen: '"{key}" Cannot contain two or more consecutive hyphens'
    hostname:
      empty: '"{key}" must be at least one character'
      emptyLabel: '"{key}" cannot contain two consecutive dots'
      endDot: '"{key}" cannot end with a dot'
      endHyphen: '"{key}" cannot end with a hyphen'
      startDot: '"{key}" cannot start with a dot'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLong: '"{key}" cannot be longer than {max} characters'
      tooLongLabel: '"{key}" cannot contain a section longer than {max} characters'
    label:
      emptyLabel: '"{key}" cannot be empty'
      endHyphen: '"{key}" cannot end with a hyphen'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLongLabel: '"{key}" cannot be more than {max} characters'
  flowOutput:
    both: Requires "Output" or "Cluster Output" to be selected.
    global: Requires "Cluster Output" to be selected.
  invalid: '"{key}" is invalid'
  invalidCron: Invalid cron schedule
  k8s:
    identifier:
      emptyLabel: '"{key}" cannot have an empty key'
      emptyPrefix: '"{key}" cannot have an empty prefix'
      endLetter: '"{key}" must end with a letter or number'
      startLetter: '"{key}" must start with a letter or number'
      tooLongKey: '"{key}" cannot have a key longer than {max} characters'
      tooLongPrefix: '"{key}" cannot have a prefix longer than {max} characters'
  monitoring:
    route:
      interval: '"{key}" must be of a format with digits followed by a unit i.e. 1h, 2m, 30s'
      match: At least one Match or Match Regex must be selected
  noSchema: No schema found to validate
  noType: No type to validate
  number:
    between: '"{key}" should be between {min} and {max}'
    exactly: '"{key}" should be exactly {val}'
    max: '"{key}" should be at most {val}'
    min: '"{key}" should be at least {val}'
  output:
    logdna:
      apiKey: Required an "Api Key" to be set.
  podAffinity:
    affinityTitle: Pod Affinity
    antiAffinityTitle: Pod Anti-Affinity
    matchExpressions:
      operator: Rule [{index}] of {group} {rules} - operator must be one of 'In', 'NotIn', 'Exists', 'DoesNotExist'
      valueMustBeEmpty: Rule [{index}] of {group} {rules} - value must be empty if operator is 'Exists' or 'DoesNotExist'
      valuesMustBeDefined: Rule [{index}] of {group} {rules} - value must be defined if operator is 'In' or 'NotIn'
    preferredDuringSchedulingIgnoredDuringExecution: preferred rules
    requiredDuringSchedulingIgnoredDuringExecution: required rules
    topologyKey: Rule [{index}] of {group} {rules} - Topology key is required.
  port: A port must be a number between 1 and 65535.
  prometheusRule:
    groups:
      required: At least one rule group is required.
      singleAlert: A rule may contain alert rules or recording rules but not both.
      valid:
        name: Name is required for rule group {index}.
        rule:
          alertName: Rule group {groupIndex} rule {ruleIndex} requires a Alert Name.
          expr: Rule group {groupIndex} rule {ruleIndex} requires a PromQL Expression.
          labels: Rule group {groupIndex} rule {ruleIndex} requires at least one label. Severity is recommended.
          recordName: Rule group {groupIndex} rule {ruleIndex} requires a Time Series Name.
        singleEntry: At least one alert rule or one recording rule is required in rule group {index}.
  required: '"{key}" is required'
  requiredOrOverride: '"{key}" is required or must allow override'
  roleTemplate:
    roleTemplateRules:
      missingApiGroup: You must specify an API Group for each resource grant
      missingOneResource: You must specify at least one Resource, Non-Resource URL or API Group for each resource grant
      missingResource: You must specify a Resource for each resource grant
      missingVerb: You must specify at least one verb for each resource grant
  service:
    externalName:
      none: External Name is required on an ExternalName Service.
    ports:
      name:
        required: Port Rule [{position}] - Name is required.
      nodePort:
        requiredInt: Port Rule [{position}] - Node Port must be integer values if included.
      port:
        required: Port Rule [{position}] - Port is required.
        requiredInt: Port Rule [{position}] - Port must be integer values if included.
      targetPort:
        between: Port Rule [{position}] - Target Port must be between 1 and 65535
        iana: Port Rule [{position}] - Target Port must be an IANA Service Name or Integer
        ianaAt: 'Port Rule [{position}] - Target Port '
        required: Port Rule [{position}] - Target Port is required
  setting:
    serverUrl:
      https: server-url must be https.
  stringLength:
    between: '"{key}" should be between {min} and {max} {max, plural, =1 {character} other {characters}}'
    exactly: '"{key}" should be {count, plural, =1 {# character} other {# characters}}'
    max: '"{key}" should be at most {count} {count, plural, =1 {character} other {characters}}'
    min: '"{key}" should be at least {count} {count, plural, =1 {character} other {characters}}'
  targets:
    missingProjectId: A target must have a project selected.
vncConsole:
  error:
    message: Web VNC console connection is disconnected
volumeClaimTemplate:
  add:
    label: Add Claim Template
wizard:
  finish: Finish
  next: Next
  previous: Previous
  step: Step {number}
wm:
  connection:
    connected: Connected
    connecting: Connecting&hellip;
    disconnected: Disconnected
    error: Error
  containerLogs:
    clear: Clear
    containerName: 'Container: {label}'
    download: Download
    follow: Follow
    noData: There are no log entries to show in the current range.
    noMatch: No lines match the current filter.
    previous: Use Previous Container
    range:
      all: Everything
      hours: |-
        {value, number}
        {value, plural,
        =1 {Hour}
        other {Hours}
        }
      label: Show the last
      lines: '{value, number} Lines'
      minutes: |-
        {value, number} {value, plural,
        =1 {Minute}
        other {Minutes}
        }
    search: Filter
    timestamps: Show Timestamps
    wrap: Wrap Lines
  containerShell:
    clear: Clear
    containerName: 'Container: {label}'
    permissionDenied:
      message: Permission Denied
      title: Error Open Shell
  kubectlShell:
    title: 'Kubectl: {name}'
workload:
  container:
    command:
      addEnvVar: Add Variable
      args: Arguments
      as: as
      command: Command
      env: Environment Variables
      fromResource:
        configMap: ConfigMap
        containerName: Container Name
        key:
          label: Key
          placeholder: e.g. metadata.labels['<KEY>']
        name:
          label: Variable Name
          placeholder: e.g. FOO
        prefix: Prefix
        secret: Secret
        source:
          label: Source
          placeholder: e.g. my-container
        type: Type
        value:
          label: Value
          placeholder: e.g. bar
      stdin: Stdin
      tty: TTY
      workingDir: WorkingDir
    containerName: Container Name
    healthCheck:
      checkInterval: Check Interval
      command:
        command: Command to run
      failureThreshold: Failure Threshold
      httpGet:
        headers: Request Headers
        path: Request Path
        port: Check Port
      initialDelay: Initial Delay
      kind:
        HTTP: HTTP request returns a successful status (200-399)
        HTTPS: HTTPS request returns a successful status
        exec: Command run inside the container exits with status 0
        none: None
        tcp: TCP connection opens successfully
      livenessProbe: Liveness Check
      livenessTip: Containers will be restarted when this check is failing.  Not recommended for most uses.
      noHealthCheck: There is not a Readiness Check, Liveness Check or Startup Check configured.
      readinessProbe: Readiness Check
      readinessTip: Containers will be removed from service endpoints when this check is failing.  Recommended.
      startupProbe: Startup Check
      startupTip: Containers will wait until this check succeeds before attempting other health checks.
      successThreshold: Success Threshold
      timeout: Timeout
    image: Container Image
    imagePullPolicy: Pull Policy
    imagePullSecrets: Pull Secrets
    init: Init Container
    lifecycleHook:
      exec:
        add: Add command to execute
        command:
          label: Command
          placeholder: e.g. sh -c 'sleep 10'
        title: Exec
      httpGet:
        add: Create HTTP request
        host:
          label: Host IP
          placeholder: e.g. 172.17.0.2
        path:
          label: Path
          placeholder: e.g. app/bin/endpoint?param=value
        port:
          label: Port
          placeholder: e.g. 3000
        scheme:
          label: Scheme
          placeholder: e.g. HTTP
        title: HttpGet
      httpHeaders:
        name:
          label: Name
          placeholder: e.g. accept-ranges
        title: HTTP Headers
        value:
          label: Value
          placeholder: e.g. bytes
      postStart:
        add: Add PostStart Hook
        label: PostStart
      preStop:
        add: Add PreStop Hook
        label: PreStop
      tcpSocket:
        add: Open a TCP socket
        host:
          label: Host
          placeholder: e.g. 192.168.0.1
        port:
          label: Port
          placeholder: e.g. 80
        title: TCPSocket
    name: Container Name
    noPorts: There are no ports configured.
    noResourceLimits: There are no resource requirements configured.
    noServiceAccess: You do not have permission to create or manage services
    ports:
      containerPort: Private Container Port
      createService: Service Type
      hostIP: Host IP
      hostPort: Public Host Port
      listeningPort: Listening Port
      name: Name
      noCreateService: Do not create a service
      protocol: Protocol
    removeContainer: Remove Container
    security:
      addCapabilities: Add Capabilities
      addGroupIDs: Add Group IDs
      allowPrivilegeEscalation:
        "false": No
        label: Privilege Escalation
        "true": 'Yes: container can gain more privileges than its parent process'
      dropCapabilities: Drop Capabilities
      fsGroup: Filesystem Group
      hostIPC: Use Host IPC Namespace
      hostPID: Use Host PID Namespace
      podFsGroup: Pod Filesystem Group
      privileged:
        "false": No
        label: Privileged
        "true": 'Yes: container has full access to the host'
      readOnlyRootFilesystem:
        "false": No
        label: Read-Only Root Filesystem
        "true": 'Yes: container has a read-only root filesystem'
      runAsGroup: Run as Group ID
      runAsNonRoot:
        "false": No
        label: Run as Non-Root
        "true": 'Yes: container must run as a non-root user'
      runAsNonRootOptions:
        noOption: "No"
        yesOption: 'Yes: containers must run as non-root-user'
      runAsUser: Run as User ID
      shareProcessNamespace: Share single process namespace
      supplementalGroups: Additional Group IDs
      sysctls: Sysctls
      sysctlsKey: Name
    standard: Standard Container
    tags: Tags
    titles:
      command: Command
      container: Container
      containers: Containers
      env: Environment Variables
      events: Events
      general: General
      healthCheck: Health Check
      image: Image
      lifecycle: Lifecycle Hooks
      metrics: Metrics
      networkSettings: Network Settings
      networking: Networking
      nodeScheduling: Node Scheduling
      podAnnotations: Pod Annotations
      podLabels: Pod Labels
      podScheduling: Pod Scheduling
      ports: Ports
      resources: Resources
      securityContext: Security Context
      status: Status
      upgrading: Scaling and Upgrade Policy
      volumeClaimTemplates: Volume Claim Templates
  cronSchedule: Schedule
  detail:
    pods:
      title: Pods
  detailTop:
    node: Node
    podIP: Pod IP
    podRestarts: Pod Restarts
    pods: Pods by State
    runs: Runs
    workload: Workload
  gaugeStates:
    failed: Failed
    running: Running
    succeeded: Successful
  hideTabs: Hide Advanced Options
  job:
    activeDeadlineSeconds:
      label: Active Deadline
      tip: The duration that the job may be active before the system tries to terminate it.
    backoffLimit:
      label: Back Off Limit
      tip: The number of retries before marking this job failed.
    completions:
      label: Completions
      tip: The number of successfully finished pods the job should be run with.
    failedJobsHistoryLimit:
      label: Failed Job History Limit
      tip: The number of failed finished jobs to retain.
    parallelism:
      label: Parallelism
      tip: The maximum number of pods the job should run at any given time.
    startingDeadlineSeconds:
      label: Starting Deadline Seconds
      tip: The deadline in seconds for starting the job if it misses scheduled time
    successfulJobsHistoryLimit:
      label: Successful Job History Limit
      tip: The number of successful finished jobs to retain.
    suspend: Suspend
  list:
    errorCannotScale: Failed to scale {workloadName} {direction, select, up { up } down { down } }
  metrics:
    metricsView: Metrics View
    pod: Pod Metrics
  networking:
    dns: DNS
    dnsPolicy:
      label: DNS Policy
      options:
        clusterFirst: Cluster First
        clusterFirstWithHostNet: Cluster First With Host Network
        default: Default
        none: None
      placeholder: Select a Policy...
    hostAliases:
      add: Add Alias
      keyLabel: IP Address
      keyPlaceholder: e.g. 1.1.1.1
      label: Host Aliases
      tip: Additional /etc/hosts entries to be injected in the container.
      valueLabel: Hostname
      valuePlaceholder: e.g. foo.com, bar.com
    hostname:
      label: Hostname
      placeholder: e.g. web
    nameservers:
      add: Add Nameserver
      label: Nameservers
      placeholder: e.g. 1.1.1.1
    networkMode:
      label: Network Mode
      options:
        hostNetwork: Host Network
        normal: Normal
      placeholder: Select a Mode...
    resolver:
      add: Add Option
      label: Resolver Options
    searches:
      add: Add Search Domain
      label: Search Domains
      placeholder: e.g. mycompany.com
    subdomain:
      label: Subdomain
      placeholder: e.g. web
    vlansubnet:
      ip:
        label: IP
        placeholder: e.g. 192.168.1.100,Multiple ips are connected by commas
      label: Flat Network
      mac:
        label: MAC
        placeholder: e.g. 0a:00:27:00:00:00, Multiple MACs are connected by commas
      network:
        label: Interface
        placeholder: Select a Inetwork...
      subnet:
        label: Subnet
        placeholder: Please choose a MacvlanSubnet
      tip: 'The upgrade strategy has been changed to: stop the old Pod and start the new Pod'
  normanWarning: It looks like this workload was created in the legacy Rancher UI. You may need to manually delete any services that were automatically created for it.
  replicas: Replicas
  scheduling:
    activeDeadlineSeconds: Pod Active Deadline
    activeDeadlineSecondsTip: The duration that the pod may be active before the system tries to mark it failed and kill associated containers.
    affinity:
      addNodeSelector: Add Node Selector
      affinityOption: Affinity
      affinityTitle: Run pods on nodes with pods matching these selectors
      antiAffinityOption: Anti-Affinity
      antiAffinityTitle: Run pods on nodes without pods matching these selectors
      anyNode: Run pods on any available node
      matchExpressions:
        addRule: Add Rule
        doesNotExist: is not set
        exists: is set
        greaterThan: '>'
        in: in list
        inNamespaces: 'Pods in these namespaces:'
        key: Key
        lessThan: <
        namespaces: Namespaces
        notIn: not in list
        operator: Operator
        value: Value
        weight: Weight
      noPodRules: There are no pod scheduling rules configured.
      nodeName: Node Name
      preferAny: 'Prefer any of:'
      preferred: Preferred
      priority: Priority
      requireAny: 'Require any of:'
      required: Required
      schedulingRules: Run pods on node(s) matching scheduling rules
      specificNode: Run pods on specific node(s)
      thisPodNamespace: This pod's namespace
      topologyKey:
        label: Topology Key
        placeholder: e.g. failure-domain.beta.kubernetes.io/zone
      type: Type
      weight:
        label: Weight
        placeholder: Must be a weight between 1 and 100
    priority:
      className: Priority Class Name
      priority: Priority
    terminationGracePeriodSeconds: Termination Grace Period
    terminationGracePeriodSecondsTip: The duration that the pod needs to terminate gracefully.
    titles:
      advanced: Advanced
      limits: Limits and Reservations
      nodeScheduling: Node Scheduling
      nodeSelector: Nodes with these labels
      podScheduling: Pod Scheduling
      priority: Priority
      tab: Scheduling
      tolerations: Tolerations
    tolerations:
      addToleration: Add Toleration
      effect: Effect
      effectOptions:
        all: All
        noExecute: NoExecute
        noSchedule: NoSchedule,
        preferNoSchedule: PreferNoSchedule
      labelKey: Label Key
      operator: Operator
      operatorOptions:
        equal: =
        exists: Exists
      tolerationSeconds: Toleration Seconds
      value: Value
  serviceAccountName:
    createMessage: The service name [ {name} ] does not exist in this namespace, you will need to create it manually.
    label: Service Account Name
  serviceName: Service Name
  showTabs: Show Advanced Options
  storage:
    addClaim: Add Claim
    addMount: Add Mount
    addVolume: Add Volume
    certificate: Certificate
    csi:
      cachingMode:
        label: Caching Mode
        options:
          none: None
          readOnly: Read Only
          readWrite: Read Write
      diskName: Disk Name
      diskURI: Disk URI
      drivers:
        driver.longhorn.io: Longhorn
      fsType: Filesystem Type
      kind:
        label: Kind
        options:
          dedicated: Dedicated
          managed: Managed
          shared: Shared
      partition: Partition
      pdName: Persistent Disk Name
      secretName: Secret Name
      shareName: Share Name
      storagePolicyID: Storage Policy ID
      storagePolicyName: Storage Policy Name
      volumeID: Volume ID
      volumePath: Volume Path
    defaultMode: Default Mode
    driver: driver
    hostPath:
      label: The Path on the Node must be
      options:
        blockDevice: An existing block device
        charDevice: An existing character device
        default: 'Anything: do not check the target path'
        directory: An existing directory
        directoryOrCreate: A directory, or create if it doesn't exist
        file: An existing file
        fileOrCreate: A file, or create if it doesn't exist
        socket: An existing socket
    keyToPath:
      addAction: Add Item
      default: All Keys
      header: Items
      key:
        label: Key
        placeholder: e.g. username
      mode:
        label: Mode
        placeholder: e.g. 400
      path:
        label: Path
        placeholder: e.g. my-group/my-username
      specific: Select Specific Keys
    mountPoint: Mount Point
    nodePath: Path on Node
    optional:
      label: Optional
      'no': 'No'
      'yes': 'Yes'
    path: Path
    readOnly: Read Only
    server: Server
    subPath: Sub Path in Volume
    subtypes:
      awsElasticBlockStore: Amazon EBS Disk
      azureDisk: Azure Disk
      azureFile: Azure File
      configMap: ConfigMap
      createPVC: Create Persistent Volume Claim
      csi: CSI
      driver.longhorn.io: Longhorn
      gcePersistentDisk: Google Persistent Disk
      hostPath: Bind-Mount
      nfs: NFS
      persistentVolumeClaim: Persistent Volume Claim
      secret: Secret
      vsphereVolume: VMWare vSphere Volume
    title: Storage
    volumeName: Volume Name
    volumePath: Volume Path
  typeDescriptions:
    apps.daemonset: DaemonSets run exactly one pod on every eligible node. When new nodes are added to the cluster, DaemonSets automatically deploy to them. Recommended for system-wide or vertically-scalable workloads that never need more than one pod per node.
    apps.deployment: Deployments run a scalable number of replicas of a pod distributed among the eligible nodes. Changes are rolled out incrementally and can be rolled back to the previous revision when needed. Recommended for stateless & horizontally-scalable workloads.
    apps.statefulset: StatefulSets manage stateful applications and provide guarantees about the ordering and uniqueness of the pods created. Recommended for workloads with persistent storage or strict identity, quorum, or upgrade order requirements.
    batch.cronjob: CronJobs create Jobs, which then run Pods, on a repeating schedule. The schedule is expressed in standard Unix cron format, and uses the timezone of the Kubernetes control plane (typically UTC).
    batch.job: Jobs create one or more pods to reliably perform a one-time task by running a pod until it exits successfully. Failed pods are automatically replaced until the specified number of completed runs has been reached. Jobs can also run multiple pods in parallel or function as a batch work queue.
  upgrading:
    activeDeadlineSeconds:
      label: Pod Active Deadline
      tip: The duration the pod may be active before the system will try to mark it failed and kill associated containers.
    concurrencyPolicy:
      label: Concurrency
      options:
        allow: Allow CronJobs to run concurrently
        forbid: Skip next run if current run hasn't finished
        replace: Replace run if current run hasn't finished
    maxSurge:
      label: Max Surge
      tip: The maximum number of pods allowed beyond the desired scale at any given time.
    maxUnavailable:
      label: Max Unavailable
      tip: The maximum number of pods which can be unavailable at any given time.
    minReadySeconds:
      label: Minimum Ready
      tip: The minimum duration a pod should be ready without containers crashing for it to be considered available.
    podManagementPolicy:
      label: Pod Management Policy
    progressDeadlineSeconds:
      label: Progress Deadline
      tip: The minimum duration to wait for a deployment to progress before marking it failed.
    revisionHistoryLimit:
      label: Revision History Limit
      tip: The number of old ReplicaSets to retain for rollback.
    strategies:
      labels:
        delete: 'On Delete: New pods are only created when old pods are manually deleted.'
        recreate: 'Recreate: Kill ALL pods, then start new pods.'
        rollingUpdate: 'Rolling Update: Create new pods, until max surge is reached, before deleting old pods. Don''t stop more pods than max unavailable.'
    terminationGracePeriodSeconds:
      label: Termination Grace Period
      tip: The duration the pod needs to terminate successfully.
    title: Upgrading
  validation:
    containerImage: Container {name} - "Container Image" is required.
    containers: Containers
workloadPorts:
  addHost: Add Host
  addPort: Add Port
  remove: Remove
